{
"Class" : "edu.stanford.nlp.ie.machinereading.common.SimpleTokenize", 
"Methods" : [{ "Name" : "tokenize" ,
"Nodes" : 5,
"0" : [ 17,18 ],
"1" : [ 19 ],
"2" : [ 22 ],
"3" : [ 20 ],
"4" : [  ]
},{ "Name" : "tokenize" ,
"Nodes" : 5,
"0" : [ 27,28 ],
"1" : [ 29 ],
"2" : [ 32 ],
"3" : [ 30 ],
"4" : [  ]
},{ "Name" : "findNonWhitespace" ,
"Nodes" : 6,
"0" : [ 39 ],
"1" : [ 43 ],
"2" : [ 40 ],
"3" : [ 39 ],
"4" : [ 41 ],
"5" : [  ]
},{ "Name" : "findWhitespace" ,
"Nodes" : 6,
"0" : [ 47 ],
"1" : [ 51 ],
"2" : [ 48 ],
"3" : [ 47 ],
"4" : [ 49 ],
"5" : [  ]
},{ "Name" : "normalizeQuotes" ,
"Nodes" : 10,
"0" : [ 58,59 ],
"1" : [ 59 ],
"2" : [ 67 ],
"3" : [ 61 ],
"4" : [ 64 ],
"5" : [ 59 ],
"6" : [ 61 ],
"7" : [ 61 ],
"8" : [ 62 ],
"9" : [  ]
},{ "Name" : "tokenizeWithQuotes" ,
"Nodes" : 18,
"0" : [ 75,76 ],
"1" : [ 78 ],
"2" : [ 116 ],
"3" : [ 82,79 ],
"4" : [ 107 ],
"5" : [ 110 ],
"6" : [ 113,114 ],
"7" : [ 108 ],
"8" : [ 82 ],
"9" : [ 85 ],
"10" : [ 88 ],
"11" : [ 92 ],
"12" : [ 96 ],
"13" : [ 93,94 ],
"14" : [ 102,103 ],
"15" : [ 89,90 ],
"16" : [ 82 ],
"17" : [  ]
},{ "Name" : "quotify" ,
"Nodes" : 7,
"0" : [ 124,125,126 ],
"1" : [ 126 ],
"2" : [ 131,132 ],
"3" : [ 127 ],
"4" : [ 129,126 ],
"5" : [ 128 ],
"6" : [  ]
}]
}