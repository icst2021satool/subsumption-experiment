{
"Class" : "edu.stanford.nlp.process.WordSegmentingTokenizer$WordSegmentingTokenizerFactory", 
"Methods" : [{ "Name" : "getTokenizer" ,
"Nodes" : 4,
"0" : [ ],
"2" : [ 1, 3, 5, 6],
"1" : [ 0, 2, 7],
"3" : [ 0, 2, 7],
"CoveredDUAsByNodes" : 7,
"Duas" : 10
}]
}