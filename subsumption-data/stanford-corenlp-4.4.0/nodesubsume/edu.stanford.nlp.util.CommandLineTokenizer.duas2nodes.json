{
"Class" : "edu.stanford.nlp.util.CommandLineTokenizer", 
"Methods" : [{ "Name" : "appendToBuffer" ,
"Nodes" : 4,
"Duas" : 5,
"0" :  [ 0,2 ],
"1" :  [ 0,2 ],
"2" :  [ 0,1 ],
"3" :  [ 0,2 ],
"4" :  [ 0,2 ]},{ "Name" : "tokenize" ,
"Nodes" : 23,
"Duas" : 66,
"0" :  [ 0,2 ],
"1" :  [ 0,1 ],
"2" :  [ 0,2 ],
"3" :  [ 0,5 ],
"4" :  [ 0,15,17 ],
"5" :  [ 0,15,16 ],
"6" :  [ 0,16 ],
"7" :  [ 0,17,16 ],
"8" :  [ 0,17,14 ],
"9" :  [ 0,1 ],
"10" :  [ 0,1 ],
"11" :  [ 0,4 ],
"12" :  [ 0,11 ],
"13" :  [ 0,18 ],
"14" :  [ 2,3,5 ],
"15" :  [ 2,3,4 ],
"16" :  [ 2,13,15 ],
"17" :  [ 2,13,14 ],
"18" :  [ 2,7,12 ],
"19" :  [ 2,7,8 ],
"20" :  [ 2,18,21 ],
"21" :  [ 2,18,19 ],
"22" :  [ 2,4 ],
"23" :  [ 2,9 ],
"24" :  [ 2,11 ],
"25" :  [ 2,12 ],
"26" :  [ 2,14 ],
"27" :  [ 2,16 ],
"28" :  [ 2,18 ],
"29" :  [ 2,3,5 ],
"30" :  [ 2,3,4 ],
"31" :  [ 2,5 ],
"32" :  [ 2,10 ],
"33" :  [ 2,13,15 ],
"34" :  [ 2,13,14 ],
"35" :  [ 2,15,17 ],
"36" :  [ 2,15,16 ],
"37" :  [ 2,16 ],
"38" :  [ 2,16 ],
"39" :  [ 2,17,16 ],
"40" :  [ 2,17,14 ],
"41" :  [ 5,18 ],
"42" :  [ 5,6 ],
"43" :  [ 5,6,13 ],
"44" :  [ 5,6,7 ],
"45" :  [ 5,8,11 ],
"46" :  [ 5,8,9 ],
"47" :  [ 5,9 ],
"48" :  [ 5,12 ],
"49" :  [ 20,7,12 ],
"50" :  [ 20,7,8 ],
"51" :  [ 20,18,21 ],
"52" :  [ 20,18,19 ],
"53" :  [ 16,10 ],
"54" :  [ 10,3,5 ],
"55" :  [ 10,3,4 ],
"56" :  [ 10,5 ],
"57" :  [ 10 ],
"58" :  [ 10,13,15 ],
"59" :  [ 10,13,14 ],
"60" :  [ 10,15,17 ],
"61" :  [ 10,15,16 ],
"62" :  [ 10,16 ],
"63" :  [ 10,16 ],
"64" :  [ 10,17,16 ],
"65" :  [ 10,17,14 ]}]
}