{
"Class" : "edu.stanford.nlp.process.PTBTokenizer$PTBTokenizerFactory", 
"Methods" : [{ "Name" : "<init>" ,
"Nodes" : 9,
"Duas" : 12,
"0" :  [ 0,4 ],
"1" :  [ 0,2,6 ],
"2" :  [ 0,2,3 ],
"3" :  [ 0,3,5 ],
"4" :  [ 0,3,4 ],
"5" :  [ 0,7 ],
"6" :  [ 0,1 ],
"7" :  [ 0,1 ],
"8" :  [ 0,4 ],
"9" :  [ 0,5 ],
"10" :  [ 0,6 ],
"11" :  [ 0,7 ]},{ "Name" : "getTokenizer" ,
"Nodes" : 5,
"Duas" : 17,
"0" :  [ 0,2 ],
"1" :  [ 0,1 ],
"2" :  [ 0,1 ],
"3" :  [ 0,2,1 ],
"4" :  [ 0,2,3 ],
"5" :  [ 0,3 ],
"6" :  [ 0,1 ],
"7" :  [ 0,3 ],
"8" :  [ 0,1 ],
"9" :  [ 0,3 ],
"10" :  [ 0,2 ],
"11" :  [ 0,1 ],
"12" :  [ 0,2,1 ],
"13" :  [ 0,2,3 ],
"14" :  [ 0,3 ],
"15" :  [ 0,1 ],
"16" :  [ 0,3 ]}]
}