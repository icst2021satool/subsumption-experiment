{
"Class" : "edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType", 
"Methods" : [{ "Name" : "initializeNameMap" ,
"Duas" : 10,
"0" :  "(67,74, map)",
"1" :  "(67,72, map)",
"2" :  "(67,70, map)",
"3" :  "(68,(69,70), type)",
"4" :  "(68,(69,72), type)",
"5" :  "(68,72, type)",
"6" :  "(68,70, type)",
"7" :  "(68,(69,70), type.abbreviation)",
"8" :  "(68,(69,72), type.abbreviation)",
"9" :  "(68,70, type.abbreviation)"},{ "Name" : "initializeClassMap" ,
"Duas" : 8,
"0" :  "(80,86, map)",
"1" :  "(80,83, map)",
"2" :  "(81,(82,83), type)",
"3" :  "(81,(82,81), type)",
"4" :  "(81,83, type)",
"5" :  "(81,(82,83), type.className)",
"6" :  "(81,(82,81), type.className)",
"7" :  "(81,83, type.className)"},{ "Name" : "getTokenizerType" ,
"Duas" : 20,
"0" :  "(96,101, Whitespace)",
"1" :  "(96,105, classToTokenizerMap)",
"2" :  "(96,113, nameToTokenizerMap)",
"3" :  "(96,120, Unspecified)",
"4" :  "(96,(104,105), tokClass)",
"5" :  "(96,(104,112), tokClass)",
"6" :  "(96,105, tokClass)",
"7" :  "(96,107, tokClass)",
"8" :  "(97,(100,101), whitespace)",
"9" :  "(97,(100,104), whitespace)",
"10" :  "(98,(112,113), language)",
"11" :  "(98,(112,120), language)",
"12" :  "(98,113, language)",
"13" :  "(98,115, language)",
"14" :  "(105,(106,107), type)",
"15" :  "(105,(106,109), type)",
"16" :  "(105,109, type)",
"17" :  "(113,(114,115), type)",
"18" :  "(113,(114,117), type)",
"19" :  "(113,117, type)"}]
}