{
"Class" : "edu.stanford.nlp.international.arabic.process.ArabicTokenizerTester", 
"Methods" : [{ "Name" : "main" ,
"Duas" : "57" ,
"Subsumers" : 13,
"0" : [ 5, 0], "S0" : [0, 2, 3, 5, 6, 7, 11, 13 ],
"1" : [ 1], "S1" : [1, 2, 3, 6, 7, 11, 13 ],
"2" : [ 35], "S2" : [2, 3, 4, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19, 22, 23, 26, 29, 31, 32, 35, 55 ],
"3" : [ 48], "S3" : [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 19, 22, 23, 24, 26, 29, 30, 31, 32, 33, 37, 39, 40, 41, 42, 44, 45, 47, 48, 51, 55 ],
"4" : [ 49], "S4" : [2, 3, 4, 6, 7, 9, 11, 12, 13, 14, 17, 18, 22, 24, 26, 29, 30, 31, 33, 37, 39, 40, 41, 42, 44, 45, 47, 49, 51, 55 ],
"5" : [ 34, 28, 25, 21, 20, 10], "S5" : [2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 17, 18, 20, 21, 25, 26, 28, 34, 55 ],
"6" : [ 27, 15], "S6" : [2, 3, 4, 6, 7, 11, 12, 13, 14, 15, 17, 18, 26, 27, 55 ],
"7" : [ 46, 43], "S7" : [2, 3, 4, 6, 7, 11, 12, 13, 14, 17, 18, 22, 24, 26, 29, 30, 31, 33, 37, 39, 40, 41, 43, 46, 51, 55 ],
"8" : [ 54, 52, 53, 50], "S8" : [2, 3, 4, 6, 7, 11, 12, 13, 14, 17, 18, 22, 24, 26, 29, 30, 31, 33, 37, 39, 40, 41, 50, 51, 52, 53, 54, 55 ],
"9" : [ 36], "S9" : [2, 3, 4, 6, 7, 11, 12, 13, 14, 17, 18, 22, 26, 29, 31, 36, 55 ],
"10" : [ 38], "S10" : [2, 3, 4, 6, 7, 11, 12, 13, 14, 17, 18, 22, 26, 29, 31, 38, 55 ],
"11" : [ 56], "S11" : [2, 3, 4, 6, 7, 11, 12, 13, 14, 17, 18, 26, 55, 56 ],
"12" : [ 16], "S12" : [2, 3, 6, 7, 11, 13, 16 ]
}]
}