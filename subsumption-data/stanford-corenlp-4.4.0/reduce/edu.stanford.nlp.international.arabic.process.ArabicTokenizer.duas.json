{
"Class" : "edu.stanford.nlp.international.arabic.process.ArabicTokenizer", 
"Methods" : [{ "Name" : "getNext" ,
"Duas" : 7,
"0" :  "(71,76, this)",
"1" :  "(71,76, this.lexer)",
"2" :  "(76,(77,77), nextToken)",
"3" :  "(76,(77,79), nextToken)",
"4" :  "(76,79, nextToken)",
"5" :  "(76,(77,79), nextToken)",
"6" :  "(76,(77,76), nextToken)"},{ "Name" : "atbFactory" ,
"Duas" : 2,
"0" :  "(136,140, tf)",
"1" :  "(136,138, tf)"},{ "Name" : "main" ,
"Duas" : 40,
"0" :  "(174,(174,174), args)",
"1" :  "(174,(174,183), args)",
"2" :  "(174,183, args)",
"3" :  "(174,(174,175), args)",
"4" :  "(174,(174,183), args)",
"5" :  "(174,217, err)",
"6" :  "(174,175, err)",
"7" :  "(174,176, err)",
"8" :  "(174,177, log)",
"9" :  "(174,178, log)",
"10" :  "(174,199, in)",
"11" :  "(174,210, out)",
"12" :  "(174,209, out)",
"13" :  "(174,207, out)",
"14" :  "(183,(184,185), tokenizerOptions)",
"15" :  "(183,(184,185), tokenizerOptions)",
"16" :  "(183,186, tokenizerOptions)",
"17" :  "(185,192, tf)",
"18" :  "(185,199, tf)",
"19" :  "(185,187, tf)",
"20" :  "(195,217, nLines)",
"21" :  "(195,205, nLines)",
"22" :  "(196,217, nTokens)",
"23" :  "(196,202, nTokens)",
"24" :  "(199,(201,202), tokenizer)",
"25" :  "(199,(201,216), tokenizer)",
"26" :  "(199,203, tokenizer)",
"27" :  "(200,(209,209), printSpace)",
"28" :  "(200,(209,210), printSpace)",
"29" :  "(202,217, nTokens)",
"30" :  "(202,202, nTokens)",
"31" :  "(203,(204,205), word)",
"32" :  "(203,(204,209), word)",
"33" :  "(203,210, word)",
"34" :  "(205,217, nLines)",
"35" :  "(205,205, nLines)",
"36" :  "(206,(209,209), printSpace)",
"37" :  "(206,(209,210), printSpace)",
"38" :  "(211,(209,209), printSpace)",
"39" :  "(211,(209,210), printSpace)"}]
}