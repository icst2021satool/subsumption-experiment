{
"Class" : "edu.stanford.nlp.process.LexerTokenizer", 
"Methods" : [{ "Name" : "getNext" ,
"Duas" : "18" ,
"Subsumers" : 5,
"0" : [ 11], "S0" : [0, 2, 4, 6, 10, 11, 17 ],
"1" : [ 15], "S1" : [0, 2, 3, 4, 6, 7, 9, 14, 15, 17 ],
"2" : [ 12], "S2" : [1, 5, 8, 10, 12 ],
"3" : [ 16], "S3" : [1, 3, 5, 7, 8, 9, 14, 16 ],
"4" : [ 13], "S4" : [3, 7, 9, 13, 14 ]
},{ "Name" : "<init>" ,
"Duas" : "4" ,
"Subsumers" : 2,
"0" : [ 3, 2, 0], "S0" : [0, 2, 3 ],
"1" : [ 1], "S1" : [1 ]
},{ "Name" : "main" ,
"Duas" : "4" ,
"Subsumers" : 1,
"0" : [ 3, 1, 0], "S0" : [0, 1, 2, 3 ]
}]
}