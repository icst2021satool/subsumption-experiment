{
"Class" : "edu.stanford.nlp.loglinear.learning.BacktrackingAdaGradOptimizer", 
"Methods" : [{ "Name" : "updateWeights" ,
"Duas" : 40,
"0" :  "(22,66, weights)",
"1" :  "(22,38, weights)",
"2" :  "(22,54, gradient)",
"3" :  "(22,64, gradient)",
"4" :  "(22,66, gradient)",
"5" :  "(22,70, gradient)",
"6" :  "(22,71, logLikelihood)",
"7" :  "(22,73, logLikelihood)",
"8" :  "(22,(73,73), quiet)",
"9" :  "(22,(73,76), quiet)",
"10" :  "(22,(40,40), quiet)",
"11" :  "(22,(40,44), quiet)",
"12" :  "(22,(45,46), quiet)",
"13" :  "(22,(45,47), quiet)",
"14" :  "(22,(27,27), quiet)",
"15" :  "(22,(27,28), quiet)",
"16" :  "(22,73, log)",
"17" :  "(22,46, log)",
"18" :  "(22,40, log)",
"19" :  "(22,27, log)",
"20" :  "(22,56, s)",
"21" :  "(22,58, s)",
"22" :  "(22,70, s)",
"23" :  "(22,71, s)",
"24" :  "(22,37, s)",
"25" :  "(22,38, s)",
"26" :  "(22,(44,45), s)",
"27" :  "(22,(44,76), s)",
"28" :  "(22,46, s)",
"29" :  "(22,37, s.lastDerivative)",
"30" :  "(22,38, s.lastDerivative)",
"31" :  "(22,(44,45), s.lastDerivative)",
"32" :  "(22,(44,76), s.lastDerivative)",
"33" :  "(22,46, s.lastDerivative)",
"34" :  "(22,56, s.adagradAccumulator)",
"35" :  "(22,58, s.adagradAccumulator)",
"36" :  "(24,(26,27), logLikelihoodChange)",
"37" :  "(24,(26,33), logLikelihoodChange)",
"38" :  "(24,(33,37), logLikelihoodChange)",
"39" :  "(24,(33,54), logLikelihoodChange)"},{ "Name" : "lambda$updateWeights$2" ,
"Duas" : 3,
"0" :  "(60,(60,60), d)",
"1" :  "(60,(60,61), d)",
"2" :  "(60,61, d)"}]
}