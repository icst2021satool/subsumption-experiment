{
"Class" : "edu.stanford.nlp.stats.EquivalenceClassEval$Eval", 
"Methods" : [{ "Name" : "eval" ,
"Duas" : 25,
"0" :  "(538,545, this)",
"1" :  "(538,546, this)",
"2" :  "(538,547, this)",
"3" :  "(538,549, this)",
"4" :  "(538,550, this)",
"5" :  "(538,(545,545), guesses)",
"6" :  "(538,(545,545), guesses)",
"7" :  "(538,545, guesses)",
"8" :  "(538,546, golds)",
"9" :  "(538,(547,547), golds)",
"10" :  "(538,(547,547), golds)",
"11" :  "(538,547, golds)",
"12" :  "(538,548, pw)",
"13" :  "(538,552, pw)",
"14" :  "(538,545, this.guessedCorrect)",
"15" :  "(538,546, this.gold)",
"16" :  "(538,547, this.goldCorrect)",
"17" :  "(538,545, precision)",
"18" :  "(538,548, precision)",
"19" :  "(540,547, recall)",
"20" :  "(540,548, recall)",
"21" :  "(542,548, f1)",
"22" :  "(544,549, this.guessed)",
"23" :  "(545,549, this.guessedCorrect)",
"24" :  "(546,550, this.gold)"},{ "Name" : "evalPrecision" ,
"Duas" : 39,
"0" :  "(559,(559,560), this)",
"1" :  "(559,(559,563), this)",
"2" :  "(559,(572,573), this)",
"3" :  "(559,(572,578), this)",
"4" :  "(559,574, this)",
"5" :  "(559,563, guesses)",
"6" :  "(559,566, guesses)",
"7" :  "(559,560, guesses)",
"8" :  "(559,564, golds)",
"9" :  "(559,567, golds)",
"10" :  "(559,561, golds)",
"11" :  "(559,(559,560), this.bagEval)",
"12" :  "(559,(559,563), this.bagEval)",
"13" :  "(559,(572,573), this.checker)",
"14" :  "(559,(572,578), this.checker)",
"15" :  "(559,574, this.checker)",
"16" :  "(560,566, internalGuesses)",
"17" :  "(560,570, internalGuesses)",
"18" :  "(561,567, internalGolds)",
"19" :  "(561,(572,573), internalGolds)",
"20" :  "(561,(572,578), internalGolds)",
"21" :  "(561,574, internalGolds)",
"22" :  "(563,566, internalGuesses)",
"23" :  "(563,570, internalGuesses)",
"24" :  "(564,567, internalGolds)",
"25" :  "(564,(572,573), internalGolds)",
"26" :  "(564,(572,578), internalGolds)",
"27" :  "(564,574, internalGolds)",
"28" :  "(568,579, thisGuessed)",
"29" :  "(568,571, thisGuessed)",
"30" :  "(569,579, thisGuessedCorrect)",
"31" :  "(569,573, thisGuessedCorrect)",
"32" :  "(570,(572,573), o)",
"33" :  "(570,(572,578), o)",
"34" :  "(570,574, o)",
"35" :  "(571,579, thisGuessed)",
"36" :  "(571,571, thisGuessed)",
"37" :  "(573,579, thisGuessedCorrect)",
"38" :  "(573,573, thisGuessedCorrect)"},{ "Name" : "evalRecall" ,
"Duas" : 12,
"0" :  "(584,(588,589), guesses)",
"1" :  "(584,(588,593), guesses)",
"2" :  "(584,594, thisGold)",
"3" :  "(584,587, thisGold)",
"4" :  "(585,594, thisGoldCorrect)",
"5" :  "(585,589, thisGoldCorrect)",
"6" :  "(586,(588,589), o)",
"7" :  "(586,(588,593), o)",
"8" :  "(587,594, thisGold)",
"9" :  "(587,587, thisGold)",
"10" :  "(589,594, thisGoldCorrect)",
"11" :  "(589,589, thisGoldCorrect)"}]
}