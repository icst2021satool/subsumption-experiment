{
"Class" : "edu.stanford.nlp.parser.metrics.Evalb$CBEval", 
"Methods" : [{ "Name" : "checkCrossing" ,
"Duas" : 18,
"0" :  "(97,106, this)",
"1" :  "(97,107, this)",
"2" :  "(97,104, this)",
"3" :  "(97,(99,100), s2)",
"4" :  "(97,(99,102), s2)",
"5" :  "(97,104, this.zeroCB)",
"6" :  "(97,106, this.cb)",
"7" :  "(97,107, this.num)",
"8" :  "(97,(103,104), c)",
"9" :  "(97,(103,106), c)",
"10" :  "(97,106, c)",
"11" :  "(97,100, c)",
"12" :  "(98,(99,100), constit)",
"13" :  "(98,(99,102), constit)",
"14" :  "(100,(103,104), c)",
"15" :  "(100,(103,106), c)",
"16" :  "(100,106, c)",
"17" :  "(100,100, c)"},{ "Name" : "evaluate" ,
"Duas" : 11,
"0" :  "(112,(115,116), this)",
"1" :  "(112,(115,119), this)",
"2" :  "(112,116, this)",
"3" :  "(112,(115,115), pw)",
"4" :  "(112,(115,119), pw)",
"5" :  "(112,116, pw)",
"6" :  "(112,(115,116), this.runningAverages)",
"7" :  "(112,(115,119), this.runningAverages)",
"8" :  "(112,116, this.cb)",
"9" :  "(112,116, this.num)",
"10" :  "(112,116, this.zeroCB)"}]
}