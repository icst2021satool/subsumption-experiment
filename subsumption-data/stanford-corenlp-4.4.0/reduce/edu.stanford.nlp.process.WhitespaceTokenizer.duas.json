{
"Class" : "edu.stanford.nlp.process.WhitespaceTokenizer", 
"Methods" : [{ "Name" : "getNext" ,
"Duas" : 24,
"0" :  "(132,(132,133), this)",
"1" :  "(132,(132,136), this)",
"2" :  "(132,136, this)",
"3" :  "(132,(138,139), this)",
"4" :  "(132,(138,141), this)",
"5" :  "(132,141, this)",
"6" :  "(132,(132,133), this.lexer)",
"7" :  "(132,(132,136), this.lexer)",
"8" :  "(132,136, this.lexer)",
"9" :  "(132,141, this.lexer)",
"10" :  "(132,(138,139), this.eolIsSignificant)",
"11" :  "(132,(138,141), this.eolIsSignificant)",
"12" :  "(136,(137,137), token)",
"13" :  "(136,(137,144), token)",
"14" :  "(136,144, token)",
"15" :  "(136,(137,138), token)",
"16" :  "(136,(137,144), token)",
"17" :  "(136,139, token)",
"18" :  "(141,(137,137), token)",
"19" :  "(141,(137,144), token)",
"20" :  "(141,144, token)",
"21" :  "(141,(137,138), token)",
"22" :  "(141,(137,144), token)",
"23" :  "(141,139, token)"},{ "Name" : "<init>" ,
"Duas" : 5,
"0" :  "(158,164, this)",
"1" :  "(158,164, factory)",
"2" :  "(158,(163,164), r)",
"3" :  "(158,(163,166), r)",
"4" :  "(158,164, r)"},{ "Name" : "main" ,
"Duas" : 20,
"0" :  "(219,(219,219), args)",
"1" :  "(219,(219,219), args)",
"2" :  "(219,(220,220), args)",
"3" :  "(219,(220,221), args)",
"4" :  "(219,(221,221), args)",
"5" :  "(219,(221,221), args)",
"6" :  "(219,221, args)",
"7" :  "(219,(219,219), args)",
"8" :  "(219,(219,219), args)",
"9" :  "(219,221, in)",
"10" :  "(219,228, out)",
"11" :  "(219,225, eolIsSignificant)",
"12" :  "(225,(230,231), tokenizer)",
"13" :  "(225,(230,238), tokenizer)",
"14" :  "(225,231, tokenizer)",
"15" :  "(228,235, pw)",
"16" :  "(228,233, pw)",
"17" :  "(231,(232,233), w)",
"18" :  "(231,(232,235), w)",
"19" :  "(231,235, w)"}]
}