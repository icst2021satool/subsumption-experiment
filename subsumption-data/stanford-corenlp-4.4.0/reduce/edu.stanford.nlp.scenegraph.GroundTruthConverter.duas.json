{
"Class" : "edu.stanford.nlp.scenegraph.GroundTruthConverter", 
"Methods" : [{ "Name" : "main" ,
"Duas" : 62,
"0" :  "(18,80, out)",
"1" :  "(18,20, reader)",
"2" :  "(20,(20,21), line)",
"3" :  "(20,(20,85), line)",
"4" :  "(20,21, line)",
"5" :  "(21,(22,23), img)",
"6" :  "(21,(22,25), img)",
"7" :  "(21,25, img)",
"8" :  "(21,29, img)",
"9" :  "(21,30, img)",
"10" :  "(21,31, img)",
"11" :  "(21,32, img)",
"12" :  "(21,46, img)",
"13" :  "(21,40, img)",
"14" :  "(21,41, img)",
"15" :  "(21,37, img)",
"16" :  "(21,25, img.regions)",
"17" :  "(21,29, img.id)",
"18" :  "(21,30, img.url)",
"19" :  "(21,31, img.height)",
"20" :  "(21,32, img.width)",
"21" :  "(21,46, img.objects)",
"22" :  "(21,40, img.objects)",
"23" :  "(21,41, img.objects)",
"24" :  "(21,37, img.objects)",
"25" :  "(25,39, region)",
"26" :  "(25,50, region)",
"27" :  "(25,51, region)",
"28" :  "(25,52, region)",
"29" :  "(25,53, region)",
"30" :  "(25,54, region)",
"31" :  "(25,62, region)",
"32" :  "(25,71, region)",
"33" :  "(25,62, region.attributes)",
"34" :  "(25,39, region.relationships)",
"35" :  "(25,71, region.relationships)",
"36" :  "(25,50, region.phrase)",
"37" :  "(25,51, region.x)",
"38" :  "(25,52, region.y)",
"39" :  "(25,53, region.h)",
"40" :  "(25,54, region.w)",
"41" :  "(28,44, predictedImg)",
"42" :  "(28,58, predictedImg)",
"43" :  "(28,59, predictedImg)",
"44" :  "(28,61, predictedImg)",
"45" :  "(28,69, predictedImg)",
"46" :  "(28,80, predictedImg)",
"47" :  "(28,73, predictedImg)",
"48" :  "(28,75, predictedImg)",
"49" :  "(28,65, predictedImg)",
"50" :  "(28,66, predictedImg)",
"51" :  "(28,46, predictedImg)",
"52" :  "(34,45, objectIds)",
"53" :  "(34,40, objectIds)",
"54" :  "(34,41, objectIds)",
"55" :  "(34,37, objectIds)",
"56" :  "(44,46, predictedImg.objects)",
"57" :  "(49,74, newRegion)",
"58" :  "(49,64, newRegion)",
"59" :  "(20,(20,21), line)",
"60" :  "(20,(20,85), line)",
"61" :  "(20,21, line)"}]
}