@@ Method, Nodes, Edges, DUAs, SubDUAs, Perc, Time_s, Time_ms
@@ edu.stanford.nlp.ling.CoreUtilities.toSentence,7,8,20,11,55.00000000000001,0,8
@@ edu.stanford.nlp.ling.CoreUtilities.deepCopy,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.CoreUtilities.toCoreLabelList,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.CoreUtilities.toCoreLabelList,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.CoreUtilities.toCoreLabelList,8,10,19,15,78.94736842105263,0,2
@@ edu.stanford.nlp.ling.CoreUtilities.toCoreLabelListWithCharacterOffsets,8,10,21,16,76.19047619047619,0,5
@@ edu.stanford.nlp.ling.CoreUtilities.toCoreLabelList,11,15,26,22,84.61538461538461,0,2
@@ edu.stanford.nlp.ling.TaggedWord.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.TaggedWord.setFromString,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.MultiTokenTag$Tag.equals,13,18,35,35,100.0,0,1
@@ edu.stanford.nlp.ling.DocumentReader.<init>,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.DocumentReader.readDocument,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.DocumentReader.getBufferedReader,6,7,7,6,85.71428571428571,0,1
@@ edu.stanford.nlp.ling.DocumentReader.readText,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.WordLemmaTag.setFromString,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.ling.WordLemmaTag.equals,11,15,19,19,100.0,0,1
@@ edu.stanford.nlp.ling.WordLemmaTag.hashCode,11,13,16,16,100.0,0,1
@@ edu.stanford.nlp.ling.WordLemmaTag.compareTo,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.ValueLabel.toString,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.ling.ValueLabel.equals,9,12,10,10,100.0,0,1
@@ edu.stanford.nlp.ling.ValueLabel.hashCode,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.ling.BasicDocument.init,8,9,9,9,100.0,0,1
@@ edu.stanford.nlp.ling.BasicDocument.label,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.BasicDocument.setLabels,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.ling.BasicDocument.addLabel,4,4,5,5,100.0,0,5
@@ edu.stanford.nlp.ling.BasicDocument.setTitle,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.BasicDocument.presentableText,7,8,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.CoreLabel.<init>,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.ling.CoreLabel.<init>,15,19,18,18,100.0,0,0
@@ edu.stanford.nlp.ling.CoreLabel.initFromStrings,20,27,53,40,75.47169811320755,0,2
@@ edu.stanford.nlp.ling.CoreLabel.parseStringKeys,7,8,20,12,60.0,0,0
@@ edu.stanford.nlp.ling.CoreLabel.initFromStrings,16,21,47,34,72.3404255319149,0,0
@@ edu.stanford.nlp.ling.CoreLabel.getString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.CoreLabel.setWord,6,8,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.CoreLabel.index,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.CoreLabel.sentIndex,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.CoreLabel.beginPosition,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.CoreLabel.endPosition,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.ling.CoreLabel.toString,43,69,113,112,99.11504424778761,0,2
@@ edu.stanford.nlp.ling.WordTag.toString,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.WordTag.setFromString,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.ling.WordTag.equals,16,23,39,39,100.0,0,1
@@ edu.stanford.nlp.ling.WordTag.hashCode,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.WordTag.compareTo,11,14,15,15,100.0,0,1
@@ edu.stanford.nlp.ling.WordTagFactory.newLabel,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.WordTagFactory.newLabelFromString,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.WordTagFactory.newLabel,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.SentenceUtils.toTaggedList,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.ling.SentenceUtils.toUntaggedList,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.SentenceUtils.toUntaggedList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.SentenceUtils.toWordList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.SentenceUtils.toCoreLabelList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.SentenceUtils.toCoreLabelList,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.ling.SentenceUtils.listToString,7,8,10,10,100.0,0,1
@@ edu.stanford.nlp.ling.SentenceUtils.listToString,7,8,9,9,100.0,0,1
@@ edu.stanford.nlp.ling.SentenceUtils.listToOriginalTextString,22,31,31,28,90.32258064516128,0,1
@@ edu.stanford.nlp.ling.SentenceUtils.wordToString,29,44,57,50,87.71929824561403,0,1
@@ edu.stanford.nlp.ling.SentenceUtils.extractNgram,14,19,30,25,83.33333333333334,0,1
@@ edu.stanford.nlp.ling.CategoryWordTag.<init>,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.CategoryWordTag.toString,13,20,20,20,100.0,0,0
@@ edu.stanford.nlp.ling.CategoryWordTag.toString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.BasicDatum.label,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.BasicDatum.setLabels,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.BasicDatum.addLabel,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.BasicDatum.equals,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.ling.CoreLabel$CoreLabelFactory.newLabel,14,19,25,25,100.0,0,0
@@ edu.stanford.nlp.ling.TaggedWordFactory.newLabel,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.TaggedWordFactory.newLabelFromString,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.RVFDatum.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.RVFDatum.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.WordLemmaTagFactory.newLabel,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.WordLemmaTagFactory.newLabelFromString,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.ling.IndexedWord.<init>,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.ling.IndexedWord.makeSoftCopy,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.IndexedWord.pseudoPosition,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.IndexedWord.toCopyIndex,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.IndexedWord.isCopy,11,15,20,20,100.0,0,0
@@ edu.stanford.nlp.ling.IndexedWord.equals,18,26,44,44,100.0,0,0
@@ edu.stanford.nlp.ling.IndexedWord.hashCode,12,16,34,17,50.0,0,1
@@ edu.stanford.nlp.ling.IndexedWord.compareTo,21,30,43,43,100.0,0,0
@@ edu.stanford.nlp.ling.StringLabel.<init>,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.AnnotationLookup.toCoreKey,7,8,5,5,100.0,0,1
@@ edu.stanford.nlp.ling.AnnotationLookup.getValueType,4,4,6,5,83.33333333333334,0,1
@@ edu.stanford.nlp.ling.MultiTokenTag.isStart,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.MultiTokenTag.isEnd,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.MultiTokenTag.equals,11,15,27,27,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern.match,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern.match,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern.match,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$RepeatPatternExpr.<init>,7,9,16,16,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$RepeatPatternExpr.build,22,31,82,60,73.17073170731707,0,5
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$RepeatPatternExpr.toString,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$GroupPatternExpr.assignGroupIds,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$GroupPatternExpr.updateBindings,4,4,11,11,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$GroupPatternExpr.toString,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$FilterExtractRule.extract,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$StringPatternExtractRule.<init>,7,8,12,8,66.66666666666666,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$StringPatternExtractRule.extract,7,8,13,11,84.61538461538461,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$StringPatternExtractRule.apply,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.<init>,10,13,11,11,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.appendRules,25,36,67,61,91.04477611940298,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.collapse,20,29,72,17,23.61111111111111,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.createExtractorFromFiles,11,14,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.getValue,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.extractCoreMapsToList,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.extractCoreMapsMergedWithTokens,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.flatten,8,9,10,10,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.cleanupTags,11,14,18,18,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.cleanupTags,11,14,19,19,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.applyCompositeRule,19,27,49,31,63.26530612244898,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.extractExpressions,16,22,65,39,60.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.annotateExpressions,12,16,22,22,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.annotateExpressions,10,13,17,17,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor.filterInvalidExpressions,15,20,25,18,72.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NilAnnotationPattern.match,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$AnnotationExtractRuleCreator.create,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$AnnotationExtractRuleCreator.create,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ProcessTokensRegexRequest.matchPattern,13,16,40,28,70.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.ProcessTokensRegexRequest.processRequest,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiPatternMatcher$BasicSequencePatternTrigger.apply,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$SequenceMatchedExpressionExtractor.apply,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules.createRule,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules.createExtractionRule,7,9,15,12,80.0,0,3
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules.createExtractionRule,7,9,18,13,72.22222222222221,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules.lookupExtractRuleCreator,8,11,14,14,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$StringAnnotationPattern.match,6,7,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapNodePatternTrigger.<init>,15,19,31,31,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapNodePatternTrigger.apply,15,21,27,27,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapNodePatternTrigger.lambda$new$0,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.NodePattern.matchWithResult,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$NodePatternState.match,13,18,42,42,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$PhraseStringCollection.isEmpty,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$PhraseStringCollection.contains,12,15,18,18,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$PhraseStringCollection.containsAll,7,8,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$PhraseStringCollection.addAll,7,8,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$PhraseStringCollection.removeAll,7,8,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapNodePattern$AttributesEqualMatchChecker.matches,10,13,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiNodePattern$IntersectMultiNodePattern.match,12,16,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$AttributesEqualMatchChecker.matches,10,13,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.condense,26,35,36,36,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getParents,6,7,14,7,50.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getParents,8,10,26,14,53.84615384615385,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getBranchState,8,10,20,10,50.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getBranchState,8,10,22,18,81.81818181818183,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getMatchedGroups,7,9,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getMatchedGroup,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.setGroupStart,6,7,13,13,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.setGroupEnd,9,12,29,29,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.clearGroupStart,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getMatchedResults,7,9,12,11,91.66666666666666,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getMatchedResult,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.setMatchedResult,6,7,13,13,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getBranchId,12,16,33,28,84.84848484848484,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getMatchStateInfo,7,9,12,11,91.66666666666666,0,2
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.getMatchStateInfo,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.removeMatchStateInfo,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.startMatchedCountInc,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.endMatchedCountInc,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.setMatchedInterval,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchStates.mergeBranchStates,15,20,35,35,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$GroupEndState.match,8,9,23,23,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.MultiCoreMapNodePattern$StringSequenceAnnotationPattern.<init>,8,10,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiCoreMapNodePattern$StringSequenceAnnotationPattern.<init>,8,10,19,11,57.89473684210527,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiCoreMapNodePattern$StringSequenceAnnotationPattern.match,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.TokenSequencePattern.compile,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.split,11,13,23,23,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.match,18,23,30,21,70.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.compareMatches,11,14,36,26,72.22222222222221,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.getMatchIndex,7,8,22,15,68.18181818181817,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.getMatchIndices,7,8,24,17,70.83333333333334,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.selectMatchIndex,30,41,97,51,52.57731958762887,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.setMatchedGroups,14,20,37,35,94.5945945945946,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.isAllMatch,10,12,15,12,80.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.isMatch,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$MatchedStates.addStates,5,5,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.<init>,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.replaceAllExtended,8,9,15,12,80.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.replaceFirstExtended,7,8,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.replaceAll,5,5,12,9,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.replaceFirst,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.find,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.find,13,17,22,17,77.27272727272727,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.find0,15,19,39,28,71.7948717948718,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.findNextNonOverlapping,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.findNextAll,12,17,37,37,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.find,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.findMatchStart,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.findMatchStartNoBacktracking,13,19,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.findMatchStartBacktracking,23,34,47,42,89.36170212765957,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.matches,8,10,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.clearMatched,9,11,28,20,71.42857142857143,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.getStateMessage,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.region,10,14,31,31,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.toBasicSequenceMatchResult,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.start,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.end,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.groupNodes,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.groupValue,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.groupInfo,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.groupMatchResults,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.groupMatchResult,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.nodeMatchResult,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher.getMatchedSignature,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.NodePattern$ConjNodePattern.match,7,8,6,5,83.33333333333334,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapNodePatternTrigger$StringTriggerCandidate.<init>,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiCoreMapNodePattern.match,10,13,43,32,74.4186046511628,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$StringMatchResultExtractor.apply,6,7,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$CompositeExtractRuleCreator.create,6,7,16,12,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$CompositeExtractRuleCreator.create,8,10,20,16,80.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$CompositeExtractRuleCreator.lambda$updateExtractRule$0,6,8,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$StringAnnotationRegexPattern.match,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$StringAnnotationRegexPattern.matchWithResult,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchAction$NextMatchAction.apply,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NotNilAnnotationPattern.match,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$PhraseTableIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$GroupStartState.match,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$IntegerAnnotationPattern.match,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$AbstractStringAnnotationPattern.ignoreCase,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$AbstractStringAnnotationPattern.normalize,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$AbstractStringAnnotationPattern.getNormalized,6,7,10,5,50.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$ListExtractRule.extract,7,8,8,6,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$ListExtractRule.ruleList,15,19,30,26,86.66666666666667,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern.transform,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern.findNodePattern,14,19,23,23,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern.findNodePatterns,21,31,39,39,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.setMatchType,6,7,10,10,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.markTargetString,27,38,68,30,44.11764705882353,0,1
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.findTargetStringOffsetsExct,21,31,69,35,50.72463768115942,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.getRegex,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.getPattern,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.getRegex,9,13,28,23,82.14285714285714,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.getExctWsRegex,12,15,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.getLnrmRegex,8,9,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.findTargetStringOffsetsRegex,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.findOffsets,22,32,53,29,54.71698113207547,0,1
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher.findTargetStringOffsets,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapSequenceMatchAction$MergeAction.apply,27,38,178,86,48.31460674157304,0,1
@@ edu.stanford.nlp.ling.tokensregex.NodePattern$DisjNodePattern.match,7,8,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ling.tokensregex.Env.getDefaultTokensAggregator,11,15,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.ling.tokensregex.Env.bindStringRegex,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.Env.expandStringRegex,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.Env.bind,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.Env.getNodePattern,14,19,23,23,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.Env.getSequencePatternExpr,15,20,20,20,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.Env.push,6,7,15,11,73.33333333333333,0,1
@@ edu.stanford.nlp.ling.tokensregex.Env.pop,7,9,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.Env.peek,7,9,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$ConjEndState.match,7,9,22,22,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$ConjStartState.match,8,10,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$PhraseMatch.getInterval,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$MultiSequencePatternExtractRule.extract,7,8,10,8,80.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$MultiSequencePatternExtractRule.apply,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$1.getNext,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$1.hasNext,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$1.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$AndPatternExpr.build,5,5,16,12,75.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$AndPatternExpr.assignGroupIds,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$AndPatternExpr.updateBindings,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$AndPatternExpr.copy,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$AndPatternExpr.optimize,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$AndPatternExpr.transform,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchAction$BranchAction.apply,10,12,20,20,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.lookupAnnotationKey,9,13,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.lookupAnnotationKeyWithClassname,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultTokensAggregators,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultTokensAggregator,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultTokensResultAnnotationKey,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultResultAnnotationKey,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultResultAnnotationExtractor,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultNestedResultsAnnotationKey,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultTextAnnotationKey,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.EnvLookup.getDefaultTokensAnnotationKey,5,6,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchState.<init>,13,18,37,37,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchState.updateKeepBids,8,10,12,12,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchState.addBidsToCollapse,9,11,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchState.addMatchedGroups,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$BranchState.addMatchedResults,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$AnnotationExtractRule.update,43,76,50,42,84.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$AnnotationExtractRule.isMostlyCompatible,14,23,72,72,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$AnnotationExtractRule.hasTokensRegexPattern,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$RepeatState.<init>,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$RepeatState.match,34,49,97,63,64.94845360824742,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$Frag.add,4,4,9,8,88.88888888888889,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$Frag.add,4,4,9,8,88.88888888888889,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$Frag.connect,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$Frag.connect,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapSequenceMatcher.annotateGroup,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapSequenceMatcher.getMergedList,8,10,27,21,77.77777777777779,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapSequenceMatcher.createMergedChunk,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapSequenceMatcher.mergeGroup,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapSequenceMatcher.lambda$static$0,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$SequenceMatchResultExtractor.apply,6,7,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.extractAnnotation,14,19,49,46,93.87755102040816,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.replaceMerged,11,14,30,20,66.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.replaceMergedUsingTokenOffsets,20,28,60,41,68.33333333333333,0,1
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.removeNullValues,9,11,7,7,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.removeNested,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.removeOverlapping,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.getBestMatched,11,15,20,10,50.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.lambda$static$7,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.lambda$static$5,13,18,20,20,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.lambda$static$4,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression.lambda$static$3,7,8,8,8,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SeqStartState.match,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern$CmpType$3.accept,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$Phrase.isLonger,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$Phrase.addForm,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable$Phrase.getAlternateForms,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.copy,9,11,32,22,68.75,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.start,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.start,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.end,8,10,17,17,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.end,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.group,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.group,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupNodes,8,11,23,23,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupNodes,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupValue,7,9,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupValue,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupInfo,7,8,20,20,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupInfo,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupMatchResults,9,12,21,21,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupMatchResults,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.nodeMatchResult,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupMatchResult,8,12,24,24,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.groupMatchResult,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult.getFirstVarGroup,8,10,31,20,64.51612903225806,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionNodePattern.match,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$State.equals,11,15,27,27,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatcher$State.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.NodePattern$NegateNodePattern.match,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern.newStringRegexPattern,14,18,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern.populate,56,87,101,97,96.03960396039604,0,1
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern.match,7,8,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern.matchWithResult,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern.match,7,8,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern.toString,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$MultiTokenPatternExtractRuleCreator.updateExtractRule,6,7,23,23,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$MultiTokenPatternExtractRuleCreator.create,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$MultiTokenPatternExtractRuleCreator.lambda$updateExtractRule$0,6,8,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern$CmpType$7.accept,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$AnnotationMatchedFilter.test,6,7,7,7,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression$SingleAnnotationExtractor.setAnnotations,18,24,34,29,85.29411764705883,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression$SingleAnnotationExtractor.annotate,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MatchedExpression$SingleAnnotationExtractor.annotate,26,35,65,59,90.76923076923077,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$BackRefPatternExpr.<init>,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$BackRefPatternExpr.toString,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapNodePatternTrigger$1.compare,12,15,28,28,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SeqEndState.match,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.BasicSequenceMatchResult$MatchedGroup.matchLength,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiNodePattern$UnionMultiNodePattern.match,14,19,23,12,52.17391304347826,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$MultiNodePatternState.match,21,28,61,50,81.9672131147541,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor$Stage.addRule,6,7,10,9,90.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor$Stage.addFilterRule,8,9,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern$CmpType$5.accept,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchAction$SeriesAction.apply,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$SequencePatternExtractRule.extract,9,11,23,21,91.30434782608695,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$SequencePatternExtractRule.apply,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiPatternMatcher.findNonOverlapping,10,12,16,14,87.5,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiPatternMatcher.find,10,12,17,15,88.23529411764706,0,1
@@ edu.stanford.nlp.ling.tokensregex.MultiPatternMatcher.findNonOverlappingMaxScore,8,9,15,13,86.66666666666667,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiPatternMatcher.findAllNonOverlappingMatchesPerPattern,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiPatternMatcher.getTriggeredPatterns,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$State.updateOutStates,7,8,9,9,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$State.match,8,10,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$State.add,7,8,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$State.value,6,8,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$State.markOptional,13,18,24,24,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$CoreMapToListFunctionApplier.apply,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern$CmpType$2.accept,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.isEmpty,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.containsKey,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.get,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.readPhrases,10,12,17,17,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.readPhrasesWithTagScores,13,16,37,27,72.97297297297297,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.readPhrases,10,12,18,18,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.getLongestPhrase,8,10,13,3,23.076923076923077,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.splitText,8,9,22,16,72.72727272727273,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.toNormalizedWordList,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.addPhrases,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.addPhrases,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.addPhrase,4,4,12,11,91.66666666666666,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.addPhrase,14,18,35,35,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.addPhrase,56,79,211,104,49.28909952606635,0,2
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.getNormalizedForm,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.createNormalizedForm,11,15,37,21,56.75675675675676,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.lookup,38,53,88,60,68.18181818181817,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.checkWordListMatch,17,23,53,33,62.264150943396224,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.findNonOverlappingPhrases,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.findMatches,37,56,111,95,85.58558558558559,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.findMatchesNormalized,48,71,156,133,85.25641025641025,0,1
@@ edu.stanford.nlp.ling.tokensregex.PhraseTable.toString,7,8,14,10,71.42857142857143,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$BackRefState.match,7,8,32,32,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$BackRefState.match,10,13,35,35,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$CoreMapFunctionApplier.<init>,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$CoreMapFunctionApplier.apply,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$SequenceRegexPattern.matchWithResult,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$ConjMatchStateInfo.addChildBid,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$ConjMatchStateInfo.isAllChildMatched,8,10,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$ConjMatchStateInfo.isAllChildMatched,16,22,33,20,60.60606060606061,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$ConjMatchStateInfo.getAllChildMatchedBids,18,24,42,25,59.523809523809526,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$ConjMatchStateInfo.updateKeepBids,9,11,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$TextPatternExtractRuleCreator.create,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$TextPatternExtractRuleCreator.create,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr.build,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr.assignGroupIds,5,5,4,1,25.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr.updateBindings,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr.copy,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr.transform,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr.optimize,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr.optimizeOrStringSeqs,51,73,123,84,68.29268292682927,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$OrPatternExpr._getStringAnnotation_,7,10,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.MultiWordStringMatcher$LongestStringComparator.compare,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern$CmpType$4.accept,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$StringInSetAnnotationPattern.<init>,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchAction$StartMatchAction.apply,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.CoreMapNodePattern.valueOf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.CoreMapSequenceMatchAction$AnnotateAction.apply,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SequencePatternExpr.build,6,7,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SequencePatternExpr.assignGroupIds,5,5,4,1,25.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SequencePatternExpr.updateBindings,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SequencePatternExpr.copy,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SequencePatternExpr.optimize,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequencePattern$SequencePatternExpr.transform,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.ComplexNodePattern$NumericAnnotationPattern$CmpType$6.accept,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$BasicSequenceExtractRule.extract,7,8,22,13,59.09090909090909,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$TokenPatternExtractRuleCreator.updateExtractRule,6,7,25,25,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$TokenPatternExtractRuleCreator.create,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$TokenPatternExtractRuleCreator.create,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.SequenceMatchRules$TokenPatternExtractRuleCreator.lambda$updateExtractRule$0,6,8,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.demo.TokensRegexRetokenizeDemo.runPipeline,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.demo.TokensRegexRetokenizeDemo.main,11,13,16,10,62.5,0,1
@@ edu.stanford.nlp.ling.tokensregex.demo.TokensRegexMatcher.main,22,28,39,21,53.84615384615385,0,1
@@ edu.stanford.nlp.ling.tokensregex.demo.TokensRegexMatcherDemo.main,14,17,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.ling.tokensregex.demo.TokensRegexDemo.main,23,29,31,14,45.16129032258064,0,1
@@ edu.stanford.nlp.ling.tokensregex.demo.TokensRegexAnnotatorDemo.main,17,21,21,11,52.38095238095239,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$34.checkArgs,10,14,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$34.apply,7,8,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$10.compute,7,8,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$RegexMatchResultVarExpression.valueOf,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$RegexMatchResultVarExpression.evaluate,10,14,16,16,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$12.compute,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$36.checkArgs,9,12,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$36.apply,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$StringFunction.checkArgs,10,13,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$StringFunction.apply,13,17,48,30,62.5,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$TypedExpression.<init>,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$TypedExpression.equals,16,23,39,39,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$TypedExpression.hashCode,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$VarAssignmentExpression.evaluate,21,30,47,47,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$VarAssignmentExpression.equals,20,29,51,51,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$VarAssignmentExpression.hashCode,11,13,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$BooleanFunction.checkArgs,11,15,15,15,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$BooleanFunction.apply,8,10,27,23,85.18518518518519,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$32.checkArgs,11,16,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$32.removeTag,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$32.apply,10,12,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$NumericFunction.checkArgs,11,15,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$NumericFunction.apply,8,10,27,23,85.18518518518519,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$16.checkArgs,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$16.apply,8,9,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$29.checkArgs,13,20,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$29.apply,27,37,47,39,82.97872340425532,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$30.checkArgs,14,21,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$30.getTag,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$30.apply,13,17,20,18,90.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$VarExpression.evaluate,18,26,40,34,85.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$TypeCheckedFunction.<init>,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$TypeCheckedFunction.getParamDesc,10,12,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$TypeCheckedFunction.checkArgs,17,25,47,42,89.36170212765957,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$37.checkArgs,14,21,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$37.apply,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$35.checkArgs,9,12,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$35.apply,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions.convertValueToBoolean,16,21,17,14,82.35294117647058,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions.convertValueToBooleanValue,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions.asObject,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions.asExpression,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions.asValue,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions.createValue,7,9,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions.isArgTypesCompatible,18,25,58,23,39.6551724137931,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleCachedExpression.evaluate,7,9,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleCachedExpression.hasValue,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleCachedExpression.equals,13,18,31,31,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleCachedExpression.hashCode,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleExpression.equals,13,18,27,27,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleExpression.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$11.compute,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$WrappedExpression.equals,11,15,23,23,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$WrappedExpression.hashCode,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$9.compute,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$28.checkArgs,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$28.apply,20,27,24,18,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$31.checkArgs,12,18,14,14,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$31.setTag,4,4,7,6,85.71428571428571,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$31.apply,13,16,18,18,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$ListExpression.addAll,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$ListExpression.evaluate,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleValue.equals,13,18,27,27,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$SimpleValue.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$CompareFunction.compare,27,38,35,35,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$CompareFunction.checkArgs,13,20,26,26,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$CompareFunction.apply,12,17,17,17,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$33.checkArgs,11,16,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$33.apply,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.<init>,7,8,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.checkValue,8,10,8,6,75.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.getValue,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.get,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.set,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.toCompatibleObject,14,20,23,23,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.attemptTypeConversion,41,67,60,60,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.simplifyNoTypeConversion,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.evaluateNoTypeConversion,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CompositeValue.doEvaluation,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$17.checkArgs,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$17.apply,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$7.compute,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.<init>,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.hasTag,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.setTag,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.addTag,10,12,33,20,60.60606060606061,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.removeTag,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.getTag,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.equals,11,15,23,23,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Tags.hashCode,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$FunctionCallExpression.simplify,9,11,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$FunctionCallExpression.evaluate,40,55,121,78,64.46280991735537,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$FunctionCallExpression.equals,16,23,39,39,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$FunctionCallExpression.hashCode,8,9,11,11,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$RegexMatchVarExpression.valueOf,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$RegexMatchVarExpression.evaluate,14,20,24,24,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$19.checkArgs,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$19.apply,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions.lookupFunctionObject,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions.join,7,8,13,10,76.92307692307693,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions.isInteger,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions.main,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$5.compute,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$24.apply,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$20.apply,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$1.compute,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$41.checkArgs,14,21,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$41.apply,14,21,32,31,96.875,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$39.checkArgs,14,21,16,16,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$39.apply,29,40,53,53,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$43.checkArgs,9,12,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$43.apply,5,5,16,9,56.25,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$IfExpression.evaluate,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$22.apply,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$3.compute,5,6,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$44.checkArgs,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$44.apply,10,12,24,18,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$25.apply,5,6,7,7,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$4.compute,7,9,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$18.checkArgs,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$18.apply,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$27.checkArgs,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$27.apply,20,27,24,18,75.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$6.compute,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$ConditionalExpression.<init>,28,51,24,24,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$42.checkArgs,10,14,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$42.apply,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$NumericComparator.compare,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$NamedValueFunction.getParamDesc,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$NamedValueFunction.toString,4,4,9,8,88.88888888888889,0,2
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$2.compute,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$23.apply,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$21.apply,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$CaseExpression.<init>,7,8,15,10,66.66666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$38.checkArgs,10,14,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$38.apply,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$MethodCallExpression.simplify,10,13,20,16,80.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$MethodCallExpression.evaluate,22,31,69,50,72.46376811594203,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$MethodCallExpression.equals,23,34,59,59,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.Expressions$MethodCallExpression.hashCode,11,13,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$40.checkArgs,14,21,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.types.ValueFunctions$40.apply,14,20,35,21,60.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenMgrError.addEscapes,18,28,59,31,52.54237288135594,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenMgrError.LexicalErr,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.parseInteger,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.parseLongInteger,6,7,11,3,27.27272727272727,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.appendSpecialTokens,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.getStringFromTokens,9,11,33,15,45.45454545454545,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.RuleList,10,12,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.Rule,11,14,16,13,81.25,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.ExpressionExtractorRule,15,22,29,29,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.AssignmentRule,10,12,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.AssignableExpression,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.Expression,17,23,31,25,80.64516129032258,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.Index,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.FunctionCallExpression,16,20,32,32,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.ValueExpression,11,14,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CompositeFieldValue,17,22,30,30,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.FieldValue,9,12,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.BasicValue,19,31,40,40,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.AssignableVar,11,15,19,19,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.VarOrRegexVar,17,27,34,34,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.MethodCallExpression,16,20,33,33,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.AssignableNestedVarExpression,16,21,38,22,57.89473684210527,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NestedVarExpression,18,24,51,26,50.98039215686274,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NestedFunctionCallExpression,18,24,51,26,50.98039215686274,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.ListExpression,10,12,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.ListExpression2,10,12,15,15,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.BasicCondExpression,18,25,35,25,71.42857142857143,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CondGroup,11,14,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CondExpression,29,40,72,38,52.77777777777778,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CaseExpression,23,30,46,44,95.65217391304348,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.StringRegex,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqRegex,20,26,42,29,69.04761904761905,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.StringNumberValue,15,23,30,30,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqRegexBasic,37,52,110,74,67.27272727272727,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqRegexRepeatTimes,27,37,63,49,77.77777777777779,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqRegexDisj,20,27,33,33,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqRegexDisjConj,33,48,126,44,34.92063492063492,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqRegexGroup,19,26,38,30,78.94736842105263,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.BracketedNode,12,15,19,17,89.47368421052632,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqVar,6,7,5,5,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqBackRef,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.Node,11,14,19,17,89.47368421052632,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NodeDisj,20,27,34,32,94.11764705882352,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NodeConj,20,27,34,32,94.11764705882352,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NodeDisjConj,33,48,126,44,34.92063492063492,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NodeGroup,11,14,16,13,81.25,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NodeBasic,11,15,19,19,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CoreMapNode,46,65,103,99,96.11650485436894,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.AttrValue,35,52,125,70,56.00000000000001,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CoreMapWordPattern,17,26,52,36,69.23076923076923,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.MultiNodePattern,25,33,53,44,83.01886792452831,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CoreMapVarValue,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CoreMapVarNodePattern,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CoreMapExprNodePattern,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SeqRegexWithAction,10,12,16,14,87.5,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.Action,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.AnnotateAction,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SetAttrValues,17,22,30,30,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.SetAttrValue,18,25,43,29,67.44186046511628,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.NumberToken,12,16,21,18,85.71428571428571,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.IntegerToken,11,14,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.CmpToken,11,14,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.RelaxedStringToken,11,14,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.RelaxedString,11,15,20,20,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.RelaxedStringNoIdentifier,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_2,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_3,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_4,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_5,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_6,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_7,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_8,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_9,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_10,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_11,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_12,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_13,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_14,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_15,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_16,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_17,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_18,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_19,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_20,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_21,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_22,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_23,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_24,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_25,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_26,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_27,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_28,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_29,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_30,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_31,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_32,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_33,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_34,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_2_35,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexGroup_756_9_128,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexGroup_756_9_121,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexGroup_755_5_112,10,13,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_RelaxedStringToken_1140_3_108,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_MethodCallExpression_364_8_90,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CmpToken_1133_3_52,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_MethodCallExpression_361_3_33,10,13,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_IntegerToken_1126_3_49,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_VarOrRegexVar_353_9_66,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_VarOrRegexVar_351_9_65,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_VarOrRegexVar_349_9_64,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NumberToken_1119_3_135,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_VarOrRegexVar_347_9_63,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_VarOrRegexVar_345_9_42,8,12,18,18,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_VarOrRegexVar_345_9_62,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexDisjConj_720_12_107,9,13,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AssignableVar_339_9_89,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AssignableVar_337_9_72,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AssignableVar_337_9_88,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicValue_327_9_80,8,10,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicValue_325_9_79,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicValue_323_9_78,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicValue_321_9_77,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicValue_319_9_76,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicValue_317_9_67,9,14,22,22,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicValue_317_9_75,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexRepeatTimes_691_7_126,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexRepeatTimes_689_8_125,8,10,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CompositeFieldValue_285_27_81,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_FieldValue_298_13_39,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_28,10,13,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexRepeatTimes_681_8_124,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_27,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexRepeatTimes_679_8_123,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexRepeatTimes_677_8_122,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexRepeatTimes_676_3_118,11,17,33,33,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapExprNodePattern_1045_9_96,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_657_12_115,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapVarNodePattern_1039_9_95,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_651_9_117,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapVarValue_1033_9_134,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_ValueExpression_271_5_45,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AttrValue_961_80_131,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_649_9_106,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_ValueExpression_269_5_44,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_647_9_105,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_ValueExpression_268_3_26,5,6,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_645_9_104,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_643_9_103,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_FunctionCallExpression_257_10_74,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_641_9_102,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_639_9_101,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexBasic_639_7_97,11,17,33,33,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_MultiNodePattern_1019_8_120,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_FunctionCallExpression_253_3_40,10,13,12,12,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_MultiNodePattern_1015_6_127,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_35,10,13,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_Index_244_3_30,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AttrValue_965_47_133,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_MultiNodePattern_1006_5_119,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_34,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_MultiNodePattern_1004_5_111,10,13,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_13,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_12,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_11,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_10,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_9,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_8,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapWordPattern_986_9_110,11,18,30,30,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegex_604_7_98,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_Expression_224_3_31,9,14,22,22,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegex_602_7_70,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AttrValue_965_23_132,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegex_601_4_59,8,10,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AssignableExpression_217_3_38,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AttrValue_964_19_58,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AttrValue_962_19_57,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_StringRegex_592_5_23,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AttrValue_961_18_56,9,13,18,18,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AssignmentRule_209_3_21,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CaseExpression_579_11_48,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AttrValue_960_13_37,8,11,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_7,8,10,6,6,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_6,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_5,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapNode_936_25_100,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_ExpressionExtractorRule_188_5_20,7,10,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_4,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapNode_936_23_94,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_33,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapNode_948_9_86,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapNode_943_9_85,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_3,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_2,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_1,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapNode_926_13_93,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CondExpression_542_12_83,7,9,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapNode_925_9_69,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CoreMapNode_925_9_84,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NodeBasic_916_4_54,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NodeBasic_913_4_53,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NodeBasic_913_4_35,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CondGroup_528_5_92,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CondGroup_526_5_91,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_CondGroup_525_3_82,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_32,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_26,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_31,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_30,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicCondExpression_507_7_34,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NodeGroup_892_3_55,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_25,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BasicCondExpression_504_3_99,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_ListExpression2_490_6_47,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NodeDisjConj_860_12_130,9,13,16,16,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_ListExpression_473_6_46,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_24,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_23,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_22,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NestedFunctionCallExpression_442_6_41,7,10,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_21,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_20,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqBackRef_808_5_114,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_19,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_18,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_NestedVarExpression_410_6_43,7,10,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_17,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqVar_792_3_113,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BracketedNode_780_5_116,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_29,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_16,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_BracketedNode_776_3_109,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_15,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3_14,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_AssignableNestedVarExpression_382_6_73,6,8,10,10,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_RelaxedString_1148_5_51,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_SeqRegexGroup_758_9_129,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_RelaxedString_1147_3_50,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_3R_RelaxedString_1147_3_32,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.ReInit,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.ReInit,13,16,41,28,68.29268292682927,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.<init>,8,9,20,12,60.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.ReInit,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_consume_token,16,21,72,46,63.888888888888886,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_scan_token,19,27,91,48,52.74725274725275,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.getNextToken,5,5,16,14,87.5,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.getToken,8,9,34,6,17.647058823529413,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_ntk_f,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_add_error_token,23,32,72,57,79.16666666666666,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.generateParseException,23,31,90,44,48.888888888888886,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_rescan_token,44,81,142,49,34.50704225352113,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParser.jj_save,7,8,34,15,44.11764705882353,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.ExpandBuff,5,5,24,24,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.FillBuff,16,22,78,56,71.7948717948718,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.UpdateLineColumn,12,17,38,28,73.68421052631578,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.readChar,8,10,30,29,96.66666666666667,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.backup,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.ReInit,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.ReInit,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.GetImage,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.GetSuffix,5,5,18,18,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.SimpleCharStream.adjustBeginLineColumn,15,20,101,63,62.37623762376238,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.ParseException.initialise,25,33,109,46,42.201834862385326,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.ParseException.add_escapes,18,28,59,31,52.54237288135594,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjStopStringLiteralDfa_0,35,53,43,43,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa0_0,23,42,63,63,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa1_0,23,41,61,61,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa2_0,13,21,41,41,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa3_0,11,17,33,33,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa4_0,13,20,33,33,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa5_0,7,9,20,20,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa6_0,8,11,21,21,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa7_0,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveStringLiteralDfa8_0,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjMoveNfa_0,290,496,4381,555,12.668340561515636,0,44
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjFillToken,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjCanMove_0,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.getNextToken,17,23,57,48,84.21052631578947,0,1
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.jjCheckNAdd,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.ReInitRounds,5,5,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.ling.tokensregex.parser.TokenSequenceParserTokenManager.SwitchTo,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.MultiMatch.getMultimatched,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.MultiMatch.getMultivalues,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.MultiMatch.getMultioffsets,7,8,8,8,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.MultiMatch.equals,14,20,31,31,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.MultiMatch.toString,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.ExactMatchCost.cost,12,15,16,16,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.BoundedCostOrderedMap.put,12,17,45,45,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.BoundedCostOrderedMap.putAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.BoundedCostOrderedMap.valuesList,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.Match.getMatchedLength,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.Match.equals,21,31,59,59,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.Match.hashCode,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.Match.toString,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.Match.getInterval,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$MultiMatchQueue.add,9,11,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$MultiMatchQueue.topCost,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$MultiMatchQueue.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$MultiMatchQueue.toSortedList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$PartialApproxMatch.<init>,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$PartialApproxMatch.withMatch,26,37,86,81,94.18604651162791,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$PartialApproxMatch.withMatch,9,12,32,30,93.75,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$PartialApproxMatch.equals,18,26,47,47,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher$MatchQueue.add,6,7,16,16,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.getChildTrie,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.getChildTrie,10,12,17,5,29.411764705882355,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.putChildTrie,16,21,46,18,39.130434782608695,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.isLeaf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.updateTrieStrings,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.size,8,10,15,9,60.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.isEmpty,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.containsKey,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.get,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.get,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.put,11,14,39,12,30.76923076923077,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.remove,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.remove,12,15,31,9,29.03225806451613,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.putAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.updateKeys,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.updateValues,8,10,14,14,100.0,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMap.updateEntries,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.ApproxMatch.equals,11,15,23,23,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.ApproxMatch.toString,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.<init>,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.findClosestMatches,60,84,162,104,64.19753086419753,0,2
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.segment,9,11,28,16,57.14285714285714,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.segment,9,11,28,16,57.14285714285714,0,1
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.getNonOverlapping,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.updateAllMatches,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.updateAllMatchesWithStart,10,14,33,33,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.addToQueue,22,35,73,73,100.0,0,0
@@ edu.stanford.nlp.ling.tokensregex.matcher.TrieMapMatcher.lambda$static$0,49,70,138,133,96.37681159420289,0,1
@@ edu.stanford.nlp.misc.DependencyAnalyzer$Identifier.equals,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.misc.DependencyAnalyzer.addStartingClasses,20,26,59,36,61.016949152542374,0,0
@@ edu.stanford.nlp.misc.DependencyAnalyzer.transitiveClosure,11,14,15,15,100.0,0,1
@@ edu.stanford.nlp.misc.DependencyAnalyzer.main,12,15,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.misc.DependencyAnalyzer.prependPackage,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.misc.DependencyAnalyzer.<init>,33,46,113,64,56.63716814159292,0,1
@@ edu.stanford.nlp.misc.DependencyAnalyzer.canonicalIdentifier,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.ui.JarFileChooser.show,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.ui.JarFileChooser.showListSelectionDialog,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ui.JarFileChooser.getFiles,11,14,17,17,100.0,0,1
@@ edu.stanford.nlp.ui.JarFileChooser$1.mouseClicked,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer$GradientWorker.run,7,8,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.loglinear.learning.BacktrackingAdaGradOptimizer.updateWeights,15,21,31,31,100.0,0,0
@@ edu.stanford.nlp.loglinear.learning.BacktrackingAdaGradOptimizer.lambda$updateWeights$2,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer$Constraint.applyToWeights,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer$Constraint.applyToDerivative,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer.optimize,14,18,36,36,100.0,0,1
@@ edu.stanford.nlp.loglinear.learning.LogLikelihoodDifferentiableFunction.getSummaryForInstance,27,35,60,48,80.0,0,0
@@ edu.stanford.nlp.loglinear.learning.LogLikelihoodDifferentiableFunction.getDeterministicAssignment,11,14,28,9,32.142857142857146,0,0
@@ edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer$TrainingWorker.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer$TrainingWorker.estimateRelativeRuntime,7,8,7,4,57.14285714285714,0,1
@@ edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer$TrainingWorker.run,58,82,229,140,61.135371179039296,0,3
@@ edu.stanford.nlp.loglinear.storage.ModelBatch.writeToStream,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.loglinear.storage.ModelBatch.writeToStreamWithoutFactors,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.GamePlayerBenchmark$SampleState.push,5,6,16,16,100.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.GamePlayerBenchmark$SampleState.pop,5,6,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.GamePlayerBenchmark.main,37,48,121,74,61.15702479338842,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.GamePlayerBenchmark.gameplay,27,37,109,70,64.22018348623854,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.GamePlayerBenchmark.selectOrCreateChildAtRandom,16,21,32,27,84.375,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLBenchmark.benchmarkOptimizer,33,43,102,75,73.52941176470588,0,1
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLBenchmark.getWordShape,13,19,14,14,100.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLBenchmark.generateSentenceModel,14,19,35,31,88.57142857142857,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLBenchmark.getSentences,11,14,33,22,66.66666666666666,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLBenchmark.getEmbeddings,13,16,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLBenchmark.loadEmbeddingsFromFile,12,15,27,22,81.48148148148148,0,1
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark$ConcatVectorConstructionRecord.getRandomSizes,8,9,19,11,57.89473684210527,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark$ConcatVectorConstructionRecord.<init>,13,16,48,26,54.166666666666664,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark$ConcatVectorConstructionRecord.create,8,9,30,18,60.0,0,1
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark.main,40,52,136,67,49.26470588235294,0,1
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark.cloneBenchmark,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark.makeVectors,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark.addBenchmark,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark.dotProductBenchmark,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark.constructionBenchmark,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.ConcatVectorBenchmark.protoSerializationBenchmark,8,9,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLFeaturizer.getWordShape,13,19,14,14,100.0,0,1
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLFeaturizer.annotate,43,62,131,59,45.038167938931295,0,1
@@ edu.stanford.nlp.loglinear.benchmarks.CoNLLFeaturizer.lambda$annotate$0,17,24,53,53,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.NDArrayDoubles.<init>,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArrayDoubles.fastPassByReferenceIterator,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArrayDoubles.combinatorialNeighborStatesCount,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArrayDoubles.getTableAccessOffset,11,15,35,24,68.57142857142857,0,1
@@ edu.stanford.nlp.loglinear.model.ConcatVectorNamespace.newWeightsVector,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorNamespace.ensureFeature,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorNamespace.ensureSparseFeature,6,7,23,23,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorNamespace.debugVector,10,12,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorNamespace.debugFeatureValue,6,7,27,27,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.NDArrayDoubles$2.hasNext,7,8,22,15,68.18181818181817,0,0
@@ edu.stanford.nlp.loglinear.model.NDArrayDoubles$2.next,8,10,40,26,65.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArray.<init>,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArray.fastPassByReferenceIterator,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArray.combinatorialNeighborStatesCount,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArray.getTableAccessOffset,11,15,35,24,68.57142857142857,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel$Factor.valueEquals,7,9,26,26,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.GraphicalModel$Factor.getProtoBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel$Factor.readFromProto,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.addFactor,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.addFactor,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.getVariableSizes,21,27,41,28,68.29268292682927,0,1
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.getProtoBuilder,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.readFromProto,10,12,26,18,69.23076923076923,0,1
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.valueEquals,19,25,37,31,83.78378378378379,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.toString,5,5,4,1,25.0,0,1
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.cloneModel,10,12,28,18,64.28571428571429,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.getProtoMetaDataBuilder,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.GraphicalModel.readMetaDataFromProto,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.<init>,10,12,38,28,73.68421052631578,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.newEmptyClone,8,10,34,20,58.82352941176471,0,1
@@ edu.stanford.nlp.loglinear.model.ConcatVector.setDenseComponent,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.setSparseComponent,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.dotProduct,29,44,195,102,52.307692307692314,0,1
@@ edu.stanford.nlp.loglinear.model.ConcatVector.addVectorInPlace,63,93,435,179,41.14942528735632,0,2
@@ edu.stanford.nlp.loglinear.model.ConcatVector.elementwiseProductInPlace,42,61,255,140,54.90196078431373,0,1
@@ edu.stanford.nlp.loglinear.model.ConcatVector.mapInPlace,14,18,63,33,52.38095238095239,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.getDenseComponent,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.getValueAt,11,15,40,40,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.getSparseIndex,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.getProtoBuilder,9,11,44,25,56.81818181818182,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.readFromProto,8,9,28,17,60.71428571428571,0,1
@@ edu.stanford.nlp.loglinear.model.ConcatVector.valueEquals,43,67,274,119,43.43065693430657,0,1
@@ edu.stanford.nlp.loglinear.model.ConcatVector.toString,14,18,69,36,52.17391304347826,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVector.increaseSizeTo,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorTable.getProtoBuilder,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorTable.readFromProto,8,9,16,11,68.75,0,1
@@ edu.stanford.nlp.loglinear.model.ConcatVectorTable.valueEquals,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorTable.cacheVectors,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorTable.releaseCache,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.ConcatVectorTable.cloneTable,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.NDArray$2.hasNext,7,8,20,13,65.0,0,1
@@ edu.stanford.nlp.loglinear.model.NDArray$2.next,8,10,38,24,63.1578947368421,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.<init>,23,34,77,38,49.35064935064935,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.hasSparse,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.isInitialized,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.writeTo,7,8,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.getSerializedSize,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.equals,15,21,31,31,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.clear,11,13,28,23,82.14285714285714,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.buildPartial,17,22,56,47,83.92857142857143,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.mergeFrom,32,45,75,69,92.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.isInitialized,7,8,14,7,50.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.ensureFactorIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getFactorList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getFactorCount,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getFactor,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.setFactor,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.setFactor,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addFactor,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addFactor,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addFactor,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addFactor,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addAllFactor,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.clearFactor,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.removeFactor,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getFactorOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getFactorOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getFactorFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.ensureVariableMetaDataIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getVariableMetaDataList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getVariableMetaDataCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getVariableMetaData,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.setVariableMetaData,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.setVariableMetaData,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addVariableMetaData,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addVariableMetaData,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addVariableMetaData,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addVariableMetaData,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.addAllVariableMetaData,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.clearVariableMetaData,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.removeVariableMetaData,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getVariableMetaDataOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getVariableMetaDataOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getVariableMetaDataFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.hasMetaData,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getMetaData,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.setMetaData,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.setMetaData,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.mergeMetaData,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.clearMetaData,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getMetaDataOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel$Builder.getMetaDataFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable.<init>,27,40,111,41,36.93693693693694,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable.isInitialized,11,14,20,13,65.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable.writeTo,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable.getSerializedSize,10,12,39,25,64.1025641025641,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable.equals,12,16,25,25,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.buildPartial,6,7,25,17,68.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.mergeFrom,14,18,32,30,93.75,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.ensureKeyIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.setKey,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.addKey,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.addKeyBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.ensureValueIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.setValue,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.addValue,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData$Builder.addValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.buildPartial,9,11,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.mergeFrom,22,30,51,47,92.15686274509804,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.ensureDimensionSizeIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.getDimensionSizeList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.ensureFactorTableIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.getFactorTableList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.getFactorTableCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.getFactorTable,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.setFactorTable,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.setFactorTable,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.addFactorTable,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.addFactorTable,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.addFactorTable,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.addFactorTable,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.addAllFactorTable,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.clearFactorTable,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.removeFactorTable,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.getFactorTableOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.getFactorTableOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorTableProto$ConcatVectorTable$Builder.getFactorTableFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.clear,8,9,18,18,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.buildPartial,14,18,42,37,88.09523809523809,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.mergeFrom,13,17,26,26,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.hasFeaturesTable,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.getFeaturesTable,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.setFeaturesTable,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.setFeaturesTable,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.mergeFeaturesTable,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.clearFeaturesTable,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.getFeaturesTableOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.getFeaturesTableFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.ensureNeighborIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.getNeighborList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.hasMetaData,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.getMetaData,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.setMetaData,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.setMetaData,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.mergeMetaData,10,13,27,27,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.clearMetaData,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.getMetaDataOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor$Builder.getMetaDataFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.<init>,26,38,101,44,43.56435643564357,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.hasMetaData,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.getMetaData,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.getMetaDataOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.isInitialized,11,14,20,13,65.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.writeTo,10,12,35,27,77.14285714285715,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.getSerializedSize,12,15,46,27,58.69565217391305,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.equals,17,24,35,35,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$GraphicalModel.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector.<init>,16,22,44,27,61.36363636363637,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector.isInitialized,11,14,20,13,65.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector.getSerializedSize,7,8,21,14,66.66666666666666,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector.equals,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData.<init>,21,30,73,30,41.0958904109589,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData.writeTo,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData.getSerializedSize,10,12,40,26,65.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData.equals,12,16,25,25,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$MetaData.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.buildPartial,6,7,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.mergeFrom,11,14,22,22,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.isInitialized,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.hasSparse,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.ensureDataIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Component$Builder.getDataList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.mergeFrom,17,23,36,36,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.isInitialized,7,8,14,7,50.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.ensureComponentIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.getComponentList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.getComponentCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.getComponent,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.setComponent,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.setComponent,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.addComponent,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.addComponent,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.addComponent,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.addComponent,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.addAllComponent,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.clearComponent,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.removeComponent,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.getComponentOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.getComponentOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.ConcatVectorProto$ConcatVector$Builder.getComponentFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.<init>,32,48,130,56,43.07692307692308,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.hasFeaturesTable,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.getFeaturesTable,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.getFeaturesTableOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.hasMetaData,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.getMetaData,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.getMetaDataOrBuilder,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.writeTo,9,11,28,24,85.71428571428571,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.getSerializedSize,11,14,38,28,73.68421052631578,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.equals,20,29,41,41,100.0,0,1
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.loglinear.model.proto.GraphicalModelProto$Factor.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.loglinear.inference.CliqueTree.calculateMAP,13,17,57,23,40.35087719298245,0,0
@@ edu.stanford.nlp.loglinear.inference.CliqueTree.messagePassing,342,500,1284,668,52.024922118380054,0,14
@@ edu.stanford.nlp.loglinear.inference.CliqueTree.getObservedAssignments,8,9,31,19,61.29032258064516,0,0
@@ edu.stanford.nlp.loglinear.inference.CliqueTree.marginalizeMessage,14,19,26,13,50.0,0,1
@@ edu.stanford.nlp.loglinear.inference.CliqueTree.domainsOverlap,10,12,6,6,100.0,0,0
@@ edu.stanford.nlp.loglinear.inference.CliqueTree.assertsEnabled,5,6,4,4,100.0,0,9
@@ edu.stanford.nlp.loglinear.inference.TableFactor.<init>,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.loglinear.inference.TableFactor.<init>,25,34,77,49,63.63636363636363,0,1
@@ edu.stanford.nlp.loglinear.inference.TableFactor.getSummedMarginals,39,51,159,87,54.71698113207547,0,1
@@ edu.stanford.nlp.loglinear.inference.TableFactor.getMaxedMarginals,19,24,72,44,61.111111111111114,0,0
@@ edu.stanford.nlp.loglinear.inference.TableFactor.sumOut,68,92,271,167,61.62361623616236,0,2
@@ edu.stanford.nlp.loglinear.inference.TableFactor.multiply,56,82,194,151,77.83505154639175,0,1
@@ edu.stanford.nlp.loglinear.inference.TableFactor.valueSum,10,12,18,8,44.44444444444444,0,0
@@ edu.stanford.nlp.loglinear.inference.TableFactor.marginalize,28,37,82,60,73.17073170731707,0,1
@@ edu.stanford.nlp.loglinear.inference.TableFactor.getVariableSize,7,8,23,14,60.86956521739131,0,1
@@ edu.stanford.nlp.loglinear.inference.TableFactor.normalizeLogArr,18,23,37,19,51.35135135135135,0,0
@@ edu.stanford.nlp.loglinear.inference.TableFactor.<init>,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.loglinear.inference.TableFactor.assertsEnabled,5,6,4,4,100.0,0,0
@@ edu.stanford.nlp.loglinear.inference.TableFactor.lambda$observe$2,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$4.aggregate,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.TaggedTextOutputter.print,13,17,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse.<init>,16,22,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse.isInitialized,11,14,20,13,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse.equals,10,13,21,21,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TokensRegexHandler.handle,12,17,44,43,97.72727272727273,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TokensRegexHandler.lambda$handle$6,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TokensRegexHandler.lambda$null$5,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TokensRegexHandler.lambda$null$3,5,5,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TokensRegexHandler.lambda$null$2,8,9,18,13,72.22222222222221,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TokensRegexHandler.lambda$null$1,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.WebServiceAnnotator.ping,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.WebServiceAnnotator.ensureServer,22,32,46,43,93.47826086956522,0,1
@@ edu.stanford.nlp.pipeline.WebServiceAnnotator.unmount,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.<init>,39,62,270,74,27.40740740740741,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasSubject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getSubject,6,7,9,9,100.0,0,7
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getSubjectBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasRelation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getRelation,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getRelationBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasObject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getObject,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getObjectBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasConfidence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getTree,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getTreeOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasIstmod,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasPrefixBe,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasSuffixBe,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hasSuffixOf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.isInitialized,9,12,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.writeTo,29,40,104,92,88.46153846153845,0,12
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.getSerializedSize,31,43,188,83,44.148936170212764,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.equals,59,91,119,119,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.hashCode,28,40,135,45,33.33333333333333,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.AnnotatorPool$CachedAnnotator.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorPool$CachedAnnotator.equals,11,15,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorPool$CachedAnnotator.hashCode,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree.<init>,16,22,44,27,61.36363636363637,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree.equals,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.build,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.mergeFrom,17,23,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.ensureTreebankIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.getTreebankList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.getTreebankCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.getTreebank,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.setTreebank,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.setTreebank,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.addTreebank,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.addTreebank,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.addTreebank,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.addTreebank,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.addAllTreebank,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.clearTreebank,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.removeTreebank,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.getTreebankOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.getTreebankOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$Builder.getTreebankFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreEntityMention.canonicalEntityMention,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.ServerAnnotatorImplementations$SingletonAnnotator.<init>,10,12,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator$Entry.<init>,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator$Entry.toString,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreDocument.wrapAnnotations,8,11,19,19,100.0,0,1
@@ edu.stanford.nlp.pipeline.QuoteAttributionAnnotator.<init>,15,21,45,43,95.55555555555556,0,0
@@ edu.stanford.nlp.pipeline.QuoteAttributionAnnotator.entityMentionsToCharacterMap,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAttributionAnnotator.annotate,18,25,36,36,100.0,0,1
@@ edu.stanford.nlp.pipeline.QuoteAttributionAnnotator.requires,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult.<init>,16,22,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult.isInitialized,11,14,20,13,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult.equals,10,13,21,21,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.<init>,134,224,2574,252,9.79020979020979,0,16
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasMentionID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getMentionType,6,7,9,9,100.0,0,4
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasNumber,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getNumber,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getNumberBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getGender,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasAnimacy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getAnimacy,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getAnimacyBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasPerson,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getPerson,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getPersonBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasStartIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHeadIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHeadString,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getHeadString,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getHeadStringBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasNerString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getNerString,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getNerStringBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasOriginalRef,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasGoldCorefClusterID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasCorefClusterID,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasMentionNum,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasSentNum,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasUtter,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasParagraph,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasIsSubject,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasIsDirectObject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasIsIndirectObject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasIsPrepositionObject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHasTwin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasGeneric,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasIsSingleton,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHasBasicDependency,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHasEnhancedDepenedncy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHasContextParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHeadIndexedWord,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getHeadIndexedWord,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getHeadIndexedWordOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasDependingVerb,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getDependingVerb,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getDependingVerbOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasHeadWord,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getHeadWord,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getHeadWordOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hasSpeakerInfo,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getSpeakerInfo,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getSpeakerInfoOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.writeTo,93,133,340,304,89.41176470588236,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.getSerializedSize,95,136,973,285,29.290853031860227,0,14
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.equals,186,293,373,373,100.0,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.hashCode,86,127,1034,132,12.76595744680851,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.readUndelimited,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoBuilder,136,201,315,315,100.0,0,2
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoBuilder,119,173,301,153,50.83056478405316,0,2
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoBuilder,69,94,118,98,83.05084745762711,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,14,19,22,22,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,12,15,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoSection,16,21,23,23,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.createIndexedWordProtoFromIW,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.createIndexedWordProtoFromCL,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,59,85,164,164,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,16,22,29,29,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,20,28,37,37,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,16,22,26,26,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,14,24,36,36,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto,6,7,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toMapStringStringProto,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toMapIntStringProto,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoQuote,44,64,85,85,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoMention,26,37,50,50,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,133,199,256,256,100.0,0,2
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,42,61,86,86,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProtoNoTokens,41,60,80,80,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.loadSentenceMentions,21,29,37,37,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,187,275,412,356,86.40776699029125,0,3
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toFlattenedTree,14,18,22,22,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toFlattenedTree,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,35,50,56,47,83.92857142857143,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,15,21,31,27,87.09677419354838,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,14,24,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,7,8,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,53,78,109,71,65.13761467889908,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,18,24,46,32,69.56521739130434,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,12,15,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,5,5,11,7,63.63636363636363,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,18,24,50,35,70.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProtoNoTokens,25,38,49,49,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,23,29,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,26,34,29,29,100.0,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,19,25,23,23,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,51,71,72,72,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,26,37,49,49,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.fromProto,18,24,33,32,96.96969696969697,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.recoverOriginalText,20,27,52,34,65.38461538461539,0,1
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.lambda$fromProto$18,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.lambda$fromProto$17,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.lambda$fromProto$16,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CorefMentionAnnotator.synchCorefMentionEntityMention,20,31,97,33,34.02061855670103,0,2
@@ edu.stanford.nlp.pipeline.CorefMentionAnnotator.annotate,37,52,86,68,79.06976744186046,0,1
@@ edu.stanford.nlp.pipeline.CorefMentionAnnotator.getMentionFinder,5,6,16,16,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.getBackends,13,16,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.annotate,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.doAnnotation,19,28,34,34,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.checkStatus,9,12,17,17,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.run,16,21,38,37,97.36842105263158,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.shutdown,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.main,22,31,42,37,88.09523809523809,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.lambda$shell$5,11,16,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient.lambda$new$1,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUReader.<init>,9,11,19,18,94.73684210526315,0,1
@@ edu.stanford.nlp.pipeline.CoNLLUReader.readCoNLLUFileCreateCoNLLXLines,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUReader.readCoNLLUFileCreateCoNLLUDocuments,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUReader.convertCoNLLUDocumentToAnnotation,13,16,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUReader.convertCoNLLUSentenceToCoreMap,56,76,179,114,63.687150837988824,0,1
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$6.aggregate,13,17,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.buildPartial,8,10,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.mergeFrom,10,13,17,17,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.hasIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node$Builder.hasCopyAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreQuote.<init>,25,35,74,62,83.78378378378379,0,1
@@ edu.stanford.nlp.pipeline.LabeledChunkIdentifier.getAnnotatedChunks,22,33,109,39,35.77981651376147,0,1
@@ edu.stanford.nlp.pipeline.LabeledChunkIdentifier.isEndOfChunk,25,41,43,36,83.72093023255815,0,0
@@ edu.stanford.nlp.pipeline.LabeledChunkIdentifier.isEndOfChunk,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.LabeledChunkIdentifier.isStartOfChunk,36,59,57,50,87.71929824561403,0,1
@@ edu.stanford.nlp.pipeline.LabeledChunkIdentifier.isStartOfChunk,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.LabeledChunkIdentifier.isChunk,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.LabeledChunkIdentifier.getTagType,13,17,45,37,82.22222222222221,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.clear,8,9,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.buildPartial,14,18,49,39,79.59183673469387,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.mergeFrom,32,45,75,69,92.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.isInitialized,14,18,30,16,53.333333333333336,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.hasMatchIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.ensureNodeIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getNodeList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getNodeCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getNode,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.setNode,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.setNode,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addNode,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addNode,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addNode,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addNode,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addAllNode,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.clearNode,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.removeNode,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getNodeOrBuilder,4,4,10,10,100.0,0,4
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getNodeOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getNodeFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.ensureRelnIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getRelnList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getRelnCount,4,4,8,8,100.0,0,11
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getReln,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.setReln,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.setReln,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addReln,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addReln,7,8,15,15,100.0,0,11
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addReln,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addReln,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.addAllReln,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.clearReln,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.removeReln,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getRelnOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getRelnOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match$Builder.getRelnFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.buildPartial,8,10,27,18,66.66666666666666,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.mergeFrom,10,13,18,18,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.setText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.setTextBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.hasBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation$Builder.hasEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.mergeFrom,17,23,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.ensureResultIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.getResultList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.getResultCount,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.getResult,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.setResult,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.setResult,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.addResult,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.addResult,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.addResult,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.addResult,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.addAllResult,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.clearResult,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.removeResult,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.getResultOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.getResultOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$GraphResult$Builder.getResultFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$2.aggregate,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.buildPartial,22,31,118,53,44.91525423728814,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.mergeFrom,24,34,55,46,83.63636363636363,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasMentionID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getMentionType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setMentionType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasNumber,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getNumber,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getNumberBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setNumber,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setNumberBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getGender,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setGender,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasAnimacy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getAnimacy,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.getAnimacyBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setAnimacy,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.setAnimacyBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasBeginIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasHeadIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasSentenceIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention$Builder.hasPosition,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$MostFreqAggregator.aggregate,13,18,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.<init>,14,20,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.hasBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.hasEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.writeTo,8,10,24,24,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.getSerializedSize,10,13,33,24,72.72727272727273,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.equals,23,34,47,47,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$MatchLocation.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.<init>,15,22,55,30,54.54545454545454,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.hasSentenceNum,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.hasTokenIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.hasDocID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.hasCopyCount,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.writeTo,10,13,31,31,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.getSerializedSize,12,16,44,30,68.18181818181817,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.equals,28,42,57,57,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.hashCode,12,16,35,21,60.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.ColumnDataClassifierAnnotator.annotate,12,16,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexAnnotator.<init>,13,17,40,40,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexAnnotator.addTokenOffsets,7,8,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexAnnotator.extract,7,8,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexAnnotator.annotate,22,31,54,52,96.29629629629629,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.<init>,22,36,188,51,27.127659574468083,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasHeadStart,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasHeadEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getMentionType,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasNormalizedName,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getNormalizedName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getNormalizedNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasHeadTokenIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasCorefID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getCorefID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getCorefIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasObjectID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getObjectID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getObjectIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasExtentStart,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasExtentEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hasSubtype,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getSubtype,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getSubtypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.writeTo,24,34,80,80,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.getSerializedSize,26,37,149,72,48.322147651006716,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.equals,63,98,127,127,100.0,0,8
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.hashCode,26,37,119,42,35.294117647058826,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.WikidictAnnotator.<init>,18,25,63,40,63.49206349206349,0,1
@@ edu.stanford.nlp.pipeline.WikidictAnnotator.normalizeTimex,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.WikidictAnnotator.link,33,54,70,64,91.42857142857143,0,1
@@ edu.stanford.nlp.pipeline.WikidictAnnotator.doOneSentence,12,15,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.<init>,24,34,66,65,98.48484848484848,0,1
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.setUpFineGrainedNER,10,13,18,18,100.0,0,1
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.setUpAdditionalRulesNER,8,10,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.setUpTokensRegexRules,8,10,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.setUpEntityMentionBuilding,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.setUpDocDateAnnotator,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.mergeTokens,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.annotationWithNERTokenization,30,43,52,50,96.15384615384616,0,1
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.transferNERAnnotationsToAnnotation,22,30,42,20,47.61904761904761,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.annotate,45,67,114,94,82.45614035087719,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.doOneSentence,20,26,55,37,67.27272727272727,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.doOneFailedSentence,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.requires,6,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.requirementsSatisfied,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.NERCombinerAnnotator.lambda$static$0,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.<init>,22,32,80,36,45.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.hasMatchIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.isInitialized,18,24,38,24,63.1578947368421,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.writeTo,10,12,36,28,77.77777777777779,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.getSerializedSize,12,15,47,28,59.57446808510638,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.equals,17,24,35,35,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Match.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NaturalLogicRelation.forNumber,10,16,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NaturalLogicRelation.valueOf,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.mergeFrom,17,23,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.ensureTreesIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.getTreesList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.getTreesCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.getTrees,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.setTrees,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.setTrees,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.addTrees,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.addTrees,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.addTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.addTrees,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.addAllTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.clearTrees,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.removeTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.getTreesOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.getTreesOrBuilderList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse$Builder.getTreesFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreSentence.wrapEntityMentions,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreSentence.tregexResultTrees,7,8,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.<init>,27,44,258,62,24.031007751937985,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasTokenStartInSentenceInclusive,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasTokenEndInSentenceExclusive,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasNer,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getNer,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getNerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasNormalizedNER,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getNormalizedNER,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getNormalizedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasEntityType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getEntityType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getEntityTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasTimex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getTimex,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getTimexOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasWikipediaEntity,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getWikipediaEntity,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getWikipediaEntityBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getGender,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasEntityMentionIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasCanonicalEntityMentionIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hasEntityMentionText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getEntityMentionText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getEntityMentionTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.isInitialized,12,16,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.writeTo,26,37,86,86,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.getSerializedSize,28,40,167,77,46.10778443113773,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.equals,68,106,137,137,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.hashCode,28,40,135,45,33.33333333333333,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.RelationExtractorAnnotator.getVerbose,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.RelationExtractorAnnotator.getModelName,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.RelationExtractorAnnotator.annotate,17,24,31,26,83.87096774193549,0,0
@@ edu.stanford.nlp.pipeline.RelationExtractorAnnotator.main,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$CoreNLPHandler.getContentType,9,14,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$CoreNLPHandler.handle,24,36,85,84,98.82352941176471,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.<init>,13,18,35,24,68.57142857142857,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.hasBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.hasEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.writeTo,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.getSerializedSize,8,10,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.equals,18,26,37,37,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.TextOutputter.print,94,138,198,180,90.9090909090909,0,2
@@ edu.stanford.nlp.pipeline.TextOutputter.outputQuotes,13,17,18,15,83.33333333333334,0,1
@@ edu.stanford.nlp.pipeline.TextOutputter.lambda$print$0,7,8,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.<init>,21,30,70,39,55.714285714285715,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.hasGold,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.getGold,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.getGoldOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.isInitialized,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.writeTo,7,8,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.getSerializedSize,9,11,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.equals,15,21,31,31,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.<init>,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.annotate,7,8,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.annotate,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.getTotalTime,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.timingInformation,5,5,8,5,62.5,0,0
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.requirementsSatisfied,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.requires,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationPipeline.main,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.<init>,23,35,94,47,50.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.getValue,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.getValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.hasYieldBeginIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.hasYieldEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.hasScore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.hasSentiment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.getSentiment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.writeTo,15,20,51,47,92.15686274509804,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.getSerializedSize,17,23,76,44,57.89473684210527,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.equals,35,53,75,75,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.hashCode,16,22,55,28,50.90909090909091,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.mergeFrom,17,23,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.ensureResultIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.getResultList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.getResultCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.getResult,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.setResult,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.setResult,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.addResult,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.addResult,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.addResult,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.addResult,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.addAllResult,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.clearResult,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.removeResult,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.getResultOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.getResultOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$Builder.getResultFieldBuilder,7,8,13,12,92.3076923076923,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.<init>,13,18,35,24,68.57142857142857,0,17
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.hasTokenIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.writeTo,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.getSerializedSize,8,10,23,18,78.26086956521739,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.equals,18,26,37,37,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.hashCode,8,10,20,15,75.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.clear,8,9,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.buildPartial,12,15,35,33,94.28571428571428,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.mergeFrom,19,26,40,40,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.isInitialized,11,14,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.mergeFrom,4,4,5,5,100.0,0,5
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.ensureTokenIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getTokenList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getTokenCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getToken,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.setToken,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.setToken,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.addToken,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.addToken,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.addToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.addToken,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.addAllToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.clearToken,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.removeToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getTokenOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getTokenOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getTokenFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.hasGraph,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getGraph,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.setGraph,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.setGraph,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.mergeGraph,10,13,27,27,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.clearGraph,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getGraphOrBuilder,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies$Builder.getGraphFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.clear,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.build,4,4,4,4,100.0,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.mergeFrom,17,23,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.isInitialized,7,8,14,7,50.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.ensureMatchIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.getMatchList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.getMatchCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.getMatch,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.setMatch,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.setMatch,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.addMatch,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.addMatch,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.addMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.addMatch,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.addAllMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.clearMatch,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.removeMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.getMatchOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.getMatchOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch$Builder.getMatchFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.<init>,25,38,93,43,46.236559139784944,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.hasRoot,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.hasAssumedTruth,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.hasScore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.isInitialized,6,7,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.writeTo,11,14,37,33,89.1891891891892,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.getSerializedSize,13,17,51,35,68.62745098039215,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.equals,25,37,51,51,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.hashCode,12,16,35,21,60.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch.<init>,16,22,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch.isInitialized,11,14,20,13,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch.equals,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$PatternMatch.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.clear,5,5,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.buildPartial,17,23,64,43,67.1875,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.mergeFrom,27,38,59,56,94.91525423728814,0,10
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.ensureChildIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getChildList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getChildCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getChild,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.setChild,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.setChild,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.addChild,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.addChild,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.addChild,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.addChild,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.addAllChild,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.clearChild,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.removeChild,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getChildOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getChildOrBuilderList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getChildFieldBuilder,7,8,13,12,92.3076923076923,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getValue,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.setValue,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.setValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.hasYieldBeginIndex,5,5,4,4,100.0,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.hasYieldEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.hasScore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.hasSentiment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.getSentiment,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$ParseTree$Builder.setSentiment,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.<init>,22,32,79,41,51.89873417721519,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.hasSentence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.hasMatch,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.getMatch,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.getMatchOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.writeTo,9,11,29,25,86.20689655172413,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.getSerializedSize,11,14,39,25,64.1025641025641,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.equals,20,29,41,41,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.GenderAnnotator.loadGenderNames,8,9,1,1,100.0,0,1
@@ edu.stanford.nlp.pipeline.GenderAnnotator.annotateEntityMention,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.GenderAnnotator.annotate,13,17,19,19,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoNLLOutputter.orNeg,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLOutputter.orNull,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLOutputter.line,14,18,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLOutputter.print,23,34,61,42,68.85245901639344,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.buildPartial,6,7,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.mergeFrom,11,14,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.hasSpeakerName,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.getSpeakerName,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.getSpeakerNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.setSpeakerName,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.setSpeakerNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.ensureMentionsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo$Builder.getMentionsList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.clear,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.buildPartial,9,11,26,23,88.46153846153845,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.mergeFrom,11,14,22,22,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.hasDoc,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.getDoc,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.setDoc,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.setDoc,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.mergeDoc,10,13,27,27,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.clearDoc,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.getDocOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.getDocFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.ensurePatternIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.setPattern,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.addPattern,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest$Builder.addPatternBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.RegexNERAnnotator.annotate,30,43,88,69,78.4090909090909,0,1
@@ edu.stanford.nlp.pipeline.RegexNERAnnotator.findEndOfAnswerAnnotation,6,7,18,9,50.0,0,0
@@ edu.stanford.nlp.pipeline.RegexNERAnnotator.findStartOfNERAnnotation,6,7,16,7,43.75,0,1
@@ edu.stanford.nlp.pipeline.RegexNERAnnotator.findEndOfNERAnnotation,6,7,18,9,50.0,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.print,5,5,8,8,100.0,0,3
@@ edu.stanford.nlp.pipeline.XMLOutputter.annotationToDoc,39,57,129,123,95.34883720930233,0,1
@@ edu.stanford.nlp.pipeline.XMLOutputter.addSentiment,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.addTriples,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.buildDependencyTreeInfo,10,12,14,14,100.0,0,1
@@ edu.stanford.nlp.pipeline.XMLOutputter.addDependencyInfo,10,14,26,26,100.0,0,1
@@ edu.stanford.nlp.pipeline.XMLOutputter.addEntities,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.addRelations,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.addCorefGraphInfo,13,17,23,21,91.30434782608695,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.addCorefMention,7,9,26,26,100.0,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.addWordInfo,28,41,66,66,100.0,0,1
@@ edu.stanford.nlp.pipeline.XMLOutputter.setSingleElement,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.XMLOutputter.toXML,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.toXML,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.XMLOutputter.makeProbabilitiesElement,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.<init>,18,23,53,49,92.45283018867924,0,1
@@ edu.stanford.nlp.pipeline.ParserAnnotator.convertFlagsToArray,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.loadModel,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.doOneSentence,15,22,43,33,76.74418604651163,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.doOneFailedSentence,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.finishSentence,18,25,46,38,82.6086956521739,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.doOneSentence,13,17,24,24,100.0,0,1
@@ edu.stanford.nlp.pipeline.ParserAnnotator.requires,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotator.requirementsSatisfied,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.KBPAnnotator.<init>,15,20,43,41,95.34883720930233,0,0
@@ edu.stanford.nlp.pipeline.KBPAnnotator.acronymMatch,30,45,63,59,93.65079365079364,0,1
@@ edu.stanford.nlp.pipeline.KBPAnnotator.annotate,184,272,444,290,65.31531531531532,0,5
@@ edu.stanford.nlp.pipeline.KBPAnnotator.lambda$main$5,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.KBPAnnotator.lambda$annotate$3,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.KBPAnnotator.lambda$corefChainToKBPMentions$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.KBPAnnotator.lambda$corefChainToKBPMentions$0,6,8,19,18,94.73684210526315,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.build,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.buildPartial,6,7,19,16,84.21052631578947,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.mergeFrom,11,14,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.isInitialized,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.hasTregex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.getTregex,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.getTregexBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.setTregex,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.setTregexBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.ensureTsurgeonIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.setTsurgeon,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.addTsurgeon,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation$Builder.addTsurgeonBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$7.aggregate,15,20,30,15,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.clear,20,25,58,53,91.37931034482759,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.buildPartial,102,148,965,269,27.875647668393782,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.mergeFrom,129,187,367,278,75.74931880108991,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasMentionID,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getMentionType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setMentionType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setMentionTypeBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasNumber,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getNumber,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getNumberBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setNumber,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setNumberBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getGender,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setGender,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setGenderBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasAnimacy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getAnimacy,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getAnimacyBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setAnimacy,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setAnimacyBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasPerson,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getPerson,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getPersonBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setPerson,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setPersonBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasStartIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasEndIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHeadIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHeadString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadString,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadStringBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setHeadString,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setHeadStringBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasNerString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getNerString,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getNerStringBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setNerString,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setNerStringBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasOriginalRef,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasGoldCorefClusterID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasCorefClusterID,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasMentionNum,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasSentNum,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasUtter,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasParagraph,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasIsSubject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasIsDirectObject,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasIsIndirectObject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasIsPrepositionObject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHasTwin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasGeneric,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasIsSingleton,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHasBasicDependency,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHasEnhancedDepenedncy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHasContextParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHeadIndexedWord,5,5,4,4,100.0,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadIndexedWord,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setHeadIndexedWord,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setHeadIndexedWord,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.mergeHeadIndexedWord,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.clearHeadIndexedWord,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadIndexedWordOrBuilder,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadIndexedWordFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasDependingVerb,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getDependingVerb,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setDependingVerb,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setDependingVerb,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.mergeDependingVerb,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.clearDependingVerb,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getDependingVerbOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getDependingVerbFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasHeadWord,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadWord,7,8,12,12,100.0,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setHeadWord,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setHeadWord,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.mergeHeadWord,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.clearHeadWord,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadWordOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getHeadWordFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.hasSpeakerInfo,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSpeakerInfo,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setSpeakerInfo,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setSpeakerInfo,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.mergeSpeakerInfo,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.clearSpeakerInfo,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSpeakerInfoOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSpeakerInfoFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensureSentenceWordsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSentenceWordsList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSentenceWordsCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSentenceWords,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setSentenceWords,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setSentenceWords,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addSentenceWords,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addSentenceWords,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addSentenceWords,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addSentenceWords,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addAllSentenceWords,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.clearSentenceWords,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.removeSentenceWords,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSentenceWordsOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSentenceWordsOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getSentenceWordsFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensureOriginalSpanIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getOriginalSpanList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getOriginalSpanCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getOriginalSpan,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setOriginalSpan,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setOriginalSpan,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addOriginalSpan,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addOriginalSpan,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addOriginalSpan,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addOriginalSpan,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addAllOriginalSpan,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.clearOriginalSpan,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.removeOriginalSpan,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getOriginalSpanOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getOriginalSpanOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getOriginalSpanFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensureDependentsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setDependents,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addDependents,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addDependentsBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensurePreprocessedTermsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.setPreprocessedTerms,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addPreprocessedTerms,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.addPreprocessedTermsBytes,4,4,5,5,100.0,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensureAppositionsIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getAppositionsList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensurePredicateNominativesIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getPredicateNominativesList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensureRelativePronounsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getRelativePronounsList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensureListMembersIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getListMembersList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.ensureBelongToListsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Mention$Builder.getBelongToListsList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient$BackendScheduler.lambda$run$0,5,6,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.NumberAnnotator.annotate,13,17,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.NumberAnnotator.doOneSentenceNew,12,17,27,27,100.0,0,1
@@ edu.stanford.nlp.pipeline.BinarizerAnnotator.annotate,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.BinarizerAnnotator.doOneSentence,5,5,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.pipeline.BinarizerAnnotator.isBinarized,11,14,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.checkOffsets,9,11,25,22,88.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.fixTokenOffsets,15,19,43,19,44.18604651162791,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.copyUnsetAnnotations,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.fixChunkTokenBoundaries,30,43,131,50,38.16793893129771,0,1
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getMergedChunk,8,9,27,19,70.37037037037037,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getMergedChunk,13,17,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getChunkOffsetsUsingCharOffsets,12,15,38,21,55.26315789473685,0,1
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.mergeChunks,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getFirstNonWsChar,7,8,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getFirstNonWsCharOffset,9,11,20,11,55.00000000000001,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.fixChunkSentenceBoundaries,65,96,204,96,47.05882352941176,0,3
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getTokenText,17,23,26,18,69.23076923076923,0,1
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.hasCharacterOffsets,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.annotateChunkText,18,25,81,33,40.74074074074074,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.annotateChunkTokens,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getAnnotatedChunk,6,7,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getAnnotatedChunkUsingCharOffsets,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.getAnnotatedChunksUsingSortedCharOffsets,42,63,157,83,52.86624203821656,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.annotateChunk,14,18,20,20,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.annotateChunks,5,5,10,6,60.0,0,1
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.annotateChunks,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.createCoreMap,8,10,21,19,90.47619047619048,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.appendCoreMap,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChunkAnnotationUtils.splitCoreMap,7,8,24,21,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$RefCase.forNumber,6,8,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.<init>,13,18,35,24,68.57142857142857,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.hasName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.getName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.getNameBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.hasMatchIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.writeTo,6,7,17,17,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.getSerializedSize,8,10,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.equals,18,26,37,37,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.hashCode,8,10,20,15,75.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.<init>,20,31,105,44,41.904761904761905,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hasSource,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hasTarget,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hasDep,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.getDep,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.getDepBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hasIsExtra,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hasSourceCopy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hasTargetCopy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hasLanguage,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.getLanguage,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.isInitialized,10,13,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.writeTo,16,22,52,52,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.getSerializedSize,18,25,83,48,57.831325301204814,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.equals,43,66,91,91,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.hashCode,18,25,66,31,46.96969696969697,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUReader$CoNLLUSentence.processLine,9,11,19,19,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUReader$CoNLLUSentence.addSentenceData,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUReader$CoNLLUSentence.addMWTData,5,5,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$ConcatListAggregator.aggregate,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.buildPartial,47,68,367,115,31.33514986376022,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.mergeFrom,46,67,134,90,67.16417910447761,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.isInitialized,5,6,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasEnd,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasSentenceBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasSentenceEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasTokenBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasTokenEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasDocid,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getDocid,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getDocidBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setDocid,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setDocidBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasAuthor,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setAuthor,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasMention,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getMention,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getMentionBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setMention,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setMentionBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasMentionBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasMentionEnd,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getMentionType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setMentionType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasMentionSieve,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getMentionSieve,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getMentionSieveBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setMentionSieve,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setMentionSieveBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasSpeaker,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getSpeaker,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getSpeakerBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setSpeaker,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setSpeakerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasSpeakerSieve,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getSpeakerSieve,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getSpeakerSieveBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setSpeakerSieve,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setSpeakerSieveBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasCanonicalMention,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getCanonicalMention,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getCanonicalMentionBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setCanonicalMention,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setCanonicalMentionBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasCanonicalMentionBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasCanonicalMentionEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.hasAttributionDependencyGraph,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getAttributionDependencyGraph,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setAttributionDependencyGraph,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.setAttributionDependencyGraph,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.mergeAttributionDependencyGraph,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.clearAttributionDependencyGraph,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getAttributionDependencyGraphOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote$Builder.getAttributionDependencyGraphFieldBuilder,4,4,8,7,87.5,0,1
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toList,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toMap,5,5,13,9,69.23076923076923,0,1
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toMap,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toMap,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toNullable,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toNullableList,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toNullableMap,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toCorefMention,18,23,30,24,80.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toCorefChain,7,8,13,11,84.61538461538461,0,1
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toQuotation,8,11,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toSentence,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.hasSpeakerAnnotations,10,12,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONAnnotationReader.toAnnotation,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.AnnotatorPool.register,7,9,23,22,95.65217391304348,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorPool.clear,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorPool.get,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.<init>,142,234,2762,283,10.246198406951484,0,6
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasTokenOffsetBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasTokenOffsetEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasCharacterOffsetBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasCharacterOffsetEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getParseTree,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getParseTreeOrBuilder,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasBinarizedParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getBinarizedParseTree,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getBinarizedParseTreeOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasAnnotatedParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getAnnotatedParseTree,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getAnnotatedParseTreeOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSentiment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSentiment,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSentimentBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasBasicDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getBasicDependencies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getBasicDependenciesOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasCollapsedDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getCollapsedDependencies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getCollapsedDependenciesOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasCollapsedCCProcessedDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getCollapsedCCProcessedDependencies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getCollapsedCCProcessedDependenciesOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasAlternativeDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getAlternativeDependencies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getAlternativeDependenciesOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasEnhancedDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getEnhancedDependencies,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getEnhancedDependenciesOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasEnhancedPlusPlusDependencies,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getEnhancedPlusPlusDependencies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getEnhancedPlusPlusDependenciesOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasParagraph,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasLineNumber,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasHasRelationAnnotations,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasHasNumerizedTokensAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasHasCorefMentionsAnnotation,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSentenceID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSentenceID,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSentenceIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSectionDate,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSectionDate,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSectionDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSectionIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSectionName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSectionName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSectionNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSectionAuthor,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSectionAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSectionAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasDocID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getDocID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getDocIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSectionQuoted,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasHasEntityMentionsAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasHasKBPTriplesAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasHasOpenieTriplesAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasChapterIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasParagraphIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasEnhancedSentence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getEnhancedSentence,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getEnhancedSentenceOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSpeaker,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSpeaker,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSpeakerBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hasSpeakerType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSpeakerType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSpeakerTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.isInitialized,58,86,124,89,71.7741935483871,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.writeTo,107,153,389,345,88.68894601542416,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.getSerializedSize,109,156,1530,300,19.607843137254903,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.equals,212,334,425,425,100.0,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.hashCode,98,145,1325,150,11.320754716981133,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreMapAggregator.merge,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.<init>,15,22,37,31,83.78378378378379,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.hasOpenNode,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.getOpenNode,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.hasCloseNode,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.getCloseNode,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.getValue,9,12,23,15,65.21739130434783,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.getValueBytes,8,10,21,13,61.904761904761905,0,7
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.hasScore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.writeTo,10,13,31,31,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.getSerializedSize,12,16,44,30,68.18181818181817,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.equals,22,34,51,51,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.hashCode,10,14,34,23,67.64705882352942,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CharniakParserAnnotator.annotate,13,17,29,27,93.10344827586206,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.buildPartial,16,22,73,38,52.054794520547944,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.mergeFrom,18,25,34,34,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.isInitialized,16,22,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.hasName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.getName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.getNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.setName,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.setNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.hasQuantifierSpanBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.hasQuantifierSpanEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.hasSubjectSpanBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.hasSubjectSpanEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.hasObjectSpanBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator$Builder.hasObjectSpanEnd,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.buildPartial,6,7,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.mergeFrom,8,10,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.hasBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Span$Builder.hasEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.<init>,20,29,60,41,68.33333333333333,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.hasDocument,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.getDocument,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.getDocumentOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.hasLanguage,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.getLanguage,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.hasRelativePronouns,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.getRelativePronouns,9,12,23,15,65.21739130434783,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.getRelativePronounsBytes,8,10,21,13,61.904761904761905,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.writeTo,8,10,23,23,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.getSerializedSize,10,13,32,23,71.875,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.equals,20,30,45,45,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.hashCode,9,12,28,20,71.42857142857143,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.clear,14,17,39,30,76.92307692307693,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.buildPartial,38,53,172,100,58.139534883720934,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.mergeFrom,61,88,170,129,75.88235294117646,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.isInitialized,5,6,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasSubject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubject,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubjectBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setSubject,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setSubjectBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasRelation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelation,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelationBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setRelation,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setRelationBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasObject,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObject,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObjectBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setObject,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setObjectBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasConfidence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.ensureSubjectTokensIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubjectTokensList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubjectTokensCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubjectTokens,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setSubjectTokens,7,8,15,15,100.0,0,5
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setSubjectTokens,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addSubjectTokens,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addSubjectTokens,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addSubjectTokens,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addSubjectTokens,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addAllSubjectTokens,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.clearSubjectTokens,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.removeSubjectTokens,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubjectTokensOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubjectTokensOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getSubjectTokensFieldBuilder,7,8,13,12,92.3076923076923,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.ensureRelationTokensIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelationTokensList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelationTokensCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelationTokens,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setRelationTokens,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setRelationTokens,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addRelationTokens,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addRelationTokens,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addRelationTokens,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addRelationTokens,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addAllRelationTokens,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.clearRelationTokens,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.removeRelationTokens,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelationTokensOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelationTokensOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getRelationTokensFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.ensureObjectTokensIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObjectTokensList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObjectTokensCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObjectTokens,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setObjectTokens,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setObjectTokens,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addObjectTokens,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addObjectTokens,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addObjectTokens,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addObjectTokens,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.addAllObjectTokens,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.clearObjectTokens,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.removeObjectTokens,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObjectTokensOrBuilder,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObjectTokensOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getObjectTokensFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasTree,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getTree,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setTree,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.setTree,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.mergeTree,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.clearTree,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getTreeOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.getTreeFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasIstmod,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasPrefixBe,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasSuffixBe,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$RelationTriple$Builder.hasSuffixOf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.<init>,32,49,135,74,54.81481481481482,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hasProjectEquivalence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getProjectEquivalence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hasProjectForwardEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getProjectForwardEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hasProjectReverseEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getProjectReverseEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hasProjectNegation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getProjectNegation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hasProjectAlternation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getProjectAlternation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hasProjectCover,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getProjectCover,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hasProjectIndependence,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getProjectIndependence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.isInitialized,20,28,26,26,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.writeTo,16,22,52,52,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.getSerializedSize,18,25,83,48,57.831325301204814,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.equals,43,66,115,115,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.hashCode,18,25,72,37,51.388888888888886,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter$JSONWriter.routeObject,99,141,228,228,100.0,0,1
@@ edu.stanford.nlp.pipeline.JSONOutputter$JSONWriter.indent,6,7,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter$JSONWriter.space,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter$JSONWriter.newline,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.JSONOutputter$JSONWriter.lambda$object$0,7,9,14,14,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.buildPartial,16,22,73,38,52.054794520547944,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.mergeFrom,18,25,48,34,70.83333333333334,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getValue,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getValueBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setValue,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.hasAltValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getAltValue,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getAltValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setAltValue,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setAltValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.hasType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.hasTid,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getTid,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.getTidBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setTid,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.setTidBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.hasBeginPoint,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex$Builder.hasEndPoint,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clear,65,85,206,176,85.43689320388349,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.buildPartial,159,226,1189,409,34.3986543313709,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeFrom,219,321,785,471,60.0,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.isInitialized,54,80,104,69,66.34615384615384,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureTokenIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getTokenList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getTokenCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getToken,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setToken,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setToken,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addToken,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addToken,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addToken,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearToken,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getTokenOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getTokenOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getTokenFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasTokenOffsetBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasTokenOffsetEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasCharacterOffsetBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasCharacterOffsetEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getParseTree,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setParseTree,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setParseTree,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeParseTree,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearParseTree,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getParseTreeOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getParseTreeFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasBinarizedParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getBinarizedParseTree,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setBinarizedParseTree,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setBinarizedParseTree,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeBinarizedParseTree,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearBinarizedParseTree,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getBinarizedParseTreeOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getBinarizedParseTreeFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasAnnotatedParseTree,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getAnnotatedParseTree,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setAnnotatedParseTree,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setAnnotatedParseTree,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeAnnotatedParseTree,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearAnnotatedParseTree,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getAnnotatedParseTreeOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getAnnotatedParseTreeFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSentiment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSentiment,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSentimentBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSentiment,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSentimentBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureKBestParseTreesIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKBestParseTreesList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKBestParseTreesCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKBestParseTrees,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setKBestParseTrees,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setKBestParseTrees,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKBestParseTrees,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKBestParseTrees,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKBestParseTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKBestParseTrees,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllKBestParseTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearKBestParseTrees,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeKBestParseTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKBestParseTreesOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKBestParseTreesOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKBestParseTreesFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasBasicDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getBasicDependencies,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setBasicDependencies,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setBasicDependencies,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeBasicDependencies,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearBasicDependencies,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getBasicDependenciesOrBuilder,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getBasicDependenciesFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasCollapsedDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCollapsedDependencies,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setCollapsedDependencies,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setCollapsedDependencies,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeCollapsedDependencies,10,13,27,27,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearCollapsedDependencies,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCollapsedDependenciesOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCollapsedDependenciesFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasCollapsedCCProcessedDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCollapsedCCProcessedDependencies,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setCollapsedCCProcessedDependencies,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setCollapsedCCProcessedDependencies,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeCollapsedCCProcessedDependencies,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearCollapsedCCProcessedDependencies,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCollapsedCCProcessedDependenciesOrBuilder,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCollapsedCCProcessedDependenciesFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasAlternativeDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getAlternativeDependencies,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setAlternativeDependencies,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setAlternativeDependencies,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeAlternativeDependencies,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearAlternativeDependencies,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getAlternativeDependenciesOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getAlternativeDependenciesFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureOpenieTripleIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getOpenieTripleList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getOpenieTripleCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getOpenieTriple,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setOpenieTriple,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setOpenieTriple,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addOpenieTriple,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addOpenieTriple,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addOpenieTriple,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addOpenieTriple,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllOpenieTriple,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearOpenieTriple,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeOpenieTriple,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getOpenieTripleOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getOpenieTripleOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getOpenieTripleFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureKbpTripleIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKbpTripleList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKbpTripleCount,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKbpTriple,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setKbpTriple,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setKbpTriple,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKbpTriple,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKbpTriple,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKbpTriple,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addKbpTriple,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllKbpTriple,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearKbpTriple,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeKbpTriple,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKbpTripleOrBuilder,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKbpTripleOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getKbpTripleFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureEntailedSentenceIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedSentenceList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedSentenceCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedSentence,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEntailedSentence,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEntailedSentence,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedSentence,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedSentence,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedSentence,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedSentence,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllEntailedSentence,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearEntailedSentence,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeEntailedSentence,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedSentenceOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedSentenceOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedSentenceFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureEntailedClauseIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedClauseList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedClauseCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedClause,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEntailedClause,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEntailedClause,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedClause,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedClause,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedClause,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntailedClause,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllEntailedClause,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearEntailedClause,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeEntailedClause,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedClauseOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedClauseOrBuilderList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntailedClauseFieldBuilder,7,8,13,12,92.3076923076923,0,11
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasEnhancedDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedDependencies,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEnhancedDependencies,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEnhancedDependencies,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeEnhancedDependencies,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearEnhancedDependencies,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedDependenciesOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedDependenciesFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasEnhancedPlusPlusDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedPlusPlusDependencies,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEnhancedPlusPlusDependencies,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEnhancedPlusPlusDependencies,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeEnhancedPlusPlusDependencies,10,13,27,27,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearEnhancedPlusPlusDependencies,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedPlusPlusDependenciesOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedPlusPlusDependenciesFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureCharacterIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCharacterList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCharacterCount,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCharacter,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setCharacter,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setCharacter,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addCharacter,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addCharacter,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addCharacter,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addCharacter,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllCharacter,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearCharacter,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeCharacter,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCharacterOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCharacterOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getCharacterFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasParagraph,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setTextBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasLineNumber,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasHasRelationAnnotations,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureEntityIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntityList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntityCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntity,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEntity,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEntity,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntity,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntity,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntity,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addEntity,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllEntity,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearEntity,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeEntity,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntityOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntityOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEntityFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureRelationIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getRelationList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getRelationCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getRelation,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setRelation,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setRelation,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addRelation,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addRelation,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addRelation,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addRelation,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllRelation,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearRelation,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeRelation,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getRelationOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getRelationOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getRelationFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasHasNumerizedTokensAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureMentionsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentions,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setMentions,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setMentions,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentions,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentions,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentions,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentions,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllMentions,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearMentions,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeMentions,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsOrBuilderList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.ensureMentionsForCorefIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsForCorefList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsForCorefCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsForCoref,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setMentionsForCoref,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setMentionsForCoref,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentionsForCoref,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentionsForCoref,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentionsForCoref,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addMentionsForCoref,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.addAllMentionsForCoref,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearMentionsForCoref,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.removeMentionsForCoref,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsForCorefOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsForCorefOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getMentionsForCorefFieldBuilder,7,8,13,12,92.3076923076923,0,12
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasHasCorefMentionsAnnotation,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSentenceID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSentenceID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSentenceIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSentenceID,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSentenceIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSectionDate,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSectionDate,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSectionDateBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSectionDate,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSectionDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSectionIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSectionName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSectionName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSectionNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSectionName,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSectionNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSectionAuthor,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSectionAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSectionAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSectionAuthor,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSectionAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasDocID,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getDocID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getDocIDBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setDocID,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setDocIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSectionQuoted,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasHasEntityMentionsAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasHasKBPTriplesAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasHasOpenieTriplesAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasChapterIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasParagraphIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasEnhancedSentence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedSentence,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEnhancedSentence,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setEnhancedSentence,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.mergeEnhancedSentence,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.clearEnhancedSentence,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedSentenceOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getEnhancedSentenceFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSpeaker,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSpeaker,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSpeakerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSpeaker,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSpeakerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.hasSpeakerType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSpeakerType,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.getSpeakerTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSpeakerType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentence$Builder.setSpeakerTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoNLLUOutputter.print,11,14,28,28,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$1.aggregate,9,11,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.buildPartial,10,13,32,31,96.875,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.mergeFrom,10,14,23,23,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.hasOpenNode,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.getOpenNode,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.clearOpenNode,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.hasCloseNode,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.getCloseNode,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.clearCloseNode,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.getValue,9,12,23,15,65.21739130434783,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.getValueBytes,8,10,21,13,61.904761904761905,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.setValue,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.clearValue,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.setValueBytes,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$Builder.hasScore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$3.aggregate,9,11,16,11,68.75,0,0
@@ edu.stanford.nlp.pipeline.WebServiceAnnotator$RunningProcess.lambda$new$0,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.getDefaultExtension,12,20,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>,49,72,107,87,81.30841121495327,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.getRequiredProperty,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.loadPropertiesFromClasspath,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.loadPropertiesOrException,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.loadProperties,11,14,27,12,44.44444444444444,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.ensurePrerequisiteAnnotators,55,82,97,80,82.4742268041237,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.getDefaultAnnotatorPool,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.registerCustomAnnotators,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.constructAnnotatorPool,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.getExistingAnnotator,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.annotate,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.annotate,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.printHelp,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.timingInformation,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.shell,21,29,34,20,58.82352941176471,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.outputAnnotation,17,27,59,59,100.0,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.processFiles,38,55,109,89,81.65137614678899,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.run,21,29,55,46,83.63636363636363,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.main,7,9,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP.lambda$processFiles$39,23,34,51,51,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.buildPartial,10,13,37,28,75.67567567567568,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.mergeFrom,15,20,30,30,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.ensureTokenIndexIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.getTokenIndexList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.hasRoot,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.hasAssumedTruth,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SentenceFragment$Builder.hasScore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.buildPartial,6,7,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.mergeFrom,8,10,14,14,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.hasName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.getName,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.getNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.setName,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.setNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedNode$Builder.hasMatchIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.buildPartial,6,7,18,13,72.22222222222221,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.mergeFrom,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.isInitialized,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.hasF1,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse$Builder.hasKbestF1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.clear,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.buildPartial,9,11,34,26,76.47058823529412,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.mergeFrom,22,30,51,47,92.15686274509804,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.ensureSemgrexIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.setSemgrex,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.addSemgrex,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.addSemgrexBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.ensureQueryIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.getQueryList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.getQueryCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.getQuery,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.setQuery,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.setQuery,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.addQuery,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.addQuery,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.addQuery,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.addQuery,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.addAllQuery,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.clearQuery,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.removeQuery,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.getQueryOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.getQueryOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Builder.getQueryFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.AnnotationOutputter$Options.getKeysToPrint,7,8,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.<init>,36,62,609,89,14.614121510673234,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasBegin,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasSentenceBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasSentenceEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasTokenBegin,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasTokenEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasDocid,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getDocid,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getDocidBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasAuthor,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getAuthorBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasMention,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getMention,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getMentionBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasMentionBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasMentionEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getMentionType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasMentionSieve,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getMentionSieve,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getMentionSieveBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasSpeaker,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getSpeaker,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getSpeakerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasSpeakerSieve,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getSpeakerSieve,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getSpeakerSieveBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasCanonicalMention,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getCanonicalMention,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getCanonicalMentionBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasCanonicalMentionBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasCanonicalMentionEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hasAttributionDependencyGraph,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getAttributionDependencyGraph,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getAttributionDependencyGraphOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.isInitialized,9,12,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.writeTo,44,64,149,149,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.getSerializedSize,46,67,383,131,34.20365535248042,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.equals,113,178,227,227,100.0,0,8
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.hashCode,46,67,324,72,22.22222222222222,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Quote.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.<init>,81,130,985,130,13.19796954314721,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasText,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasDocID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.getDocID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.getDocIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasDocDate,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.getDocDate,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.getDocDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasCalendar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasHasEntityMentionsAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasXmlDoc,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasHasCorefMentionAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hasHasCorefAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.isInitialized,45,62,116,67,57.758620689655174,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.writeTo,48,65,190,150,78.94736842105263,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.getSerializedSize,50,68,344,138,40.116279069767444,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.equals,70,107,141,141,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.hashCode,40,58,252,63,25.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.SentenceAnnotator.annotate,29,40,36,32,88.88888888888889,0,5
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString.<init>,27,40,110,40,36.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString.isInitialized,6,7,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString.writeTo,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString.getSerializedSize,10,12,40,26,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString.equals,12,16,25,25,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString.hashCode,8,10,20,15,75.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType.initializeNameMap,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType.initializeClassMap,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator$TokenizerType.getTokenizerType,12,16,20,20,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$ConcatTextAggregator.aggregate,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$ConcatAggregator.aggregate,11,14,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString.<init>,21,30,73,30,41.0958904109589,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString.writeTo,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString.getSerializedSize,10,12,40,26,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString.equals,12,16,25,25,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.buildPartial,24,34,133,56,42.10526315789473,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.mergeFrom,26,37,70,50,71.42857142857143,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasHeadStart,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasHeadEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getMentionType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getMentionTypeBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setMentionType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasNormalizedName,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getNormalizedName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getNormalizedNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setNormalizedName,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setNormalizedNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasHeadTokenIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasCorefID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getCorefID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getCorefIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setCorefID,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setCorefIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasObjectID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getObjectID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getObjectIDBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setObjectID,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setObjectIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasExtentStart,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasExtentEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasType,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.hasSubtype,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getSubtype,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.getSubtypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setSubtype,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Entity$Builder.setSubtypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.<init>,18,26,56,33,58.92857142857143,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.hasChainID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.hasRepresentative,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.writeTo,9,11,30,26,86.66666666666667,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.getSerializedSize,11,14,40,26,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.equals,20,29,41,41,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest.<init>,21,30,74,31,41.891891891891895,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest.isInitialized,11,14,20,13,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest.writeTo,8,9,29,21,72.41379310344827,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest.getSerializedSize,10,12,39,25,64.1025641025641,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest.equals,12,16,25,25,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$FileHandler.<init>,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.computeExtraOptions,7,9,13,8,61.53846153846154,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.<init>,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.<init>,19,27,61,30,49.18032786885246,0,1
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.initFactory,20,30,55,29,52.72727272727272,0,1
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.setTokenBeginTokenEnd,5,5,2,1,50.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.setNewlineStatus,9,11,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.adjustFinalToken,10,14,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokenizerAnnotator.annotate,13,17,29,26,89.65517241379311,0,1
@@ edu.stanford.nlp.pipeline.GenericAnnotationSerializer.write,12,15,20,20,100.0,0,0
@@ edu.stanford.nlp.pipeline.GenericAnnotationSerializer.read,12,15,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation$Builder.buildPartial,6,7,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation$Builder.mergeFrom,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation$Builder.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokenLocation$Builder.hasTokenIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.POSTaggerAnnotator.<init>,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.pipeline.POSTaggerAnnotator.loadModel,6,7,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.pipeline.POSTaggerAnnotator.annotate,19,24,20,20,100.0,0,0
@@ edu.stanford.nlp.pipeline.POSTaggerAnnotator.doOneSentence,12,15,28,18,64.28571428571429,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse.<init>,16,22,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse.isInitialized,11,14,20,13,65.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse.equals,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.clear,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.mergeFrom,17,23,36,36,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.ensureMatchIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.getMatchList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.getMatchCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.getMatch,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.setMatch,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.setMatch,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.addMatch,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.addMatch,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.addMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.addMatch,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.addAllMatch,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.clearMatch,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.removeMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.getMatchOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.getMatchOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult$Builder.getMatchFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.WordsToSentencesAnnotator.<init>,21,28,42,33,78.57142857142857,0,1
@@ edu.stanford.nlp.pipeline.WordsToSentencesAnnotator.<init>,5,5,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.WordsToSentencesAnnotator.annotate,57,85,150,107,71.33333333333334,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.<init>,18,28,100,39,39.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hasName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.getName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.getNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hasQuantifierSpanBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hasQuantifierSpanEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hasSubjectSpanBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hasSubjectSpanEnd,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hasObjectSpanBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hasObjectSpanEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.isInitialized,20,28,26,26,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.writeTo,16,22,52,52,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.getSerializedSize,18,25,83,48,57.831325301204814,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.equals,43,66,87,87,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.hashCode,18,25,65,30,46.15384615384615,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Operator.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.DocDateAnnotator.<init>,14,18,35,35,100.0,0,0
@@ edu.stanford.nlp.pipeline.DocDateAnnotator.annotate,20,29,64,43,67.1875,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$ReadyHandler.handle,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.pipeline.LanguageInfo.main,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.pipeline.LanguageInfo.getLanguageFromString,26,41,40,40,100.0,0,1
@@ edu.stanford.nlp.pipeline.LanguageInfo.isStanfordCoreNLPSupportedLang,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.LanguageInfo.isSegmenterLanguage,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.buildPartial,11,14,32,30,93.75,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.mergeFrom,9,12,19,19,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.hasDocument,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.getDocument,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.setDocument,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.setDocument,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.mergeDocument,10,13,27,27,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.clearDocument,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.getDocumentOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.getDocumentFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.hasLanguage,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.getLanguage,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.setLanguage,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.clearLanguage,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.hasRelativePronouns,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.getRelativePronouns,9,12,23,15,65.21739130434783,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.getRelativePronounsBytes,8,10,21,13,61.904761904761905,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.setRelativePronouns,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.clearRelativePronouns,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyEnhancerRequest$Builder.setRelativePronounsBytes,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$ShutdownHandler.handle,7,9,15,10,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorImplementations.parse,11,15,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorImplementations.custom,4,4,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorImplementations.columnData,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorImplementations.dependencies,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotatorImplementations.quote,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult.<init>,16,22,44,27,61.36363636363637,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult.isInitialized,11,14,20,13,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult.equals,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$SemgrexResult.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.clear,8,9,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.buildPartial,14,18,55,38,69.0909090909091,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.mergeFrom,35,49,88,77,87.5,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.isInitialized,12,15,28,14,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.ensureNodeIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getNodeList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getNodeCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getNode,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.setNode,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.setNode,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addNode,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addNode,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addNode,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addNode,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addAllNode,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.clearNode,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.removeNode,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getNodeOrBuilder,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getNodeOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getNodeFieldBuilder,7,8,13,12,92.3076923076923,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.ensureEdgeIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getEdgeList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getEdgeCount,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getEdge,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.setEdge,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.setEdge,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addEdge,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addEdge,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addEdge,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addEdge,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.addAllEdge,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.clearEdge,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.removeEdge,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getEdgeOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getEdgeOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getEdgeFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.ensureRootIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Builder.getRootList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.buildPartial,10,13,37,23,62.16216216216216,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.mergeFrom,12,16,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.hasSentenceNum,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.hasTokenIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.hasDocID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$IndexedWord$Builder.hasCopyCount,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator.<init>,17,23,37,31,83.78378378378379,0,0
@@ edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator.annotate,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator.splitCharacters,71,107,212,94,44.339622641509436,0,2
@@ edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator.advancePos,10,12,24,12,50.0,0,0
@@ edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator.runSegmentation,42,61,156,95,60.89743589743589,0,1
@@ edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator.makeXmlToken,9,12,24,22,91.66666666666666,0,1
@@ edu.stanford.nlp.pipeline.AnnotationSerializer$IntermediateSemanticGraph.convertIntermediateGraph,29,42,86,64,74.4186046511628,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.buildPartial,6,7,24,17,70.83333333333334,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.mergeFrom,14,18,32,30,93.75,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.ensureKeyIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.getKeyList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.ensureValueIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.setValue,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.addValue,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapIntString$Builder.addValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.<init>,8,10,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.xmlFreeText,7,8,18,12,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.annotate,23,32,108,98,90.74074074074075,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.setAnnotations,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.countQuotes,7,8,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.getCoreMapQuotes,41,59,97,70,72.16494845360825,0,1
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.setQuoteIndices,18,24,30,18,60.0,0,1
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.makeQuote,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.recursiveQuotes,104,172,636,135,21.22641509433962,0,1
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.isAQuoteMapStarter,10,12,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.isSingleQuoteWithUse,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.matchesPrevQuote,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.isSingleQuoteStart,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.isSingleQuoteEnd,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.isDoubleQuoteEnd,14,20,22,22,100.0,0,1
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.requires,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.requirementsSatisfied,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuoteAnnotator.gatherQuotes,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.<init>,14,20,44,27,61.36363636363637,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.hasIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.hasCopyAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.writeTo,8,10,24,24,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.getSerializedSize,10,13,33,24,72.72727272727273,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.equals,23,34,47,47,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Node.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.InlineXMLOutputter.print,18,24,68,31,45.588235294117645,0,1
@@ edu.stanford.nlp.pipeline.StatTokSentAnnotator.<init>,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.StatTokSentAnnotator.setNewlineStatus,9,11,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.StatTokSentAnnotator.annotate,9,11,19,17,89.47368421052632,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.<init>,18,28,100,39,39.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getValue,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getValueBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hasAltValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getAltValue,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getAltValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hasType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hasTid,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getTid,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getTidBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hasBeginPoint,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hasEndPoint,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.writeTo,16,22,52,52,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.getSerializedSize,18,25,83,48,57.831325301204814,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.equals,43,66,87,87,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.hashCode,18,25,65,30,46.15384615384615,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Timex.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.clear,8,9,18,18,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.buildPartial,14,18,43,37,86.04651162790698,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.mergeFrom,21,29,44,44,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.hasSentence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.hasMatch,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getMatch,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.setMatch,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.setMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.mergeMatch,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.clearMatch,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getMatchOrBuilder,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getMatchFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.ensureGroupIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getGroupList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getGroupCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getGroup,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.setGroup,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.setGroup,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.addGroup,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.addGroup,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.addGroup,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.addGroup,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.addAllGroup,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.clearGroup,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.removeGroup,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getGroupOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getGroupOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Match$Builder.getGroupFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Node$ContentsCase.forNumber,7,10,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.ParserAnnotatorUtils.fillInParseAnnotations,15,20,33,30,90.9090909090909,0,0
@@ edu.stanford.nlp.pipeline.ParserAnnotatorUtils.setMissingTags,12,16,37,16,43.24324324324324,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TregexHandler.setTregexOffsets,8,11,17,17,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TregexHandler.handle,12,17,44,43,97.72727272727273,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TregexHandler.lambda$handle$7,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$TregexHandler.lambda$null$4,5,5,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.<init>,21,34,163,48,29.447852760736197,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasMentionID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasMentionType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getMentionType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getMentionTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasNumber,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getNumber,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getNumberBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getGender,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasAnimacy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getAnimacy,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getAnimacyBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasBeginIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasHeadIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hasPosition,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.writeTo,22,31,73,73,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.getSerializedSize,24,34,131,66,50.38167938931297,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.equals,58,90,117,117,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.hashCode,24,34,104,39,37.5,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$CorefMention.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse.<init>,16,22,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse.writeTo,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse.equals,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonResponse.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.HybridCorefAnnotator.<init>,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.HybridCorefAnnotator.annotate,8,10,16,16,100.0,0,0
@@ edu.stanford.nlp.pipeline.HybridCorefAnnotator.getLinks,13,16,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.HybridCorefAnnotator.annotateOldFormat,16,20,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.HybridCorefAnnotator.hasSpeakerAnnotations,10,12,2,2,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$ConcatCoreMapListAggregator.aggregate,13,18,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.<init>,10,13,20,20,100.0,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.setNamedEntityTagGranularity,12,15,17,8,47.05882352941176,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.findBestCoreferentEntityMention,17,22,23,19,82.6086956521739,0,1
@@ edu.stanford.nlp.pipeline.CorefAnnotator.annotate,13,17,22,22,100.0,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.getLinks,13,16,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.hasSpeakerAnnotations,10,12,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.requires,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.exactRequirements,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CorefAnnotator.lambda$findBestCoreferentEntityMention$0,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.buildPartial,6,7,16,11,68.75,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.mergeFrom,8,10,16,14,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.hasName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.getName,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.getNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.setName,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.setNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.hasReln,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.getReln,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.getRelnBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.setReln,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation$Builder.setRelnBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.build,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.buildPartial,16,22,71,36,50.70422535211267,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.mergeFrom,4,4,6,6,100.0,0,4
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.mergeFrom,18,25,33,33,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.isInitialized,16,22,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.hasProjectEquivalence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.getProjectEquivalence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.setProjectEquivalence,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.hasProjectForwardEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.getProjectForwardEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.setProjectForwardEntailment,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.hasProjectReverseEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.getProjectReverseEntailment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.setProjectReverseEntailment,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.hasProjectNegation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.getProjectNegation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.setProjectNegation,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.hasProjectAlternation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.getProjectAlternation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.setProjectAlternation,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.hasProjectCover,5,5,4,4,100.0,0,4
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.getProjectCover,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.setProjectCover,4,4,5,5,100.0,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.hasProjectIndependence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.getProjectIndependence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Polarity$Builder.setProjectIndependence,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.<init>,38,60,221,70,31.674208144796378,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hasCharBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hasCharEnd,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hasAuthor,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.getAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.getAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hasDatetime,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.getDatetime,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.getDatetimeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hasAuthorCharBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hasAuthorCharEnd,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hasXmlTag,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.getXmlTag,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.getXmlTagOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.isInitialized,19,26,32,25,78.125,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.writeTo,22,30,77,69,89.6103896103896,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.getSerializedSize,24,33,107,66,61.6822429906542,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.equals,47,72,95,95,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.hashCode,22,31,90,36,40.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationIterator.<init>,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationIterator.readNextDocument,18,27,54,50,92.5925925925926,0,0
@@ edu.stanford.nlp.pipeline.AnnotationIterator.close,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.<init>,17,24,48,30,62.5,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.hasTregex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.getTregex,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.getTregexBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.isInitialized,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.writeTo,7,8,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.getSerializedSize,9,11,30,21,70.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.equals,15,21,31,31,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Operation.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.AnnotationPipeline$1.next,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.SentimentAnnotator.<init>,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.SentimentAnnotator.doOneSentence,17,23,27,27,100.0,0,1
@@ edu.stanford.nlp.pipeline.JSONOutputter.writeTriples,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.writeTime,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.JSONOutputter.buildDependencyTree,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$writeTime$24,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$print$20,15,21,30,30,100.0,0,1
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$18,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$14,24,33,40,40,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$13,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$11,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$7,17,24,45,43,95.55555555555556,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$5,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$3,10,14,23,23,100.0,0,1
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$2,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$1,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.pipeline.JSONOutputter.lambda$null$0,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clear,23,29,65,65,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.buildPartial,151,221,1417,385,27.170077628793226,0,4
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeFrom,141,208,666,287,43.093093093093096,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.isInitialized,16,24,18,18,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasWord,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getWord,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getWordBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setWord,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setWordBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasPos,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getPos,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getPosBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setPos,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setPosBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getValue,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setValue,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasCategory,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getCategory,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getCategoryBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setCategory,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setCategoryBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasBefore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getBefore,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getBeforeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setBefore,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setBeforeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasAfter,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getAfter,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getAfterBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setAfter,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setAfterBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasOriginalText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getOriginalText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getOriginalTextBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setOriginalText,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setOriginalTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasNer,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNer,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNer,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasCoarseNER,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getCoarseNER,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getCoarseNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setCoarseNER,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setCoarseNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasFineGrainedNER,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getFineGrainedNER,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getFineGrainedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setFineGrainedNER,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setFineGrainedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.ensureNerLabelProbsIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNerLabelProbs,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.addNerLabelProbs,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.addNerLabelProbsBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasNormalizedNER,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNormalizedNER,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNormalizedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNormalizedNER,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNormalizedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasLemma,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getLemma,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getLemmaBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setLemma,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setLemmaBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasBeginChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasEndChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasUtterance,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSpeaker,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSpeaker,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSpeakerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSpeaker,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSpeakerBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSpeakerType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSpeakerType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSpeakerTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSpeakerType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSpeakerTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasBeginIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasTokenBeginIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasTokenEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasTimexValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getTimexValue,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setTimexValue,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setTimexValue,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeTimexValue,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clearTimexValue,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getTimexValueOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getTimexValueFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasHasXmlContext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.ensureXmlContextIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setXmlContext,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.addXmlContext,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.addXmlContextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasCorefClusterID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasAnswer,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getAnswer,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getAnswerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setAnswer,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setAnswerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasHeadWordIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasOperator,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getOperator,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setOperator,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setOperator,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeOperator,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clearOperator,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getOperatorOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getOperatorFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasPolarity,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getPolarity,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setPolarity,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setPolarity,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergePolarity,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clearPolarity,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getPolarityOrBuilder,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getPolarityFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasPolarityDir,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getPolarityDir,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getPolarityDirBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setPolarityDir,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setPolarityDirBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSpan,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSpan,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSpan,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSpan,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeSpan,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clearSpan,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSpanOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSpanFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSentiment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSentiment,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSentimentBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSentiment,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSentimentBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasQuotationIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasConllUFeatures,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUFeatures,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUFeatures,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUFeatures,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeConllUFeatures,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clearConllUFeatures,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUFeaturesOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUFeaturesFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasCoarseTag,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getCoarseTag,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getCoarseTagBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setCoarseTag,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setCoarseTagBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasConllUTokenSpan,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUTokenSpan,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUTokenSpan,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUTokenSpan,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeConllUTokenSpan,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clearConllUTokenSpan,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUTokenSpanOrBuilder,7,8,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUTokenSpanFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasConllUMisc,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUMisc,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUMiscBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUMisc,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUMiscBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasConllUSecondaryDeps,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUSecondaryDeps,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUSecondaryDeps,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setConllUSecondaryDeps,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.mergeConllUSecondaryDeps,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.clearConllUSecondaryDeps,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUSecondaryDepsOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getConllUSecondaryDepsFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasWikipediaEntity,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getWikipediaEntity,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getWikipediaEntityBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setWikipediaEntity,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setWikipediaEntityBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasIsNewline,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getGender,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setGender,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasTrueCase,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getTrueCase,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getTrueCaseBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setTrueCase,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setTrueCaseBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasTrueCaseText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getTrueCaseText,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getTrueCaseTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setTrueCaseText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setTrueCaseTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasChineseChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getChineseChar,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getChineseCharBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setChineseChar,4,4,5,5,100.0,0,4
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setChineseCharBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasChineseSeg,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getChineseSeg,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getChineseSegBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setChineseSeg,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setChineseSegBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasChineseXMLChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getChineseXMLChar,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getChineseXMLCharBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setChineseXMLChar,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setChineseXMLCharBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasArabicSeg,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getArabicSeg,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getArabicSegBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setArabicSeg,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setArabicSegBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSectionName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionName,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSectionAuthor,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionAuthor,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionAuthorBytes,4,4,5,5,100.0,0,6
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSectionDate,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionDate,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionDate,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasSectionEndLabel,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionEndLabel,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getSectionEndLabelBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionEndLabel,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setSectionEndLabelBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasParent,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getParent,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getParentBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setParent,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setParentBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.ensureCorefMentionIndexIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getCorefMentionIndexList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasEntityMentionIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasIsMWT,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasIsFirstMWT,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasMwtText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getMwtText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getMwtTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setMwtText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setMwtTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasNumericValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasNumericType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNumericType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNumericTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNumericType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNumericTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasNumericCompositeValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasNumericCompositeType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNumericCompositeType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.getNumericCompositeTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNumericCompositeType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.setNumericCompositeTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasCodepointOffsetBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.hasCodepointOffsetEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.MWTAnnotator.<init>,10,13,24,24,100.0,0,0
@@ edu.stanford.nlp.pipeline.MWTAnnotator.loadMultiWordTokenMappings,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.pipeline.MWTAnnotator.annotate,36,51,99,71,71.71717171717171,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.clear,5,5,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.buildPartial,11,14,36,30,83.33333333333334,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.mergeFrom,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.mergeFrom,21,29,44,44,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.hasChainID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.ensureMentionIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.getMentionList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.getMentionCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.getMention,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.setMention,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.setMention,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.addMention,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.addMention,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.addMention,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.addMention,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.addAllMention,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.clearMention,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.removeMention,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.getMentionOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.getMentionOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.getMentionFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$CorefChain$Builder.hasRepresentative,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentiment.forNumber,8,12,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Sentiment.valueOf,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.GenericWebServiceAnnotator.parseClasses,10,12,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.pipeline.GenericWebServiceAnnotator.annotateImpl,10,13,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.clear,8,9,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.buildPartial,12,15,41,33,80.48780487804879,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.mergeFrom,30,42,71,65,91.54929577464789,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.ensureOperationsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getOperationsList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getOperationsCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getOperations,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.setOperations,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.setOperations,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addOperations,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addOperations,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addOperations,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addOperations,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addAllOperations,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.clearOperations,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.removeOperations,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getOperationsOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getOperationsOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getOperationsFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.ensureTreesIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getTreesList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getTreesCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getTrees,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.setTrees,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.setTrees,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addTrees,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addTrees,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addTrees,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addTrees,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.addAllTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.clearTrees,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.removeTrees,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getTreesOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getTreesOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest$Builder.getTreesFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.<init>,13,18,35,24,68.57142857142857,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.hasF1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.hasKbestF1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.isInitialized,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.writeTo,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.getSerializedSize,8,10,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.equals,18,26,37,37,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.hashCode,8,10,20,15,75.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserResponse.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$SemgrexHandler.handle,12,17,44,43,97.72727272727273,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$SemgrexHandler.lambda$handle$6,22,31,46,46,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$SemgrexHandler.lambda$null$5,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$SemgrexHandler.lambda$null$3,8,10,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$SemgrexHandler.lambda$null$2,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.build,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.buildPartial,16,22,71,36,50.70422535211267,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.mergeFrom,18,25,34,34,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.isInitialized,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.hasSource,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.hasTarget,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.hasDep,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.getDep,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.getDepBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.setDep,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.setDepBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.hasIsExtra,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.hasSourceCopy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.hasTargetCopy,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.hasLanguage,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.getLanguage,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph$Edge$Builder.setLanguage,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.DefaultPaths.main,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.<init>,121,212,2794,285,10.200429491768075,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasWord,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getWord,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getWordBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasPos,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getPos,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getPosBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getValue,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasCategory,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getCategory,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getCategoryBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasBefore,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getBefore,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getBeforeBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasAfter,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getAfter,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getAfterBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasOriginalText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getOriginalText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getOriginalTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasNer,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNer,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasCoarseNER,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getCoarseNER,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getCoarseNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasFineGrainedNER,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getFineGrainedNER,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getFineGrainedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasNormalizedNER,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNormalizedNER,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNormalizedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasLemma,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getLemma,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getLemmaBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasBeginChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasEndChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasUtterance,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSpeaker,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSpeaker,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSpeakerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSpeakerType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSpeakerType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSpeakerTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasBeginIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasTokenBeginIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasTokenEndIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasTimexValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getTimexValue,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getTimexValueOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasHasXmlContext,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasCorefClusterID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasAnswer,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getAnswer,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getAnswerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasHeadWordIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasOperator,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getOperator,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getOperatorOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasPolarity,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getPolarity,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getPolarityOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasPolarityDir,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getPolarityDir,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getPolarityDirBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSpan,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSpan,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSpanOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSentiment,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSentiment,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSentimentBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasQuotationIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasConllUFeatures,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUFeatures,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUFeaturesOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasCoarseTag,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getCoarseTag,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getCoarseTagBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasConllUTokenSpan,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUTokenSpan,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUTokenSpanOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasConllUMisc,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUMisc,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUMiscBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasConllUSecondaryDeps,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUSecondaryDeps,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getConllUSecondaryDepsOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasWikipediaEntity,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getWikipediaEntity,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getWikipediaEntityBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasIsNewline,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getGender,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasTrueCase,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getTrueCase,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getTrueCaseBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasTrueCaseText,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getTrueCaseText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getTrueCaseTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasChineseChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getChineseChar,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getChineseCharBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasChineseSeg,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getChineseSeg,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getChineseSegBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasChineseXMLChar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getChineseXMLChar,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getChineseXMLCharBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasArabicSeg,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getArabicSeg,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getArabicSegBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSectionName,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSectionAuthor,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSectionDate,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionDate,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasSectionEndLabel,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionEndLabel,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSectionEndLabelBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasParent,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getParent,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getParentBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasEntityMentionIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasIsMWT,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasIsFirstMWT,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasMwtText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getMwtText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getMwtTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasNumericValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasNumericType,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNumericType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNumericTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasNumericCompositeValue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasNumericCompositeType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNumericCompositeType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getNumericCompositeTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasCodepointOffsetBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hasCodepointOffsetEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.isInitialized,20,30,28,28,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.writeTo,133,196,463,451,97.40820734341253,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.getSerializedSize,135,199,1192,398,33.38926174496644,0,2
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.equals,321,510,643,643,100.0,0,5
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.hashCode,132,196,2345,201,8.571428571428571,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Token.toBuilder,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Language.forNumber,14,24,23,23,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Language.valueOf,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph.<init>,32,48,160,48,30.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph.isInitialized,16,21,35,21,60.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph.writeTo,13,16,47,35,74.46808510638297,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph.getSerializedSize,15,19,62,35,56.451612903225815,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph.equals,14,19,29,29,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph.hashCode,10,13,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$DependencyGraph.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest.<init>,16,22,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest.isInitialized,11,14,20,13,65.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest.writeTo,5,5,16,12,75.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest.getSerializedSize,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest.equals,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest.hashCode,6,7,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.buildPartial,7,8,20,19,95.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.mergeFrom,17,23,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.ensureNodesIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.getNodesList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.getNodesCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.getNodes,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.setNodes,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.setNodes,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.addNodes,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.addNodes,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.addNodes,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.addNodes,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.addAllNodes,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.clearNodes,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.removeNodes,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.getNodesOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.getNodesOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$FlattenedParseTree$Builder.getNodesFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.TrueCaseAnnotator.<init>,10,13,23,23,100.0,0,1
@@ edu.stanford.nlp.pipeline.TrueCaseAnnotator.annotate,12,15,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.pipeline.TrueCaseAnnotator.setTrueCaseText,19,32,29,20,68.96551724137932,0,1
@@ edu.stanford.nlp.pipeline.TrueCaseAnnotator.loadMixedCaseMap,11,14,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.EPEOutputter.print,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.EPEOutputter.getNodes,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.EPEOutputter.getNodeIndex,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.EPEOutputter.lambda$null$5,7,8,19,19,100.0,0,0
@@ edu.stanford.nlp.pipeline.EPEOutputter.lambda$null$0,7,8,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.clear,5,5,11,9,81.81818181818183,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.buildPartial,21,29,90,55,61.111111111111114,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.mergeFrom,34,48,97,71,73.19587628865979,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.ensureArgNameIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setArgName,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.addArgName,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.addArgNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.ensureArgIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getArgList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getArgCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getArg,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setArg,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setArg,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.addArg,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.addArg,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.addArg,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.addArg,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.addAllArg,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.clearArg,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.removeArg,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getArgOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getArgOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getArgFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.hasSignature,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getSignature,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getSignatureBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setSignature,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setSignatureBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.hasObjectID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getObjectID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getObjectIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setObjectID,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setObjectIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.hasExtentStart,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.hasExtentEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.hasType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.hasSubtype,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getSubtype,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.getSubtypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setSubtype,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation$Builder.setSubtypeBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.<init>,27,42,134,49,36.56716417910448,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.hasSignature,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getSignature,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getSignatureBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.hasObjectID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getObjectID,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getObjectIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.hasExtentStart,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.hasExtentEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.hasType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.hasSubtype,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getSubtype,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getSubtypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.writeTo,20,27,71,63,88.73239436619718,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.getSerializedSize,22,30,98,61,62.244897959183675,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.equals,42,64,85,85,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.hashCode,20,28,77,33,42.857142857142854,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Relation.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.<init>,21,30,70,39,55.714285714285715,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.hasGraph,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.getGraph,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.getGraphOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.isInitialized,15,20,26,19,73.07692307692307,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.writeTo,7,8,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.getSerializedSize,9,11,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.equals,15,21,31,31,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.hashCode,8,10,20,15,75.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexRequest$Dependencies.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clear,26,33,86,62,72.09302325581395,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.buildPartial,62,87,384,170,44.27083333333333,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.mergeFrom,134,194,516,294,56.97674418604651,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.isInitialized,41,56,102,53,51.9607843137255,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getText,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureSentenceIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentenceList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentenceCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentence,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setSentence,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setSentence,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentence,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentence,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentence,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentence,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllSentence,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearSentence,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeSentence,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentenceOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentenceOrBuilderList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentenceFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureCorefChainIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCorefChainList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCorefChainCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCorefChain,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setCorefChain,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setCorefChain,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCorefChain,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCorefChain,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCorefChain,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCorefChain,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllCorefChain,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearCorefChain,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeCorefChain,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCorefChainOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCorefChainOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCorefChainFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasDocID,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getDocID,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getDocIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setDocID,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setDocIDBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasDocDate,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getDocDate,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getDocDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setDocDate,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setDocDateBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasCalendar,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureSentencelessTokenIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentencelessTokenList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentencelessTokenCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentencelessToken,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setSentencelessToken,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setSentencelessToken,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentencelessToken,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentencelessToken,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentencelessToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSentencelessToken,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllSentencelessToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearSentencelessToken,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeSentencelessToken,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentencelessTokenOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentencelessTokenOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSentencelessTokenFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureCharacterIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCharacterList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCharacterCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCharacter,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setCharacter,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setCharacter,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCharacter,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCharacter,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCharacter,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addCharacter,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllCharacter,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearCharacter,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeCharacter,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCharacterOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCharacterOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCharacterFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureQuoteIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getQuoteList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getQuoteCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getQuote,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setQuote,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setQuote,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addQuote,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addQuote,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addQuote,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addQuote,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllQuote,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearQuote,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeQuote,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getQuoteOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getQuoteOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getQuoteFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureMentionsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentions,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setMentions,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setMentions,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentions,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentions,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentions,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentions,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllMentions,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearMentions,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeMentions,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsOrBuilder,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasHasEntityMentionsAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasXmlDoc,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureSectionsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSectionsList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSectionsCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSections,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setSections,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setSections,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSections,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSections,7,8,15,15,100.0,0,3
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSections,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addSections,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllSections,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearSections,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeSections,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSectionsOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSectionsOrBuilderList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getSectionsFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureMentionsForCorefIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsForCorefList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsForCorefCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsForCoref,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setMentionsForCoref,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.setMentionsForCoref,5,5,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentionsForCoref,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentionsForCoref,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentionsForCoref,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addMentionsForCoref,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.addAllMentionsForCoref,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.clearMentionsForCoref,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.removeMentionsForCoref,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsForCorefOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsForCorefOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getMentionsForCorefFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasHasCorefMentionAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.hasHasCorefAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureCorefMentionToEntityMentionMappingsIsMutable,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getCorefMentionToEntityMentionMappingsList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.ensureEntityMentionToCorefMentionMappingsIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Document$Builder.getEntityMentionToCorefMentionMappingsList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest.<init>,21,30,75,32,42.66666666666667,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest.isInitialized,11,14,20,13,65.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest.writeTo,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest.getSerializedSize,10,12,37,22,59.45945945945946,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest.equals,12,16,25,25,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TsurgeonRequest.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator.<init>,15,20,32,26,81.25,0,0
@@ edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator.loadModel,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator.loadModel,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator.annotate,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.ArabicSegmenterAnnotator.doOneSentence,17,23,51,31,60.78431372549019,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.clear,8,9,18,18,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.buildPartial,12,15,35,32,91.42857142857143,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.mergeFrom,19,26,40,40,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.isInitialized,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.mergeFrom,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.hasGold,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getGold,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.setGold,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.setGold,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.mergeGold,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.clearGold,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getGoldOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getGoldFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.ensurePredictedIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getPredictedList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getPredictedCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getPredicted,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.setPredicted,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.setPredicted,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.addPredicted,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.addPredicted,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.addPredicted,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.addPredicted,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.addAllPredicted,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.clearPredicted,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.removePredicted,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getPredictedOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getPredictedOrBuilderList,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$EvaluateParserRequest$ParseResult$Builder.getPredictedFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.Annotation.<init>,10,12,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.MorphaAnnotator.annotate,12,15,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.MorphaAnnotator.addLemma,8,9,19,19,100.0,0,1
@@ edu.stanford.nlp.pipeline.MorphaAnnotator.phrasalVerb,15,22,24,24,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.buildPartial,6,7,25,17,68.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.mergeFrom,14,18,32,30,93.75,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.ensureKeyIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.setKey,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.addKey,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.addKeyBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.ensureValueIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.setValue,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.addValue,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$MapStringString$Builder.addValueBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLP$AnnotatorSignature.equals,11,15,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.clear,8,9,20,18,90.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.buildPartial,26,36,111,69,62.16216216216216,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.mergeFrom,36,51,88,75,85.22727272727273,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.isInitialized,15,20,22,15,68.18181818181817,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.hasCharBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.hasCharEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.hasAuthor,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getAuthor,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setAuthor,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setAuthorBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.ensureSentenceIndexesIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getSentenceIndexesList,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.hasDatetime,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getDatetime,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getDatetimeBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setDatetime,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setDatetimeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.ensureQuotesIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getQuotesList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getQuotesCount,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getQuotes,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setQuotes,7,8,15,15,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setQuotes,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.addQuotes,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.addQuotes,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.addQuotes,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.addQuotes,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.addAllQuotes,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.clearQuotes,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.removeQuotes,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getQuotesOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getQuotesOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getQuotesFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.hasAuthorCharBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.hasAuthorCharEnd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.hasXmlTag,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getXmlTag,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setXmlTag,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.setXmlTag,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.mergeXmlTag,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.clearXmlTag,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getXmlTagOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$Section$Builder.getXmlTagFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.<init>,21,30,69,38,55.072463768115945,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.hasDoc,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.getDoc,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.getDocOrBuilder,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.writeTo,7,8,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.getSerializedSize,9,11,29,20,68.96551724137932,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.equals,15,21,31,31,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexRequest.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.getProperties,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.<init>,39,53,100,79,79.0,0,1
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.annotate,14,18,21,21,100.0,0,1
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.createPatternMatcher,28,38,68,61,89.70588235294117,0,1
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.annotateMatched,20,27,69,56,81.15942028985508,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.checkPosTags,24,37,56,51,91.07142857142857,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.isLocationOrGpe,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.checkOrigNerTags,38,58,126,82,65.07936507936508,0,1
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.readEntries,11,14,31,26,83.87096774193549,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.getHeaderIndexMap,7,8,19,14,73.68421052631578,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.getIndex,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.readEntries,80,119,303,213,70.29702970297029,0,1
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.hasNoOverwritableType,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.processListMappingFiles,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.processPerFileOptions,47,71,101,68,67.32673267326733,0,1
@@ edu.stanford.nlp.pipeline.TokensRegexNERAnnotator.atLeastOneValidPosPattern,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.<init>,23,34,77,38,49.35064935064935,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.hasSpeakerName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.getSpeakerName,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.getSpeakerNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.isInitialized,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.writeTo,7,8,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.getSerializedSize,9,11,30,21,70.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.equals,15,21,31,31,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SpeakerInfo.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.buildPartial,7,8,20,19,95.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.mergeFrom,17,23,36,36,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.isInitialized,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.ensureMatchIsMutable,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.getMatchList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.getMatchCount,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.getMatch,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.setMatch,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.setMatch,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.addMatch,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.addMatch,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.addMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.addMatch,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.addAllMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.clearMatch,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.removeMatch,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.getMatchOrBuilder,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.getMatchOrBuilderList,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$TokensRegexResponse$Builder.getMatchFieldBuilder,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.<init>,13,18,35,24,68.57142857142857,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.hasName,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.getName,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.getNameBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.hasReln,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.getReln,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.getRelnBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.isInitialized,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.writeTo,6,7,17,17,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.getSerializedSize,8,10,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.equals,18,26,37,37,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.hashCode,8,10,20,15,75.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$SemgrexResponse$NamedRelation.toBuilder,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.loadDependencyGraph,32,45,68,58,85.29411764705883,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.saveDependencyGraph,28,40,50,43,86.0,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.saveCorefChains,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.countMentions,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.saveCorefChain,14,17,37,33,89.1891891891892,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.loadCorefChains,17,22,63,48,76.19047619047619,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.write,21,29,41,34,82.92682926829268,0,1
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.read,22,30,56,49,87.5,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.loadToken,21,31,42,42,100.0,0,0
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.saveToken,21,30,53,47,88.67924528301887,0,1
@@ edu.stanford.nlp.pipeline.CustomAnnotationSerializer.main,9,12,15,15,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuantifiableEntityNormalizingAnnotator.<init>,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuantifiableEntityNormalizingAnnotator.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuantifiableEntityNormalizingAnnotator.annotate,14,18,24,24,100.0,0,0
@@ edu.stanford.nlp.pipeline.QuantifiableEntityNormalizingAnnotator.annotateTokens,8,9,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer$2.checkCredentials,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreMapAttributeAggregator$8.aggregate,15,20,30,15,50.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPClient$Backend.equals,11,15,31,31,100.0,0,0
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.<init>,8,10,24,24,100.0,0,0
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.tokensForCharacters,11,15,16,16,100.0,0,0
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.annotatePronominalMentions,20,27,56,31,55.35714285714286,0,0
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.determineEntityMentionConfidences,21,28,26,26,100.0,0,1
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.annotate,45,65,87,79,90.80459770114942,0,4
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.addAcronyms,26,36,41,34,82.92682926829268,0,1
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.requires,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.lambda$overlapsWithMention$1,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.pipeline.EntityMentionsAnnotator.lambda$new$0,23,35,45,45,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.<init>,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.<init>,28,41,52,50,96.15384615384616,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.getURLParams,12,15,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.getDocument,23,33,36,25,69.44444444444444,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.mkStanfordCoreNLP,12,16,23,23,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.getProperties,33,50,83,54,65.06024096385542,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.parseSubnet,5,5,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.netMatch,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.onBlockList,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.onBlockList,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.maybeAlterStanfordTimeout,8,11,11,10,90.9090909090909,0,5
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.sendAndGetResponse,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.addSSLContext,9,12,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.livenessServer,7,8,18,16,88.88888888888889,0,1
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.run,9,11,37,30,81.08108108108108,0,2
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.launchServer,17,24,43,42,97.67441860465115,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.lambda$getProperties$6,6,7,4,4,100.0,0,3
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.lambda$mkStanfordCoreNLP$3,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.pipeline.StanfordCoreNLPServer.lambda$getDocument$2,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.maybeForceBuilderInitialization,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.clear,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.build,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.buildPartial,29,41,158,68,43.037974683544306,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.mergeFrom,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.mergeFrom,28,40,74,54,72.97297297297297,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.isInitialized,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.mergeFrom,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasSentenceIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasTokenStartInSentenceInclusive,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasTokenEndInSentenceExclusive,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasNer,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getNer,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getNerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setNer,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setNerBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasNormalizedNER,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getNormalizedNER,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getNormalizedNERBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setNormalizedNER,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setNormalizedNERBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasEntityType,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getEntityType,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getEntityTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setEntityType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setEntityTypeBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasTimex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getTimex,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setTimex,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setTimex,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.mergeTimex,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.clearTimex,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getTimexOrBuilder,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getTimexFieldBuilder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasWikipediaEntity,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getWikipediaEntity,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getWikipediaEntityBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setWikipediaEntity,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setWikipediaEntityBytes,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasGender,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getGender,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setGender,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setGenderBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasEntityMentionIndex,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasCanonicalEntityMentionIndex,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.hasEntityMentionText,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getEntityMentionText,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.getEntityMentionTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setEntityMentionText,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.CoreNLPProtos$NERMention$Builder.setEntityMentionTextBytes,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.DeterministicCorefAnnotator.<init>,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.pipeline.DeterministicCorefAnnotator.setNamedEntityTagGranularity,13,17,25,10,40.0,0,0
@@ edu.stanford.nlp.pipeline.DeterministicCorefAnnotator.annotate,19,26,49,42,85.71428571428571,0,1
@@ edu.stanford.nlp.pipeline.DeterministicCorefAnnotator.addObsoleteCoreferenceAnnotations,16,20,12,12,100.0,0,1
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.<init>,9,11,34,32,94.11764705882352,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.<init>,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.toCaseInsensitivePattern,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.addAnnotationPatterns,17,22,25,25,100.0,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.setTokenBeginTokenEnd,5,5,2,1,50.0,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.annotate,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.tokensToString,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.annotateWithTag,41,62,97,90,92.78350515463917,0,0
@@ edu.stanford.nlp.pipeline.CleanXmlAnnotator.process,173,269,591,388,65.65143824027074,0,3
@@ edu.stanford.nlp.pipeline.demo.StanfordCoreNlpDemo.main,35,48,76,34,44.73684210526316,0,0
@@ edu.stanford.nlp.pipeline.demo.StanfordCoreNlpDemoChinese.main,22,28,36,16,44.44444444444444,0,0
@@ edu.stanford.nlp.pipeline.webapp.CoreNLPServlet.doGet,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.pipeline.webapp.CoreNLPServlet.addResults,26,42,36,35,97.22222222222221,0,0
@@ edu.stanford.nlp.pipeline.webapp.CoreNLPServlet.outputVisualise,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.pipeline.webapp.CoreNLPServlet.outputPretty,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.pipeline.webapp.CoreNLPServlet.outputByWriter,9,11,20,11,55.00000000000001,0,0
@@ edu.stanford.nlp.net.Ports.available,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.net.Ports.findAvailable,7,8,15,6,40.0,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.<init>,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.ruleChanges,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.shouldSkip,10,15,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.findPreviousHead,19,29,42,32,76.19047619047619,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.postOperationFix,15,22,56,30,53.57142857142857,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.determineNonTrivialHead,68,106,177,122,68.92655367231639,0,1
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.isExistential,29,42,37,31,83.78378378378379,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.isWHQ,14,20,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.isVerbalAuxiliary,20,30,62,33,53.2258064516129,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.hasPassiveProgressiveAuxiliary,67,103,162,58,35.80246913580247,0,1
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.vpContainsParticiple,18,26,36,14,38.88888888888889,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.hasVerbalAuxiliary,13,17,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalSemanticHeadFinder.lambda$static$0,12,17,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.toSets,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.<init>,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.removeHeadsAssignedToPunc,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.langIndependentPuncCheck,7,8,16,9,56.25,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.convertStringEquality,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.normalizeNumbers,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.readDepsCoNLLX,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring.readDeps,23,32,72,19,26.38888888888889,0,1
@@ edu.stanford.nlp.trees.DependencyScoring.score,18,23,78,46,58.97435897435898,0,1
@@ edu.stanford.nlp.trees.DependencyScoring.main,11,14,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.trees.SplitTrainingSet.weightedIndex,7,8,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.trees.SplitTrainingSet.main,28,37,48,35,72.91666666666666,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructureFactory.newGrammaticalStructure,7,9,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer.cleanUpLabel,37,60,127,100,78.74015748031496,0,1
@@ edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer.includesEmptyNPSubj,14,20,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer.normalizeWholeTree,16,22,29,26,89.65517241379311,0,0
@@ edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer.addTMP9,25,39,64,28,43.75,0,1
@@ edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer.lambda$normalizeWholeTree$0,6,8,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.DiskTreebank$DiskTreebankIterator.<init>,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.DiskTreebank$DiskTreebankIterator.primeNextFile,10,14,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.DiskTreebank$DiskTreebankIterator.primeNextTree,9,13,25,9,36.0,0,0
@@ edu.stanford.nlp.trees.DiskTreebank$DiskTreebankIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.DiskTreebank$DiskTreebankIterator.next,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.trees.RecursiveTreeTransformer.transformHelper,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.RecursiveTreeTransformer.transformNonterminal,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.RecursiveTreeTransformer.transformLabel,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.WordCatEqualityChecker.areEqual,10,14,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.QPTreeTransformer.QPtransform,4,4,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.trees.QPTreeTransformer.main,10,12,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.UnnamedDependency.<init>,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.UnnamedDependency.<init>,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.UnnamedDependency.getText,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.UnnamedDependency.equalsIgnoreName,10,13,18,18,100.0,0,1
@@ edu.stanford.nlp.trees.UnnamedDependency.toString,10,15,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.FilteringTreebank.apply,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.WordStemmer.processTree,9,11,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.trees.WordStemmer.main,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring$Score.toStringAttachmentScore,7,8,26,26,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyScoring$Score.toStringFScore,6,7,28,28,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$LazyLoadTreesByParsing.iterator,5,5,12,10,83.33333333333334,0,1
@@ edu.stanford.nlp.trees.RightHeadFinder.determineHead,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.determineHead,17,24,35,35,100.0,0,1
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.determineNonTrivialHead,27,37,69,44,63.76811594202898,0,1
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.traverseLocate,32,53,58,36,62.06896551724138,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.findLeftHead,10,12,31,16,51.61290322580645,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.findLeftDisHead,10,12,31,17,54.83870967741935,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.findLeftExceptHead,12,15,35,17,48.57142857142857,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.findRightHead,10,12,30,15,50.0,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.findRightDisHead,10,12,29,15,51.724137931034484,0,0
@@ edu.stanford.nlp.trees.AbstractCollinsHeadFinder.findRightExceptHead,12,15,33,15,45.45454545454545,0,0
@@ edu.stanford.nlp.trees.NamedDependency.equals,10,13,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.NamedDependency.toString,10,15,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.MemoryTreebank.readSRLFile,7,8,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.trees.MemoryTreebank.processFile,38,52,94,62,65.95744680851064,0,0
@@ edu.stanford.nlp.trees.MemoryTreebank.load,9,11,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.MemoryTreebank.apply,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.MemoryTreebank.transform,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.correctDependencies,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.printListSorted,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.postProcessDependencies,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.getExtras,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.addStrandedPobj,39,56,74,48,64.86486486486487,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.correctWHAttachment,15,21,30,24,80.0,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.convertRel,42,62,78,66,84.61538461538461,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.filterKill,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapseDependencies,38,57,80,80,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.conjValue,12,19,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.treatCC,58,91,162,152,93.82716049382715,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.isDefinitelyActive,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapseConj,21,30,46,38,82.6086956521739,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapseReferent,20,28,34,34,100.0,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.addRef,41,61,95,46,48.421052631578945,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.addExtraNSubj,44,66,83,71,85.54216867469879,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.correctSubjPass,16,22,27,27,100.0,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.inConjDeps,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapsePrepAndPoss,186,288,456,380,83.33333333333334,0,3
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.determinePrepRelation,17,24,31,22,70.96774193548387,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.isConjWithNoPrep,10,14,13,13,100.0,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapse2WP,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapseMultiWordPrep,53,83,160,88,55.00000000000001,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapse2WPbis,48,73,132,74,56.060606060606055,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapse3WP,102,161,305,149,48.85245901639344,0,2
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.collapseFlatMWP,42,61,100,57,56.99999999999999,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.eraseMultiConj,17,26,37,37,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.removeDep,20,28,33,33,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure.lambda$collapseConj$0,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructureFactory.newGrammaticalStructure,7,9,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.TreeLeafLabelTransformer.transformTree,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.FilteringTreebank$FilteringTreebankIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.TreeFunctions$LabeledTreeToStringLabeledTreeFunction.helper,11,14,28,24,85.71428571428571,0,1
@@ edu.stanford.nlp.trees.OrderedCombinationTreeNormalizer.normalizeNonterminal,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.trees.OrderedCombinationTreeNormalizer.normalizeTerminal,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.trees.OrderedCombinationTreeNormalizer.normalizeWholeTree,5,5,5,2,40.0,0,1
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$LazyLoadTreesByParsing$1.hasNext,11,15,32,24,75.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$LazyLoadTreesByParsing$1.next,9,11,23,17,73.91304347826086,0,1
@@ edu.stanford.nlp.trees.TreeLemmatizer.transformTree,15,20,25,15,60.0,0,0
@@ edu.stanford.nlp.trees.TreeToBracketProcessor.allBrackets,18,28,32,32,100.0,0,0
@@ edu.stanford.nlp.trees.TreeToBracketProcessor.commonWordTagTypeBrackets,18,24,28,28,100.0,0,0
@@ edu.stanford.nlp.trees.GenerateTrees.readGrammar,12,16,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.GenerateTrees.produceTrees,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.GenerateTrees.produceTree,9,11,22,22,100.0,0,0
@@ edu.stanford.nlp.trees.GenerateTrees.main,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalFunctionTreeNormalizer.cleanUpLabel,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.<init>,15,20,55,41,74.54545454545455,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.indexLeaves,10,12,20,14,70.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.indexNodes,8,10,16,10,62.5,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.fromStringReps,20,27,49,49,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.attachStrandedNodes,16,23,39,39,100.0,0,1
@@ edu.stanford.nlp.trees.GrammaticalStructure.analyzeNode,23,34,55,55,100.0,0,1
@@ edu.stanford.nlp.trees.GrammaticalStructure.getDeps,24,34,51,37,72.54901960784314,0,1
@@ edu.stanford.nlp.trees.GrammaticalStructure.getTreeDeps,15,20,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.getGrammaticalRelation,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.getGrammaticalRelationCommonAncestor,16,22,42,25,59.523809523809526,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.removeGrammaticalRelationAncestors,14,18,30,17,56.666666666666664,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.typedDependencies,5,5,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.typedDependencies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.typedDependenciesCollapsed,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.typedDependenciesCCprocessed,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.isConnected,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.getRoots,11,14,15,15,100.0,0,1
@@ edu.stanford.nlp.trees.GrammaticalStructure.readCoNLLXGrammaticalStructureCollection,16,21,32,17,53.125,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure.buildCoNLLXGrammaticalStructure,24,32,67,46,68.65671641791045,0,0
@@ edu.stanford.nlp.trees.BasicCategoryTreeTransformer.transformNonterminalLabel,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyTreeTransformer.cleanUpRoot,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.DependencyTreeTransformer.cleanUpLabel,8,10,16,14,87.5,0,0
@@ edu.stanford.nlp.trees.DependencyTreeTransformer.stripTag,6,7,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.Span.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.BobChrisTreeNormalizer.cleanUpLabel,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.BobChrisTreeNormalizer.normalizeWholeTree,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.UnnamedConcreteDependency.<init>,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.UnnamedConcreteDependency.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.trees.UnnamedConcreteDependency.toString,10,15,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.CompositeTreebank.apply,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.CollinsDependency.<init>,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.trees.CollinsDependency.extractFromTree,41,60,80,67,83.75,0,1
@@ edu.stanford.nlp.trees.CollinsDependency.equals,11,15,31,31,100.0,0,1
@@ edu.stanford.nlp.trees.Dependencies.govToDepMap,7,8,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.trees.Dependencies.getGovMaxChains,15,20,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.Dependencies.getTypedDependencyChains,11,13,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.trees.TransformingTreebank$MyTreeTransformer.transformTree,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils.dependenciesToCoNLLXString,22,28,34,25,73.52941176470588,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils.dependenciesToString,30,40,54,47,87.03703703703704,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils.parseClassConstructArgs,4,4,7,5,71.42857142857143,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils.loadAlternateDependencyReader,9,11,18,8,44.44444444444444,0,1
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils.loadAlternateDependencyPrinter,9,11,18,8,44.44444444444444,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils.loadParser,12,17,28,14,50.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils.convertTrees,176,270,356,278,78.08988764044943,0,2
@@ edu.stanford.nlp.trees.TreeGraphNode.<init>,7,8,23,16,69.56521739130434,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.equals,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.setLabel,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.setChildren,13,17,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.setChildren,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.trees.TreeGraphNode.setChild,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.addChild,8,10,22,22,100.0,0,1
@@ edu.stanford.nlp.trees.TreeGraphNode.removeChild,8,9,25,13,52.0,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.percolateHeads,16,21,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.safeCast,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.highestNodeWithSameHead,6,7,13,7,53.84615384615385,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.treeFactory,5,5,5,3,60.0,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.toPrettyString,12,15,30,26,86.66666666666667,0,0
@@ edu.stanford.nlp.trees.TreeGraphNode.toOneLineString,9,11,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalStructure$ExtraTreeDepFilter.test,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure$ExtraTreeDepFilter.test,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalRelations.getConj,6,7,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalRelations.getNmod,12,16,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalRelations.getObl,12,16,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalRelations.getAdvcl,6,7,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalRelations.getAcl,8,10,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalRelations.valueOf,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.BobChrisTreeNormalizer$AOverAFilter.test,15,22,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure$NoPunctFilter.test,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.trees.CollinsRelation.toString,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.CollinsRelation.pad,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.CollinsRelation.equals,12,17,39,39,100.0,0,0
@@ edu.stanford.nlp.trees.CollinsRelation.hashCode,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$ConverterOptions.initializeNameMap,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$ConverterOptions.getConverterOptions,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.LengthTreeFilter.test,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.AbstractTreebankLanguagePack.postBasicCategoryIndex,12,17,38,13,34.21052631578947,0,0
@@ edu.stanford.nlp.trees.AbstractTreebankLanguagePack.basicCategory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.AbstractTreebankLanguagePack.stripGF,6,7,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.trees.AbstractTreebankLanguagePack.categoryAndFunction,7,8,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.trees.AbstractTreebankLanguagePack.lastIndexOfNumericTag,15,20,43,16,37.2093023255814,0,1
@@ edu.stanford.nlp.trees.AbstractTreebankLanguagePack.isLabelAnnotationIntroducingCharacter,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.AbstractTreebankLanguagePack.startSymbol,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.<init>,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.ruleChanges,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.shouldSkip,10,15,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.findPreviousHead,19,29,42,32,76.19047619047619,0,1
@@ edu.stanford.nlp.trees.SemanticHeadFinder.postOperationFix,15,22,56,30,53.57142857142857,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.determineNonTrivialHead,64,100,151,127,84.10596026490066,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.isExistential,29,42,37,31,83.78378378378379,0,1
@@ edu.stanford.nlp.trees.SemanticHeadFinder.isWHQ,14,20,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.isVerbalAuxiliary,20,30,62,33,53.2258064516129,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.hasPassiveProgressiveAuxiliary,67,103,162,58,35.80246913580247,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.vpContainsParticiple,18,26,36,14,38.88888888888889,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.hasVerbalAuxiliary,13,17,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.SemanticHeadFinder.lambda$static$0,12,17,15,15,100.0,0,2
@@ edu.stanford.nlp.trees.CompositeTreebank$CompositeTreebankIterator.hasNext,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.trees.CompositeTreebank$CompositeTreebankIterator.next,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.correctDependencies,10,13,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.printListSorted,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.postProcessDependencies,10,13,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.getExtras,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.addCaseMarkerInformation,43,62,74,57,77.02702702702703,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.addCaseMarkersToReln,11,14,32,11,34.375,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.expandPrepConjunctions,13,18,46,17,36.95652173913043,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.expandPrepConjunction,12,15,23,23,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.expandPPConjunctions,13,18,46,17,36.95652173913043,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.expandPPConjunction,14,18,36,36,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.getCaseMarkedRelation,12,16,36,16,44.44444444444444,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.addConjInformation,13,18,46,17,36.95652173913043,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.addConjToReln,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.correctWHAttachment,19,29,38,32,84.21052631578947,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.fixCCAttachment,18,25,30,21,70.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.convertRel,24,35,44,40,90.9090909090909,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.addEnhancements,34,53,82,82,100.0,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.collapseDependencies,8,10,16,16,100.0,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.conjValue,33,52,57,50,87.71929824561403,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.treatCC,60,95,166,156,93.97590361445783,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.isDefinitelyActive,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.collapseReferent,11,14,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.addRef,31,46,80,25,31.25,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.addExtraNSubj,42,64,89,77,86.51685393258427,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.correctSubjPass,17,23,47,32,68.08510638297872,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.processMultiwordPreps,9,11,27,16,59.25925925925925,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.processSimple2WP,20,28,34,28,82.35294117647058,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.processComplex2WP,38,54,93,70,75.26881720430107,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.process3WP,41,60,104,79,75.96153846153845,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.createMultiWordExpression,23,32,39,34,87.17948717948718,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.demoteQuantificationalModifiers,13,16,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.demoteQmodParentHelper,7,8,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.processNames,23,32,48,27,56.25,0,1
@@ edu.stanford.nlp.trees.UniversalEnglishGrammaticalStructure.processNamesHelper,34,47,87,82,94.25287356321839,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.valueOf,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.valueOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.valueOf,15,19,32,21,65.625,0,1
@@ edu.stanford.nlp.trees.GrammaticalRelation.isFromString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.<init>,16,22,29,28,96.55172413793103,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.getRelatedNodes,16,21,25,25,100.0,0,1
@@ edu.stanford.nlp.trees.GrammaticalRelation.isApplicable,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.toString,8,10,21,21,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.toPrettyString,8,9,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.equals,13,18,35,35,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.hashCode,11,13,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalRelation.readResolve,46,77,88,88,100.0,0,1
@@ edu.stanford.nlp.trees.GrammaticalRelation.main,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer$1.test,14,23,21,21,100.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.transformTree,36,53,95,95,100.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.rearrangeNowThat,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.changeSbarToPP,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.combineConjp,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.CoordinationTransformer.moveRB,7,8,8,5,62.5,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.SQflatten,8,11,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.UCPtransform,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.CCtransform,8,9,11,5,45.45454545454545,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.getHeadTag,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.transformCC,139,209,431,287,66.5893271461717,0,2
@@ edu.stanford.nlp.trees.CoordinationTransformer.notNP,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.trees.CoordinationTransformer.findCCparent,20,31,42,42,100.0,0,1
@@ edu.stanford.nlp.trees.CoordinationTransformer.MWETransform,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.trees.CoordinationTransformer.main,10,12,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.TransformingTreebank$TransformingTreebankIterator.next,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.trees.TransformingTreebank$MyTreeTransformer2.transformTree,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.CollinsHeadFinder.postOperationFix,12,18,34,23,67.64705882352942,0,0
@@ edu.stanford.nlp.trees.TransformingTreebank.apply,7,8,10,9,90.0,0,0
@@ edu.stanford.nlp.trees.Tree$TreeIterator.hasNext,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.trees.Tree$TreeIterator.next,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.trees.LeftHeadFinder.determineHead,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.DiskTreebank.loadPath,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.DiskTreebank.apply,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.trees.PennTreeReader.<init>,13,19,20,16,80.0,0,0
@@ edu.stanford.nlp.trees.PennTreeReader.readTree,11,16,34,20,58.82352941176471,0,0
@@ edu.stanford.nlp.trees.PennTreeReader.getTreeFromInputStream,42,61,121,79,65.28925619834712,0,1
@@ edu.stanford.nlp.trees.PennTreeReader.main,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.trees.TreeFunctions$LabeledTreeToCategoryWordTagTreeFunction.helper,11,14,28,24,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.LabeledScoredTreeNode.setChildren,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.LabeledScoredTreeNode.treeFactory,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.LabeledScoredTreeNode.nodeString,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.Constituent.toString,5,5,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.Constituent.equals,16,24,29,29,100.0,0,1
@@ edu.stanford.nlp.trees.Constituent.hashCode,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.Constituent.crosses,10,15,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.Constituent.crosses,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Constituent.contains,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.Constituent.value,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Constituent.setValue,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.trees.Constituent.setFromString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Constituent.toSentenceString,7,8,20,11,55.00000000000001,0,1
@@ edu.stanford.nlp.trees.Tree.isLeaf,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.isUnaryRewrite,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.isPreTerminal,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.isPrePreTerminal,9,11,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.isPhrasal,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.isBinary,11,15,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.isBinarized,13,18,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.equals,18,26,40,33,82.5,0,0
@@ edu.stanford.nlp.trees.Tree.hashCode,11,13,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.trees.Tree.objectIndexOf,7,8,18,9,50.0,0,0
@@ edu.stanford.nlp.trees.Tree.setChildren,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.firstChild,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.lastChild,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.upperMostUnary,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.getSpan,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.constituentsNodes,11,14,16,13,81.25,0,1
@@ edu.stanford.nlp.trees.Tree.constituents,15,21,35,30,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.Tree.localTree,5,5,15,11,73.33333333333333,0,1
@@ edu.stanford.nlp.trees.Tree.localTrees,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.updateBrackets,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.Tree.toStringBuilder,12,16,21,21,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.makeIndentString,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.trees.Tree.printLocalTree,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.indentedListPrint,9,11,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.indentedXMLPrint,19,25,34,34,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.displayChildren,8,10,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.trees.Tree.nodeString,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.trees.Tree.display,26,40,49,45,91.83673469387756,0,0
@@ edu.stanford.nlp.trees.Tree.spanString,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.depth,9,11,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.trees.Tree.depth,9,11,19,12,63.1578947368421,0,0
@@ edu.stanford.nlp.trees.Tree.headTerminal,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.headPreTerminal,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.percolateHeadAnnotations,20,27,30,30,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.percolateHeads,35,50,53,49,92.45283018867924,0,0
@@ edu.stanford.nlp.trees.Tree.makeDependencyLabel,17,25,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.dependencies,33,48,61,50,81.9672131147541,0,1
@@ edu.stanford.nlp.trees.Tree.mapDependencies,20,28,28,28,100.0,0,1
@@ edu.stanford.nlp.trees.Tree.mapDependencies,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.yield,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.yieldWords,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.yieldHasWord,14,18,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.yield,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.taggedYield,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.labeledYield,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.taggedLabeledYield,12,15,19,16,84.21052631578947,0,0
@@ edu.stanford.nlp.trees.Tree.preTerminalYield,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.getLeaves,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.labels,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.flatten,14,19,25,25,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.subTrees,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.deepCopy,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.treeSkeletonCopy,8,9,12,10,83.33333333333334,0,1
@@ edu.stanford.nlp.trees.Tree.treeSkeletonConstituentCopy,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.transform,8,9,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.Tree.spliceOut,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.spliceOutHelper,10,12,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.trees.Tree.prune,14,19,22,22,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.skipRoot,9,12,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.parentHelper,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.trees.Tree.ancestor,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.postOrderRecurse,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.preOrderRecurse,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.removeChild,8,9,25,13,52.0,0,0
@@ edu.stanford.nlp.trees.Tree.addChild,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.dominates,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.dominationPath,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.dominationPathHelper,9,11,23,18,78.26086956521739,0,1
@@ edu.stanford.nlp.trees.Tree.dominationPath,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.trees.Tree.pathNodeToNode,16,23,40,40,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.joinNode,17,25,39,37,94.87179487179486,0,0
@@ edu.stanford.nlp.trees.Tree.cCommands,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.siblings,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.insertDtr,10,12,37,22,59.45945945945946,0,0
@@ edu.stanford.nlp.trees.Tree.value,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.setValue,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.setFromString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.labelFactory,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.leftCharEdge,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.leftCharEdge,11,14,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.rightCharEdge,7,8,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.trees.Tree.rightCharEdge,11,14,25,18,72.0,0,1
@@ edu.stanford.nlp.trees.Tree.nodeNumber,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.nodeNumberHelper,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.getNodeNumberHelper,11,14,17,17,100.0,0,1
@@ edu.stanford.nlp.trees.Tree.indexLeaves,12,16,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.trees.Tree.percolateHeadIndices,14,19,25,14,56.00000000000001,0,0
@@ edu.stanford.nlp.trees.Tree.indexSpans,13,17,41,23,56.09756097560976,0,0
@@ edu.stanford.nlp.trees.Tree.lambda$pennPrint$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.Tree.lambda$toStringBuilder$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.DateTreeTransformer.transformTree,8,9,19,11,57.89473684210527,0,0
@@ edu.stanford.nlp.trees.TypedDependency.equals,21,31,55,55,100.0,0,0
@@ edu.stanford.nlp.trees.TypedDependency.hashCode,11,13,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.TypedDependency.compareTo,10,13,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.CompositeTreeTransformer.transformTree,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.trees.TreebankTagUpdater.tagTree,11,15,25,21,84.0,0,0
@@ edu.stanford.nlp.trees.TreebankTagUpdater.getTaggedLeaves,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.TreebankTagUpdater.main,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.trees.TransformingTreebank$MyTreeTransformer3.transformTree,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.TreeFunctions$LabeledToDescriptiveCoreLabelTreeFunction.apply,11,14,28,24,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.Dependencies$DependentPuncTagRejectFilter.test,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.TreeLengthComparator.compare,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructure$NoPunctTypedDependencyFilter.test,10,13,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.NPTmpRetainingTreeNormalizer$2.test,11,16,12,12,100.0,0,1
@@ edu.stanford.nlp.trees.Treebanks.main,105,156,2643,107,4.048429814604615,0,3
@@ edu.stanford.nlp.trees.Treebanks.printPunct,12,15,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.Treebanks.countTaggings,8,9,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.Treebanks.runTiming,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.trees.Treebanks.sentenceLengths,28,39,101,43,42.57425742574257,0,0
@@ edu.stanford.nlp.trees.Treebanks.lambda$countTaggings$6,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.Treebanks.lambda$main$5,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.Treebanks.lambda$main$3,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.Treebanks.lambda$main$2,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.Treebanks.lambda$main$1,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$TreeBankGrammaticalStructureWrapper$GsIterator.<init>,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$TreeBankGrammaticalStructureWrapper$GsIterator.primeGs,8,10,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$TreeBankGrammaticalStructureWrapper$GsIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.GrammaticalStructureConversionUtils$TreeBankGrammaticalStructureWrapper$GsIterator.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.Dependencies$DependentPuncWordRejectFilter.test,8,10,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.trees.CollocationFinder.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.CollocationFinder.getMangledTree,34,49,122,66,54.09836065573771,0,1
@@ edu.stanford.nlp.trees.CollocationFinder.printCollocationStrings,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.CollocationFinder.treeAsStemmedCollocation,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.CollocationFinder.treeAsNonStemmedCollocation,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.CollocationFinder.mergeLeavesIntoCollocatedString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.CollocationFinder.mergeLeavesIntoCollocatedString,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.CollocationFinder.getStemmedWordTagsFromTree,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.CollocationFinder.getNonStemmedWordTagsFromTree,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.OutputSubtrees.main,26,35,42,30,71.42857142857143,0,1
@@ edu.stanford.nlp.trees.EnglishGrammaticalRelations.getConj,6,7,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalRelations.getPrep,6,7,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalRelations.getPrepC,6,7,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.trees.EnglishGrammaticalRelations.valueOf,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.TreePrint.<init>,33,48,79,77,97.46835443037975,0,1
@@ edu.stanford.nlp.trees.TreePrint.printTree,14,19,26,26,100.0,0,1
@@ edu.stanford.nlp.trees.TreePrint.printTrees,18,24,37,36,97.2972972972973,0,0
@@ edu.stanford.nlp.trees.TreePrint.printTreeInternal,133,196,494,338,68.42105263157895,0,2
@@ edu.stanford.nlp.trees.TreePrint.getSortedDeps,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.TreePrint.getCollocationProcessedTree,7,8,13,5,38.46153846153847,0,1
@@ edu.stanford.nlp.trees.TreePrint.printHeader,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.TreePrint.printFooter,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.TreePrint.markHeadNodes,7,8,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.TreePrint.headMarkChildren,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.trees.TreePrint.main,24,32,49,23,46.93877551020408,0,0
@@ edu.stanford.nlp.trees.TreePrint.toString,11,16,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.TreePrint.toString,20,26,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.TreePrint.toReadableString,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.TreePrint.toXMLString,19,26,34,29,85.29411764705883,0,0
@@ edu.stanford.nlp.trees.TreePrint.lambda$printTreeInternal$0,9,11,10,9,90.0,0,0
@@ edu.stanford.nlp.trees.FindTreebankTree.main,40,59,137,50,36.496350364963504,0,1
@@ edu.stanford.nlp.trees.FindTreebankTree.lambda$main$0,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.SimpleTree.setChildren,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.fakeShortNameToGRel$1.equals,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.PennTreebankLanguagePack.grammaticalStructureFactory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.PennTreebankLanguagePack.grammaticalStructureFactory,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.PennTreebankLanguagePack.grammaticalStructureFactory,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.PennTreebankLanguagePack.typedDependencyHeadFinder,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.PennTreebankLanguagePack.main,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.TreeFilters$HasMatchingChild.test,16,21,23,23,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.height,7,8,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.trees.Trees.leftEdge,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.leftEdgeUnsafe,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.leftEdge,11,14,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.rightEdge,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.rightEdgeUnsafe,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.rightEdge,11,14,25,18,72.0,0,0
@@ edu.stanford.nlp.trees.Trees.leaves,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.preTerminals,7,8,6,6,100.0,0,1
@@ edu.stanford.nlp.trees.Trees.leafLabels,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.taggedLeafLabels,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.setLeafTagsIfUnset,11,14,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.setLeafLabels,10,13,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.maximalProjection,9,11,28,19,67.85714285714286,0,1
@@ edu.stanford.nlp.trees.Trees.applyToProjections,11,15,35,26,74.28571428571429,0,0
@@ edu.stanford.nlp.trees.Trees.getTerminal,13,17,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.getPreTerminal,13,17,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.localTreeAsCatList,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.trees.Trees.objectEqualityIndexOf,7,8,18,9,50.0,0,0
@@ edu.stanford.nlp.trees.Trees.toStructureDebugString,43,63,163,58,35.58282208588957,0,0
@@ edu.stanford.nlp.trees.Trees.toFlatTree,8,9,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.trees.Trees.treeToLatexHelper,12,15,36,26,72.22222222222221,0,1
@@ edu.stanford.nlp.trees.Trees.treeToLatexEvenHelper,19,27,79,60,75.9493670886076,0,0
@@ edu.stanford.nlp.trees.Trees.escape,9,11,20,15,75.0,0,0
@@ edu.stanford.nlp.trees.Trees.main,11,14,29,12,41.37931034482759,0,0
@@ edu.stanford.nlp.trees.Trees.normalizeTree,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.getLeaf,9,11,11,6,54.54545454545454,0,1
@@ edu.stanford.nlp.trees.Trees.getLowestCommonAncestor,17,22,35,15,42.857142857142854,0,1
@@ edu.stanford.nlp.trees.Trees.pathNodeToNode,21,28,52,31,59.61538461538461,0,1
@@ edu.stanford.nlp.trees.Trees.pathFromRoot,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.replaceNode,10,12,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.getLowestCommonAncestor,9,12,25,16,64.0,0,1
@@ edu.stanford.nlp.trees.Trees.outputTreeLabels,8,9,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.Trees.convertToCoreLabels,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.Trees.setSentIndex,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.UniversalPOSMapper.mapTree,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.BobChrisTreeNormalizer$EmptyFilter.test,9,13,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.fakeShortNameToGRel.containsKey,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.fakeShortNameToGRel.get,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.Treebank.decimate,10,12,16,7,43.75,0,0
@@ edu.stanford.nlp.trees.Treebank.textualSummary,96,144,262,137,52.29007633587786,0,2
@@ edu.stanford.nlp.trees.tregex.TregexPattern$TRegexTreeReaderFactory$1.normalizeNonterminal,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$24.satisfies,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$16$1.initialize,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$16$1.advance,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$8.satisfies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$19.satisfies,15,20,40,26,65.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$Heads$1.advance,7,9,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$20$1.initialize,8,10,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.trees.tregex.Relation.getRelation,27,43,36,32,88.88888888888889,0,0
@@ edu.stanford.nlp.trees.tregex.Relation.getRelation,25,43,24,18,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation.constructMultiRelation,7,8,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.trees.tregex.Relation.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$21$1.initialize,5,6,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryFollows$1.initializeHelper,19,26,87,28,32.18390804597701,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryFollows$1.advance,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$22.satisfies,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$6$1.advance,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$IthChildOf$1.initialize,10,16,46,46,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$17$1.initialize,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$17$1.advance,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$IthChildOf.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$IthChildOf.satisfies,10,14,30,30,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$IthChildOf.equals,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryDominates$1.initialize,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryDominates$1.advance,8,10,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.tregex.TokenMgrError.addEscapes,18,28,59,31,52.54237288135594,0,0
@@ edu.stanford.nlp.trees.tregex.TokenMgrError.LexicalErr,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$23$1.initialize,7,9,16,16,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$23$1.advance,7,9,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$HasIthChild.equals,13,18,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$HasIthChild.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$HasIthChild$1.initialize,6,7,14,14,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryPrecedes$1.initializeHelper,19,26,95,29,30.526315789473685,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryPrecedes$1.advance,5,5,7,7,100.0,0,2
@@ edu.stanford.nlp.trees.tregex.TregexPatternCompiler.compile,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryPrecedes.<init>,13,16,35,11,31.428571428571427,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryPrecedes.pathMatchesNode,9,11,21,20,95.23809523809523,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$4$1.initialize,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$4$1.advance,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$ImmediatelyHeads.satisfies,10,12,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$ImmediatelyHeads.equals,13,18,27,27,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$ImmediatelyHeads.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$ImmediatelyHeadedBy.equals,13,18,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$ImmediatelyHeadedBy.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$9.satisfies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$ImmediatelyHeads$1.initialize,8,10,25,25,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$15$1.advance,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$25.satisfies,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.TregexPattern$TRegexTreeVisitor.visitTree,48,71,114,98,85.96491228070175,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$21.satisfies,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$14$1.advance,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$22$1.initialize,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$23.satisfies,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$18$1.initialize,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$18$1.advance,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$12.satisfies,8,10,16,16,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$9$1.initialize,11,14,32,23,71.875,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$9$1.advance,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$11$1.initialize,11,14,32,23,71.875,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$11$1.advance,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.CoordinationPattern.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.CoordinationPattern.localString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.CoordinationPattern.toString,18,24,28,28,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$10.satisfies,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$1.satisfies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexPattern.negate,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexPattern.makeOptional,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexPattern.prettyPrint,12,15,23,19,82.6086956521739,0,1
@@ edu.stanford.nlp.trees.tregex.TregexPattern.extractSubtrees,10,12,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexPattern.main,63,91,193,142,73.57512953367875,0,1
@@ edu.stanford.nlp.trees.tregex.TregexPattern.getTreeReaderFactory,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$10$1.initialize,8,9,27,11,40.74074074074074,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$10$1.advance,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.resetChildIter,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.resetChild,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.goToNextTreeNodeMatch,56,85,202,129,63.86138613861386,0,1
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.commitVariableGroups,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.commitVariableGroups,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.decommitVariableGroups,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.removeNamedNodes,6,8,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.matchChild,11,15,34,28,82.35294117647058,0,1
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern$DescriptionMatcher.matches,14,19,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$19$1.initialize,8,10,31,21,67.74193548387096,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjStopStringLiteralDfa_0,20,29,25,25,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjMoveStringLiteralDfa0_0,23,42,63,63,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjMoveStringLiteralDfa1_0,6,8,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjMoveStringLiteralDfa2_0,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjMoveStringLiteralDfa3_0,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjMoveNfa_0,211,366,2671,395,14.788468738300262,0,4
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjFillToken,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjCanMove_0,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.getNextToken,17,23,57,48,84.21052631578947,0,2
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.jjCheckNAdd,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.ReInitRounds,5,5,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParserTokenManager.SwitchTo,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.ExpandBuff,5,5,24,24,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.FillBuff,16,22,78,56,71.7948717948718,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.UpdateLineColumn,12,17,38,28,73.68421052631578,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.readChar,8,10,30,29,96.66666666666667,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.backup,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.ReInit,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.ReInit,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.GetImage,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.GetSuffix,5,5,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.SimpleCharStream.adjustBeginLineColumn,15,20,101,63,62.37623762376238,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryFollows.<init>,13,16,35,11,31.428571428571427,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryFollows.pathMatchesNode,9,11,21,20,95.23809523809523,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$16.satisfies,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$8$1.initialize,8,9,29,12,41.37931034482759,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$8$1.advance,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.VariableStrings.isSet,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.VariableStrings.setVar,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.VariableStrings.unsetVar,6,7,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.VariableStrings.toString,8,9,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$12$1.advance,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryIsDominatedBy.equals,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$11.satisfies,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$HeadedBy.equals,13,18,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$HeadedBy.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryDominates.<init>,13,16,35,11,31.428571428571427,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryDominates.satisfies,10,13,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryDominates.pathMatchesNode,9,11,21,20,95.23809523809523,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryDominates.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryDominates.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$2.satisfies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern.<init>,59,83,175,130,74.28571428571429,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern.localString,11,13,16,16,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern.toString,18,25,50,50,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.DescriptionPattern.getChildren,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$13.satisfies,8,10,17,17,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.Root,10,13,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.Node,11,14,19,17,89.47368421052632,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.SubNode,27,37,57,45,78.94736842105263,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.ModDescription,16,20,31,27,87.09677419354838,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.Description,55,78,185,123,66.48648648648648,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.ChildrenDisj,10,13,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.ChildrenConj,19,25,30,28,93.33333333333333,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.ModChild,12,16,22,19,86.36363636363636,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.Child,12,16,21,18,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.Relation,101,141,289,202,69.8961937716263,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_2_1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_2_2,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Relation_277_3_25,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_SubNode_128_5_9,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Child_265_7_24,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Child_264_7_23,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Description_170_5_20,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3_2,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Child_263_5_22,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ModDescription_142_31_16,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Child_263_3_18,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_SubNode_119_3_8,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_SubNode_119_3_6,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ModChild_256_7_14,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Relation_305_3_27,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Description_157_5_19,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ModChild_249_7_13,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Description_157_3_17,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ModChild_248_5_12,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ModChild_248_3_10,6,8,10,10,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ModDescription_142_6_15,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Relation_278_9_29,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3_1,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Relation_277_9_28,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ModDescription_142_3_11,8,10,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Description_184_5_21,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_ChildrenConj_233_3_7,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_3R_Relation_277_5_26,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.ReInit,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.ReInit,13,16,41,28,68.29268292682927,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.ReInit,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_consume_token,16,21,72,46,63.888888888888886,0,1
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_scan_token,19,27,91,48,52.74725274725275,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.getNextToken,5,5,16,14,87.5,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.getToken,8,9,34,6,17.647058823529413,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_ntk_f,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_add_error_token,23,32,72,57,79.16666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.generateParseException,21,28,77,41,53.246753246753244,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_rescan_token,11,15,43,16,37.2093023255814,0,0
@@ edu.stanford.nlp.trees.tregex.TregexParser.jj_save,7,8,34,15,44.11764705882353,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$24$1.initialize,8,11,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$24$1.advance,8,11,17,17,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.ParseException.initialise,25,33,109,46,42.201834862385326,0,1
@@ edu.stanford.nlp.trees.tregex.ParseException.add_escapes,18,28,59,31,52.54237288135594,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$6.satisfies,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$25$1.advance,7,8,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$17.satisfies,12,16,32,22,68.75,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$13$1.advance,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$Heads.satisfies,13,17,25,24,96.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$Heads.equals,13,18,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$Heads.hashCode,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$4.satisfies,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.Relation$UnbrokenCategoryIsDominatedBy$1.advance,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Macros.readMacros,10,13,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.trees.tregex.Macros.addAllMacros,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Macros.addAllMacros,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$SearchNodeIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$SearchNodeIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$ImmediatelyHeadedBy$1.initialize,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.CoordinationPattern$CoordinationMatcher.resetChildIter,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.CoordinationPattern$CoordinationMatcher.resetChildIter,7,8,4,4,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.CoordinationPattern$CoordinationMatcher.matches,33,48,171,114,66.66666666666666,0,1
@@ edu.stanford.nlp.trees.tregex.CoordinationPattern$CoordinationMatcher.getMatch,9,13,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexMatcher.find,12,17,27,21,77.77777777777779,0,0
@@ edu.stanford.nlp.trees.tregex.TregexMatcher.findAt,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexMatcher.findNextMatchingNode,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexMatcher.getParent,8,10,20,14,70.0,0,0
@@ edu.stanford.nlp.trees.tregex.TregexMatcher.fillNodesToParents,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.Relation$HeadedBy$1.advance,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.RelabelNode$RelabelMatcher.evaluate,14,18,37,37,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonPattern.setRoot,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonPattern.toString,9,11,31,22,70.96774193548387,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.CoindexationGenerator.setLastIndex,8,10,10,9,90.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AdjoinToFootNode$Matcher.evaluate,6,7,20,20,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.PruneNode$Matcher.evaluate,10,12,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AdjoinNode.<init>,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.ProcessTsurgeonRequest.parseOperations,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.ProcessTsurgeonRequest.processRequest,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.ExciseNode$Matcher.evaluate,15,20,29,28,96.55172413793103,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TokenMgrError.addEscapes,18,28,59,31,52.54237288135594,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TokenMgrError.LexicalErr,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.ReplaceNode$Matcher.evaluate,9,11,35,31,88.57142857142857,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonPatternRoot$Matcher.evaluate,9,11,16,13,81.25,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonMatcher.<init>,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.CreateSubtreeNode$Matcher.evaluate,19,26,59,47,79.66101694915254,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.CreateSubtreeNode.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.CreateSubtreeNode.findFoot,6,7,17,17,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.RelabelNode.<init>,17,22,51,39,76.47058823529412,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.RelabelNode.removeEscapeSlashes,11,14,32,15,46.875,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.RelabelNode.toString,5,6,20,20,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.IfExistsNode$Matcher.evaluate,9,11,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TreeLocation$LocationMatcher.evaluate,16,24,30,26,86.66666666666667,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AdjoinNode$Matcher.evaluate,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonPatternRoot.matcher,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.ExpandBuff,5,5,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.FillBuff,16,22,78,56,71.7948717948718,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.UpdateLineColumn,12,17,38,28,73.68421052631578,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.readChar,8,10,30,29,96.66666666666667,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.backup,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.ReInit,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.ReInit,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.GetImage,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.GetSuffix,5,5,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleCharStream.adjustBeginLineColumn,15,20,101,63,62.37623762376238,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AuxiliaryTree.<init>,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AuxiliaryTree.copy,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AuxiliaryTree.copyHelper,16,21,52,39,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AuxiliaryTree.findFootNode,6,7,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AuxiliaryTree.findFootNodeHelper,13,17,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.AuxiliaryTree.initializeNamesNodesMaps,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleNode.jjtAddChild,6,7,21,19,90.47619047619048,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleNode.jjtGetNumChildren,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.SimpleNode.dump,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.IfExistsNode.<init>,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.InsertNode$Matcher.evaluate,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.ParseException.initialise,25,33,109,46,42.201834862385326,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.ParseException.add_escapes,18,28,59,31,52.54237288135594,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.PruneNode.pruneHelper,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.main,46,64,121,81,66.94214876033058,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.displayTree,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.getOperationFromReader,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.getTregexPatternFromReader,9,12,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.getTsurgeonOperationsFromReader,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.getTsurgeonTextFromReader,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.getOperationsFromReader,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.processPattern,7,8,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon.processPatternsOnTree,10,12,17,9,52.94117647058824,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.FetchNode$Matcher.evaluate,6,7,15,9,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.JJTTsurgeonParserState.popNode,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.JJTTsurgeonParserState.closeNodeScope,5,5,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.JJTTsurgeonParserState.closeNodeScope,8,9,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.CoindexNodes$Matcher.evaluate,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.Root,41,59,102,85,83.33333333333334,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.Operation,100,158,281,247,87.90035587188612,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.Location,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.NodeSelectionList,14,18,26,26,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.NodeSelection,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.NodeName,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.TreeList,14,18,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.TreeRoot,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.TreeNode,21,31,61,55,90.1639344262295,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.TreeDtrs,17,24,39,35,89.74358974358975,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_2,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_3,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_4,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_5,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_6,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_7,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_8,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_9,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_2_10,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeDtrs_271_3_15,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_NodeName_224_3_8,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeDtrs_269_3_14,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeDtrs_269_3_13,5,6,6,6,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_NodeSelection_215_3_4,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeNode_260_3_12,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_10,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeNode_258_3_11,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_9,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeNode_256_2_9,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeNode_256_2_10,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_8,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_7,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeRoot_246_3_7,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_2,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_6,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_1,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_5,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_4,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_Location_193_2_6,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3_3,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_3R_TreeList_234_2_5,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.ReInit,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.ReInit,13,16,42,29,69.04761904761905,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.<init>,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.ReInit,8,9,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_consume_token,16,21,72,46,63.888888888888886,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_scan_token,19,27,91,48,52.74725274725275,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.getNextToken,5,5,16,14,87.5,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.getToken,8,9,34,6,17.647058823529413,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_ntk_f,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_add_error_token,23,32,72,57,79.16666666666666,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.generateParseException,23,31,90,44,48.888888888888886,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_rescan_token,19,31,67,24,35.82089552238806,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParser.jj_save,7,8,34,15,44.11764705882353,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa0_2,13,22,32,32,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa1_2,12,19,31,31,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa2_2,17,28,49,49,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa3_2,14,22,39,39,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa4_2,15,24,41,41,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa5_2,19,29,39,39,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa6_2,17,28,37,37,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa7_2,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa8_2,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa9_2,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa10_2,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa11_2,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa12_2,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa0_0,7,10,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveNfa_0,280,486,3694,628,17.000541418516512,0,4
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveStringLiteralDfa0_1,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjMoveNfa_1,37,54,157,80,50.955414012738856,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjFillToken,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjCanMove_0,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.getNextToken,33,48,181,76,41.988950276243095,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.jjCheckNAdd,4,4,14,14,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.ReInitRounds,5,5,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.TsurgeonParserTokenManager.SwitchTo,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.tsurgeon.DeleteNode$Matcher.evaluate,7,8,10,8,80.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel$1.actionPerformed,6,7,23,23,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel$2.run,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel$4.maybeShowPopup,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel$FilenameMouseInputAdapter.mousePressed,11,14,25,25,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel$FilenameMouseInputAdapter.mouseDragged,11,15,27,27,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.OSXAdapter.handleAbout,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.OSXAdapter.handlePreferences,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.OSXAdapter.handleQuit,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.OSXAdapter.registerMacOSXApplication,6,7,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.gui.OSXAdapter.enablePrefs,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.getInstance,4,4,4,3,75.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.setMatch,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.addMatch,5,5,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.showPrevMatchedPart,6,7,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.showNextMatchedPart,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.doExportTree,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.getTreeJPanel,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.setFontSizeRepaint,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel.valueChanged,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI$2.run,6,7,9,3,33.33333333333333,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel$1.mousePressed,13,17,28,28,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel$1.addHighlight,10,13,40,40,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel$1.mouseDragged,11,15,26,26,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel$1.getCharOffset,6,7,18,12,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel$DisplayTransferHandler.exportString,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel$TRegexGUITreeVisitor.visitTree,9,11,26,12,46.15384615384615,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel$1.run,12,15,24,19,79.16666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel$3.run,11,14,25,25,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FilePanel.getInstance,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FilePanel.setActiveTreebanksFromParent,9,11,22,17,77.27272727272727,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI$1.run,8,10,12,3,25.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.Preferences.lookupHeadFinder,28,40,27,27,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.Preferences.lookupTreeReaderFactory,20,28,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.getInstance,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.getTreebankAsList,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.setMatches,38,55,81,68,83.9506172839506,0,1
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.getSelectedMatch,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.getMatches,5,5,12,8,66.66666666666666,0,1
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.getMatchedSentences,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.setMatchedParts,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel.valueChanged,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.ScrollableTreeJPanel.paintComponent,18,25,77,61,79.22077922077922,0,0
@@ edu.stanford.nlp.trees.tregex.gui.ScrollableTreeJPanel.renderRows,23,30,75,54,72.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.ScrollableTreeJPanel.doesOverlap,11,16,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.ScrollableTreeJPanel.paintTree,20,27,89,69,77.52808988764045,0,1
@@ edu.stanford.nlp.trees.tregex.gui.ScrollableTreeJPanel.getPreferredSize,6,7,17,17,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel$MatchCellRenderer.getListCellRendererComponent,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel$DisplayMouseMotionAdapter.mousePressed,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.DisplayMatchesPanel$DisplayMouseMotionAdapter.mouseDragged,8,11,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.HighlightUtils.addHighlight,6,7,16,14,87.5,0,0
@@ edu.stanford.nlp.trees.tregex.gui.HighlightUtils.isInHighlight,9,12,15,15,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.HighlightUtils.getCharOffset,6,7,18,12,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FilePanel$1.mouseClicked,13,18,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI$TransferActionListener.propertyChange,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI$TransferActionListener.actionPerformed,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.getInstance,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.enableTsurgeon,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.getHistoryString,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.addToHistoryList,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.useProgressBar,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.actionPerformed,24,34,77,77,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.stateChanged,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.showHistory,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.doRecent,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.setTregexState,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.setTsurgeonState,11,13,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.addRecentTregexPattern,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.setNumRecentPatterns,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.getMatchTreeVisitor,7,8,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.updateProgressBar,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.displayHelp,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.displayTsurgeonHelp,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.lambda$doError$4,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.lambda$returnToValidState$2,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.trees.tregex.gui.InputPanel.lambda$updateFoundStats$0,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeNode.<init>,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeNode.toString,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeNode.getDisplay,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeNode.isActive,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeNode.setActive,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeNode.sendToListeners,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeNode.getFilename,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.getMenu,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.setShortcutKeys,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.setSaveEnabled,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.setSaveHistoryEnabled,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.setTsurgeonEnabled,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.<init>,14,18,42,35,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.macOSXRegistration,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.loadPreferences,13,18,25,24,96.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.doLoadFiles,13,17,23,16,69.56521739130434,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.getFilters,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.doSaveFile,6,7,11,10,90.9090909090909,0,1
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.doSaveSentencesFile,6,7,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.doSaveHistory,6,7,11,10,90.9090909090909,0,1
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.loadTsurgeonScript,6,7,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.doPreferences,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.doTdiff,9,11,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.actionPerformed,30,43,92,92,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.matchesChanged,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.main,10,12,28,11,39.285714285714285,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TregexGUI.lambda$doFileFilters$0,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TreeFromFile.<init>,7,10,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TreeFromFile.getLabel,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.trees.tregex.gui.TreeFromFile.toString,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel.checkNumberFormat,7,9,10,9,90.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel.syncFromPrefPanel,11,13,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel.checkEncodingAndDisplay,12,17,28,16,57.14285714285714,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel.isChinese,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel.isArabic,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel.lambda$makeColorButton$4,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.PreferencesPanel.lambda$doEncodingPrompt$1,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.Tdiff.markDiff,13,17,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.Tdiff.main,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.MatchesPanel$TreeTransferHandler.exportString,11,14,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.fireTreeStructureChanged,7,8,9,4,44.44444444444444,0,1
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.getChild,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.getChildCount,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.getIndexOfChild,7,9,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.isLeaf,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.isEmpty,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.makeTreePathArray,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.addFileFolder,7,8,10,9,90.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.findLoadableFiles,16,22,30,30,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.addToMap,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.tregex.gui.FileTreeModel.checkFile,13,19,32,32,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.loadFeatureMap,14,18,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.getPOSFeatures,10,13,31,31,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.isOrdinal,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.isMultiplicative,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.getGraphFeatures,22,35,58,58,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.pronounCase,11,17,29,29,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.wasPerson,22,31,46,30,65.21739130434783,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.getRelAndIntPronFeatures,11,15,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.getImperatives,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.hasAux,8,11,23,23,100.0,0,1
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.hasTo,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.hasBeAux,10,13,17,17,100.0,0,1
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.addFeatures,23,33,43,38,88.37209302325581,0,1
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesFeatureAnnotator.main,26,35,54,36,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.ud.ProcessUniversalEnhancerRequest.enhanceDependencies,5,5,1,1,100.0,0,2
@@ edu.stanford.nlp.trees.ud.ProcessUniversalEnhancerRequest.enhanceEnglishDependencies,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.ud.ProcessUniversalEnhancerRequest.processRequest,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.ud.ProcessUniversalEnhancerRequest.getRelativePronouns,9,12,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.addRef,43,69,103,48,46.601941747572816,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.collapseReferent,17,23,28,25,89.28571428571429,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.addExtraNSubj,33,47,53,49,92.45283018867924,0,4
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.propagateConjuncts,65,103,152,150,98.68421052631578,0,1
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.addCaseMarkerInformation,11,14,17,9,52.94117647058824,0,1
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.addCaseMarkerForConjunctions,20,29,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.addCaseMarkersToReln,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.getCaseMarkedRelation,10,13,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.addConjInformation,13,18,46,17,36.95652173913043,0,1
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.addConjToReln,10,13,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalStructure.conjValue,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader.lambda$static$0,7,8,4,4,100.0,0,1
@@ edu.stanford.nlp.trees.ud.UniversalEnhancer.isEmptyNode,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalEnhancer.copyEmptyNodes,19,26,21,21,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalEnhancer.enhanceGraph,9,12,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalEnhancer.main,6,7,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer$ArgumentSequence.getAverageEmbeddings,7,8,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUTagUpdater.main,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader$WordProcessor.apply,9,11,17,17,100.0,0,6
@@ edu.stanford.nlp.trees.ud.UniversalGrammaticalRelations.getSpecificReln,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentWriter.printSemanticGraph,45,63,87,76,87.35632183908046,0,1
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentWriter.printSpan,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentWriter.printPOSAnnotations,13,16,30,17,56.666666666666664,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.coarsenUPOSTag,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.align,49,70,185,116,62.70270270270271,0,1
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.getConjGovOrphanGovPair,10,13,23,7,30.434782608695656,0,1
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.isArgument,9,11,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.isClausalArgument,9,11,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.getArgumentSubsequences,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.getFullConjunctArgumentsHelper,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.buildAllArgumentSequences,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.getFullConjunctArguments,10,12,14,7,50.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.getOrphanGovSequence,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.getGappedConjunctArguments,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.doEnhancement,48,68,137,108,78.83211678832117,0,1
@@ edu.stanford.nlp.trees.ud.UniversalGappingEnhancer.addEnhancements,15,20,38,22,57.89473684210527,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader$SentenceProcessor.getGovAndReln,8,9,16,12,75.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader$SentenceProcessor.getToken,7,8,16,11,68.75,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader$SentenceProcessor.apply,24,33,64,37,57.8125,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader$SentenceProcessor.lambda$apply$3,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader$SentenceProcessor.lambda$apply$2,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUDocumentReader$SentenceProcessor.lambda$apply$0,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUUtils.parseFeatures,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUUtils.toFeatureString,11,14,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUUtils.parseExtraDeps,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.ud.CoNLLUUtils.toExtraDepsString,11,14,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesConverter.convertTreeToBasic,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesConverter.addNERTags,8,11,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesConverter.addNERTags,8,11,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesConverter.main,21,28,35,25,71.42857142857143,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesConverter.lambda$addLemmata$1,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.ud.UniversalDependenciesConverter.lambda$addLemmata$0,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.TreebankPreprocessor.getDatasetClass,5,5,5,3,60.0,0,0
@@ edu.stanford.nlp.trees.treebank.TreebankPreprocessor.validateCommandLine,22,34,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.TreebankPreprocessor.main,32,45,53,53,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.DistributionPackage.make,10,12,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.DistributionPackage.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.PunctCountingTreeVisitor.countAnywhere,9,11,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.PunctCountingTreeVisitor.countFinal,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.trees.treebank.PunctCountingTreeVisitor.countNode,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.PunctCountingTreeVisitor.main,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.EnglishPTBTreebankCorrector.<init>,10,12,17,17,100.0,0,1
@@ edu.stanford.nlp.trees.treebank.EnglishPTBTreebankCorrector.transformTrees,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.EnglishPTBTreebankCorrector.continuing,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.DuplicateTreeStringFilter.test,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.AbstractDataset.setOptions,51,74,125,105,84.0,0,0
@@ edu.stanford.nlp.trees.treebank.AbstractDataset.buildSplitMap,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.ConfigParser.parse,27,38,85,51,60.0,0,0
@@ edu.stanford.nlp.trees.treebank.ConfigParser.toString,8,9,12,6,50.0,0,0
@@ edu.stanford.nlp.trees.treebank.ConfigParser.main,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.treebank.OntoNotesUDUpdater.main,14,18,36,11,30.555555555555557,0,0
@@ edu.stanford.nlp.trees.treebank.UselessTreeFilter.test,12,15,20,12,60.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.yylex,34,51,132,56,42.42424242424242,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraPennLexer.main,12,15,26,18,69.23076923076923,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLanguagePack.basicCategory,5,5,10,8,80.0,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraPennLanguagePack.stripGF,7,9,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennLanguagePack.containsKeptGF,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer.normalizeNonterminal,7,8,8,7,87.5,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer.fixNonUnaryRoot,7,9,20,18,90.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer.normalizeWholeTree,25,38,54,52,96.29629629629629,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer.insertNPinPPall,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer.insertNPinPP,13,18,65,35,53.84615384615385,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer.cleanUpLabel,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennTokenizer.main,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer$2.test,9,13,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.zzRefill,16,22,68,43,63.23529411764706,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.yyclose,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.yyreset,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.yylex,36,55,140,58,41.42857142857143,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraLexer.main,12,15,26,18,69.23076923076923,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraLabel.toString,6,7,17,12,70.58823529411765,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraHeadFinder.<init>,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraHeadFinder.findMarkedHead,9,12,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraHeadFinder.basicCategory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraHeadFinder.postBasicCategoryIndex,11,15,34,13,38.23529411764706,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraHeadFinder.isLabelAnnotationIntroducingCharacter,9,11,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraHeadFinder.determineNonTrivialHead,16,21,39,27,69.23076923076923,0,0
@@ edu.stanford.nlp.trees.international.negra.NegraLabel$NegraLabelFactory.newLabel,8,9,7,5,71.42857142857143,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeReaderFactory.newTreeReader,4,4,7,7,100.0,0,3
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeReaderFactory.main,7,8,9,9,100.0,0,1
@@ edu.stanford.nlp.trees.international.negra.NegraPennTreeNormalizer$1.test,9,14,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.hebrew.SplitMaker.main,13,17,34,19,55.88235294117647,0,4
@@ edu.stanford.nlp.trees.international.hebrew.HebrewTreeReaderFactory.main,7,8,15,12,80.0,0,2
@@ edu.stanford.nlp.trees.international.hebrew.HebrewTreeNormalizer.normalizeWholeTree,11,16,38,10,26.31578947368421,0,1
@@ edu.stanford.nlp.trees.international.hebrew.HebrewTreeNormalizer$HebrewEmptyFilter.test,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchTreeNormalizer.normalizeTerminal,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchTreeNormalizer.replacePOSTag,17,25,31,29,93.54838709677419,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchTreeNormalizer.normalizePreterminal,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchTreeNormalizer.normalizeWholeTree,24,36,63,35,55.55555555555556,0,1
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.close,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.readTree,10,14,35,23,65.71428571428571,0,1
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.getPOS,12,15,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.getLemma,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.getMorph,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.getSubcat,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.getWordString,13,18,27,16,59.25925925925925,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.getTreeFromXML,55,81,149,114,76.51006711409396,0,1
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.postProcessMWE,5,5,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchXMLTreeReader.main,18,23,29,23,79.3103448275862,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchTreeNormalizer$1.test,6,8,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.french.FrenchTreeNormalizer$FrenchAOverAFilter.test,13,19,14,14,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.<init>,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.normalizeWholeTree,19,27,44,38,86.36363636363636,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.normalizeTerminal,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.simplifyPOSTag,23,35,33,31,93.93939393939394,0,1
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.expandCliticPronounsInner,22,30,53,33,62.264150943396224,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.isMultiWordCandidate,10,12,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.normalizeForMultiWord,23,31,54,40,74.07407407407408,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.getMultiWords,24,36,63,59,93.65079365079364,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.shouldDropWord,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.expandConmigo,13,17,25,13,52.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.compilePatterns,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer.lambda$static$0,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishTreeNormalizer$1.transformTree,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.close,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.readTree,10,14,37,25,67.56756756756756,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.isWordNode,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.getPOS,88,138,118,114,96.61016949152543,0,1
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.getWord,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.getTreeFromXML,17,22,35,23,65.71428571428571,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.buildWordNode,9,12,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.buildEllipticNode,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.buildConstituentNode,7,9,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.shouldPrintTree,11,16,15,15,100.0,0,2
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.toString,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.process,7,8,23,17,73.91304347826086,0,0
@@ edu.stanford.nlp.trees.international.spanish.SpanishXMLTreeReader.main,17,22,24,24,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ArabicTreebankLanguagePack.main,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.trees.international.arabic.ArabicTreebankTokenizer.main,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ATBEscaper.apply,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ArabicHeadFinder$TagSet.tagSet,10,15,3,3,100.0,0,1
@@ edu.stanford.nlp.trees.international.arabic.ArabicTreeNormalizer.normalizeNonterminal,21,33,50,44,88.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ArabicTreeNormalizer.normalizeWholeTree,55,83,167,112,67.06586826347305,0,1
@@ edu.stanford.nlp.trees.international.arabic.ArabicTreeReaderFactory$XFilter.test,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ATBTreeUtils.escape,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ATBTreeUtils.unEscape,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ATBTreeUtils.taggedStringFromTree,8,9,5,5,100.0,0,1
@@ edu.stanford.nlp.trees.international.arabic.ArabicTreeNormalizer$ArabicEmptyFilter.test,13,21,18,18,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ArabicUtils.normalize,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.trees.international.arabic.ArabicUtils.main,6,7,7,7,100.0,0,1
@@ edu.stanford.nlp.trees.international.arabic.ArabicHeadFinder.findMarkedHead,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.international.arabic.ArabicTreeReaderFactory.newTreeReader,7,8,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZHeadFinder.<init>,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZHeadFinder.findMarkedHead,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZHeadFinder.basicCategory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZHeadFinder.postBasicCategoryIndex,11,15,34,13,38.23529411764706,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZHeadFinder.isLabelAnnotationIntroducingCharacter,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZHeadFinder.determineNonTrivialHead,14,18,32,21,65.625,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZPennTreeNormalizer.cleanUpLabel,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZPennTreeNormalizer.normalizeWholeTree,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZLanguagePack.basicCategory,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZLanguagePack.stripGF,8,11,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZLanguagePack.containsKeptGF,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.tuebadz.TueBaDZLanguagePack.main,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.isNumber,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.normalize,7,10,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.normalizeBMP,49,82,164,62,37.80487804878049,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.normalizeUnicode,43,73,149,55,36.91275167785235,0,2
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.isMidDot,12,19,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.isAsciiLowHigh,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.main,12,15,25,21,84.0,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseUtils.shapeOf,23,33,47,38,80.85106382978722,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.getFirstTranslation,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.normalize,7,8,10,7,70.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.normalize,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.readCEDict,17,24,43,39,90.69767441860465,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.isDigits,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.getReverseMap,11,13,9,9,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.addMap,15,20,29,20,68.96551724137932,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEnglishWordMap.main,33,44,73,58,79.45205479452055,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CEDict.path,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.TraditionalSimplifiedCharacterMap.init,16,24,41,41,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.TraditionalSimplifiedCharacterMap.apply,8,9,24,19,79.16666666666666,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.reportError,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBLexer.yylex,32,47,120,50,41.66666666666667,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseTreebankLanguagePack.getTokenizerFactory,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseTreebankLanguagePack.isPunctuationWord,12,19,16,16,100.0,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseTreebankLanguagePack.grammaticalStructureFactory,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseTreebankLanguagePack.grammaticalStructureFactory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseTreebankLanguagePack.grammaticalStructureFactory,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseTreebankLanguagePack.typedDependencyHeadFinder,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.FragmentTreeFilter.test,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseGrammaticalStructure.collapsePrepAndPoss,32,46,59,58,98.30508474576271,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseGrammaticalStructure.main,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CTBTreeReaderFactory.newTreeReader,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CTBErrorCorrectingTreeNormalizer.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CTBErrorCorrectingTreeNormalizer.cleanUpLabel,13,19,33,30,90.9090909090909,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.CTBErrorCorrectingTreeNormalizer.normalizeWholeTree,78,116,159,127,79.87421383647799,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.CTBErrorCorrectingTreeNormalizer$ChineseEmptyFilter.test,11,17,16,16,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.UniversalChineseGrammaticalStructure.collapsePrepAndPoss,32,46,59,58,98.30508474576271,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.UniversalChineseGrammaticalStructure.main,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CHTBTokenizer.main,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.UniversalChineseGrammaticalStructureFactory.newGrammaticalStructure,7,9,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.FragDiscardingPennTreeReader.readTree,6,7,11,3,27.27272727272727,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CharacterLevelTagExtender.transformTree,17,22,52,31,59.61538461538461,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CharacterLevelTagExtender.untransformTree,11,14,28,20,71.42857142857143,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.CharacterLevelTagExtender.testTransAndUntrans,7,8,8,8,100.0,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.CharacterLevelTagExtender.main,9,11,17,17,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseGrammaticalStructureFactory.newGrammaticalStructure,7,9,20,20,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.RadicalMap.getRadical,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.RadicalMap.main,33,46,74,60,81.08108108108108,0,0
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseCollinizer.transformTree,22,33,58,53,91.37931034482759,0,1
@@ edu.stanford.nlp.trees.international.pennchinese.ChineseEscaper.apply,7,8,8,7,87.5,0,1
@@ edu.stanford.nlp.classify.LogisticObjectiveFunction.calculate,19,24,71,37,52.112676056338024,0,0
@@ edu.stanford.nlp.classify.LogisticObjectiveFunction.calculateRVF,17,21,83,41,49.39759036144578,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifier.logProbabilityOf,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifier.logProbabilityOf,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.ClassifierExample.makeStopLights,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.to2D,8,9,26,16,61.53846153846154,0,1
@@ edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.calculate,30,39,127,82,64.56692913385827,0,1
@@ edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.updateDerivative,15,19,53,29,54.71698113207547,0,0
@@ edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.valueOfFeature,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.computeEmpiricalStatistics,24,31,74,54,72.97297297297297,0,0
@@ edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.smoothDistribution,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.getModelProbs,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.classify.LinearClassifierFactory$5.create,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.classify.LogisticUtils.identityMatrix,5,5,10,6,60.0,0,1
@@ edu.stanford.nlp.classify.LogisticUtils.flatten,11,13,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.unflatten,8,9,26,12,46.15384615384615,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.dotProduct,8,9,23,10,43.47826086956522,0,1
@@ edu.stanford.nlp.classify.LogisticUtils.initializeDataValues,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.indicesOf,5,5,5,4,80.0,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.convertToArray,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.calculateSums,8,9,24,16,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.calculateSums,8,9,25,17,68.0,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.sample,7,8,26,13,50.0,0,0
@@ edu.stanford.nlp.classify.LogisticUtils.prettyPrint,7,8,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$7.create,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.classify.OneVsAllClassifier.classOf,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.OneVsAllClassifier.scoresOf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.OneVsAllClassifier.train,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.getFeatureCounts,8,9,26,15,57.692307692307686,0,1
@@ edu.stanford.nlp.classify.GeneralDataset.applyFeatureCountThreshold,19,24,104,57,54.807692307692314,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.retainFeatures,19,24,100,57,56.99999999999999,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.applyFeatureMaxCountThreshold,19,24,104,57,54.807692307692314,0,1
@@ edu.stanford.nlp.classify.GeneralDataset.numFeatureTokens,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.addAll,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.classify.GeneralDataset.splitOutFold,9,13,27,26,96.29629629629629,0,3
@@ edu.stanford.nlp.classify.GeneralDataset.randomize,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.shuffleWithSideInformation,7,8,20,16,80.0,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.sampleDataset,17,22,37,23,62.16216216216216,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.mapDataset,8,9,27,19,70.37037037037037,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.mapDatum,6,7,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.mapDataset,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.makeSvmLabelMap,8,9,13,7,53.84615384615385,0,1
@@ edu.stanford.nlp.classify.GeneralDataset.printSVMLightFormat,11,13,27,21,77.77777777777779,0,0
@@ edu.stanford.nlp.classify.GeneralDataset.numDatumsPerLabel,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.GeneralDataset$1.hasNext,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.GeneralDataset$1.next,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$3.create,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction$RVFDerivativeCalculation.run,24,31,134,95,70.8955223880597,0,0
@@ edu.stanford.nlp.classify.LogPrior.getType,12,16,16,16,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.intToType,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.<init>,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.<init>,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.LogPrior.getSigma,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.getSigmaSquared,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.classify.LogPrior.getSigmaSquaredM,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.getEpsilon,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.setSigma,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.classify.LogPrior.setSigmaSquared,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.setSigmaSquaredM,9,11,31,27,87.09677419354838,0,0
@@ edu.stanford.nlp.classify.LogPrior.setEpsilon,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.LogPrior.computeStochastic,9,11,38,34,89.47368421052632,0,0
@@ edu.stanford.nlp.classify.LogPrior.compute,33,47,171,108,63.1578947368421,0,0
@@ edu.stanford.nlp.classify.WeightedDataset.getFeatureCounts,8,9,27,16,59.25925925925925,0,1
@@ edu.stanford.nlp.classify.WeightedDataset.ensureSize,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.classify.WeightedDataset.randomize,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.WeightedDataset.shuffleWithSideInformation,7,8,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.classify.KNNClassifierFactory.train,8,9,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.classify.KNNClassifierFactory.train,11,13,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$6.create,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.CrossValidator$CrossValidationIterator.hasNext,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.CrossValidator$CrossValidationIterator.next,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeDatumFromStrings,13,17,53,41,77.35849056603774,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.isRealValued,9,13,18,18,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeRVFDatumFromStrings,11,14,49,33,67.3469387755102,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.readAndReturnTrainingExamples,6,7,25,25,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeSVMLightLineInfos,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.readDataset,43,64,143,94,65.73426573426573,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.splitLineToFields,10,13,33,19,57.57575757575758,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.writeResultsSummary,37,51,116,106,91.37931034482759,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.writeAnswer,21,27,57,45,78.94736842105263,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.updatePerformanceStatistics,24,33,86,86,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.finishRanking,17,22,29,27,93.10344827586206,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.testExamples,17,24,79,74,93.67088607594937,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.testExample,29,41,127,95,74.80314960629921,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.formatCsv,23,32,65,50,76.92307692307693,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeDatum,12,15,47,43,91.48936170212765,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeRVFDatum,12,15,47,43,91.48936170212765,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.addAllInterningAndPrefixingRVF,12,16,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.addAllInterningAndPrefixing,12,16,21,16,76.19047619047619,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.addFeatureValue,17,23,32,32,100.0,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.addFeature,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeDatum,175,259,779,369,47.368421052631575,0,10
@@ edu.stanford.nlp.classify.ColumnDataClassifier.ptbTokenize,7,8,20,15,75.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.intern,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeNGramFeatures,30,43,132,63,47.72727272727273,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.newFeaturePrinter,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.printFeatures,12,15,21,13,61.904761904761905,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.printFeatures,12,15,20,12,60.0,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeClassifierAdaptL1,25,36,143,121,84.61538461538461,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.makeClassifier,25,34,124,110,88.70967741935483,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.regexpTokenize,13,17,50,13,26.0,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.splitTokenize,10,13,16,15,93.75,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.loadWordVectors,17,23,44,28,63.63636363636363,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.setProperties,273,409,1329,170,12.791572610985705,0,9
@@ edu.stanford.nlp.classify.ColumnDataClassifier.loadClassifier,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.loadClassifier,5,6,6,6,100.0,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.main,13,20,43,43,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.trainClassifier,27,38,115,85,73.91304347826086,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.printClassifier,8,9,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.testClassifier,6,7,20,20,100.0,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.crossValidate,7,8,39,23,58.97435897435898,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.classOf,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.classify.ColumnDataClassifier.scoresOf,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.ColumnDataClassifier.getClassifier,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.AdaptedGaussianPriorObjectiveFunction.calculate,5,5,8,8,100.0,0,1
@@ edu.stanford.nlp.classify.AdaptedGaussianPriorObjectiveFunction.calculateCL,31,41,133,95,71.42857142857143,0,0
@@ edu.stanford.nlp.classify.AdaptedGaussianPriorObjectiveFunction.to1D,8,9,26,16,61.53846153846154,0,0
@@ edu.stanford.nlp.classify.RVFDataset.scaleFeaturesGaussian,31,40,133,77,57.89473684210527,0,1
@@ edu.stanford.nlp.classify.RVFDataset.scaleFeatures,27,36,151,81,53.64238410596026,0,1
@@ edu.stanford.nlp.classify.RVFDataset.ensureRealValues,12,15,54,21,38.88888888888889,0,0
@@ edu.stanford.nlp.classify.RVFDataset.scaleDataset,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.RVFDataset.scaleDatum,13,17,36,34,94.44444444444444,0,1
@@ edu.stanford.nlp.classify.RVFDataset.scaleDatasetGaussian,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.RVFDataset.scaleDatumGaussian,13,17,34,32,94.11764705882352,0,0
@@ edu.stanford.nlp.classify.RVFDataset.split,4,4,24,24,100.0,0,11
@@ edu.stanford.nlp.classify.RVFDataset.add,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.add,5,5,12,12,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.getRVFDatum,5,5,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.classify.RVFDataset.addAllWithSourcesAndIds,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.RVFDataset.addAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.addLabel,4,4,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.classify.RVFDataset.addFeatures,12,16,50,37,74.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.summaryStatistics,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.printFullFeatureMatrix,17,21,70,44,62.857142857142854,0,0
@@ edu.stanford.nlp.classify.RVFDataset.printFullFeatureMatrixWithValues,17,21,76,48,63.1578947368421,0,4
@@ edu.stanford.nlp.classify.RVFDataset.selectFeaturesFromSet,18,23,91,57,62.637362637362635,0,0
@@ edu.stanford.nlp.classify.RVFDataset.applyFeatureCountThreshold,19,24,111,64,57.65765765765766,0,0
@@ edu.stanford.nlp.classify.RVFDataset.applyFeatureMaxCountThreshold,19,24,111,64,57.65765765765766,0,0
@@ edu.stanford.nlp.classify.RVFDataset.readSVMLightFormat,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.svmLightLineToRVFDatum,7,8,18,13,72.22222222222221,0,1
@@ edu.stanford.nlp.classify.RVFDataset.readSVMLightFormat,8,9,16,12,75.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.writeSVMLightFormat,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.printSparseFeatureMatrix,8,9,22,17,77.27272727272727,0,1
@@ edu.stanford.nlp.classify.RVFDataset.printSparseFeatureValues,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.RVFDataset.printSparseFeatureValues,8,10,20,16,80.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.getValuesArray,10,14,23,23,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset.toSummaryString,6,7,11,11,100.0,0,1
@@ edu.stanford.nlp.classify.RVFDataset.randomize,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.RVFDataset.shuffleWithSideInformation,7,8,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$4.create,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$QNFactory.create,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.NominalDataReader.readDatum,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.NominalDataReader.readDatum,14,18,51,27,52.94117647058824,0,1
@@ edu.stanford.nlp.classify.NominalDataReader.readData,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.<init>,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.getMinimizer,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.trainWeights,15,22,45,32,71.11111111111111,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.trainWeightsSemiSup,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.getHighPrecisionFeatures,16,21,61,37,60.65573770491803,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.heldOutSetSigma,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.trainClassifier,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.trainClassifier,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.trainClassifier,11,15,13,13,100.0,0,1
@@ edu.stanford.nlp.classify.LinearClassifierFactory.trainClassifierWithInitialWeights,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.trainClassifierWithInitialWeights,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.loadFromFilename,11,14,32,21,65.625,0,1
@@ edu.stanford.nlp.classify.LinearClassifierFactory.$deserializeLambda$,13,21,13,13,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory.lambda$useHybridMinimizer$ac01f5a7$1,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.featureOf,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.createIndex,11,13,43,23,53.48837209302325,0,2
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.to3D,11,13,49,27,55.10204081632652,0,0
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.priors,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.normalize,20,25,95,56,58.94736842105262,0,0
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.calculate,51,68,253,159,62.845849802371546,0,0
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.<init>,8,10,25,21,84.0,0,0
@@ edu.stanford.nlp.classify.LogConditionalEqConstraintFunction.initial,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.classify.MultinomialLogisticClassifier.probabilityOf,8,9,23,17,73.91304347826086,0,0
@@ edu.stanford.nlp.classify.MultinomialLogisticClassifier.load,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.classify.MultinomialLogisticClassifier.save,5,6,13,13,100.0,0,1
@@ edu.stanford.nlp.classify.MultinomialLogisticClassifier.weightsAsGenericCounter,10,12,30,25,83.33333333333334,0,0
@@ edu.stanford.nlp.classify.NBLinearClassifierFactory.trainWeights,20,26,93,53,56.98924731182796,0,0
@@ edu.stanford.nlp.classify.NBLinearClassifierFactory.weights,23,30,104,48,46.15384615384615,0,1
@@ edu.stanford.nlp.classify.NBLinearClassifierFactory.lambda$tuneSigma$0,11,13,53,32,60.37735849056604,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$2.create,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.WeightedRVFDataset.getWeights,4,4,11,10,90.9090909090909,0,1
@@ edu.stanford.nlp.classify.WeightedRVFDataset.addWeight,4,4,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.classify.ShiftParamsLogisticClassifierFactory.trainClassifier,5,5,13,11,84.61538461538461,0,1
@@ edu.stanford.nlp.classify.ShiftParamsLogisticClassifierFactory.trainWeights,7,8,22,11,50.0,0,0
@@ edu.stanford.nlp.classify.ShiftParamsLogisticClassifierFactory.augmentFeatureMatrix,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.ShiftParamsLogisticClassifierFactory.convertLabels,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.to2D,8,9,26,16,61.53846153846154,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculate,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateStochastic,9,12,30,30,100.0,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateSCL,23,29,85,56,65.88235294117646,0,1
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateCL,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateCLbatch,46,62,199,144,72.36180904522614,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateCLiterable,29,38,83,68,81.92771084337349,0,1
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateStochasticFiniteDifference,27,36,123,98,79.67479674796748,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateStochasticGradientLocal,27,36,112,87,77.67857142857143,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.valueAt,16,20,68,47,69.11764705882352,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateStochasticUpdate,52,71,235,171,72.76595744680851,0,1
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateStochasticGradient,22,28,64,46,71.875,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateStochasticAlgorithmicDifferentiation,44,58,192,130,67.70833333333334,0,1
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.rvfcalculate,46,62,243,169,69.54732510288066,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction.<init>,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.classify.CrossValidator.<init>,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.CrossValidator.computeAverage,5,5,10,7,70.0,0,0
@@ edu.stanford.nlp.classify.CrossValidator.main,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.classify.Dataset.split,4,4,22,22,100.0,0,0
@@ edu.stanford.nlp.classify.Dataset.getRandomSubDataset,8,9,21,20,95.23809523809523,0,0
@@ edu.stanford.nlp.classify.Dataset.readSVMLightFormat,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.Dataset.svmLightLineToDatum,10,12,28,19,67.85714285714286,0,0
@@ edu.stanford.nlp.classify.Dataset.getFeatureCounter,8,9,13,8,61.53846153846154,0,0
@@ edu.stanford.nlp.classify.Dataset.getL1NormalizedTFIDFDatum,13,16,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.classify.Dataset.getL1NormalizedTFIDFDataset,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.Dataset.ensureSize,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.classify.Dataset.addFeatures,9,11,22,19,86.36363636363636,0,0
@@ edu.stanford.nlp.classify.Dataset.getRVFDatum,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.Dataset.toSummaryStatistics,13,17,34,26,76.47058823529412,0,0
@@ edu.stanford.nlp.classify.Dataset.applyFeatureCountThreshold,25,33,111,73,65.76576576576578,0,1
@@ edu.stanford.nlp.classify.Dataset.printFullFeatureMatrix,17,21,69,43,62.31884057971014,0,0
@@ edu.stanford.nlp.classify.Dataset.printSparseFeatureMatrix,8,9,22,17,77.27272727272727,0,0
@@ edu.stanford.nlp.classify.Dataset.changeLabelIndex,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.classify.Dataset.changeFeatureIndex,10,12,49,31,63.26530612244898,0,0
@@ edu.stanford.nlp.classify.Dataset.selectFeatures,17,22,93,56,60.215053763440864,0,0
@@ edu.stanford.nlp.classify.Dataset.getInformationGains,31,41,145,90,62.06896551724138,0,0
@@ edu.stanford.nlp.classify.Dataset.updateLabels,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.Dataset.printSVMLightFormat,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.KNNClassifier.addInstances,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.classify.KNNClassifier.classOf,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.KNNClassifier.scoresOf,15,20,48,35,72.91666666666666,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$8.create,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.toString,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.weightsAsCounter,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.classOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.classOf,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.classOf,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.scoreOf,7,8,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.scoreOf,7,8,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.justificationOf,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.justificationOf,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.scoresOf,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.probabilityOf,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.classify.LogisticClassifier.probabilityOf,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.probabilityOf,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.trainWeightedData,8,10,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.classify.LogisticClassifier.train,17,22,50,40,80.0,0,1
@@ edu.stanford.nlp.classify.LogisticClassifier.main,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.BiasedLogConditionalObjectiveFunction.to2D,8,9,26,16,61.53846153846154,0,0
@@ edu.stanford.nlp.classify.BiasedLogConditionalObjectiveFunction.calculate,26,33,116,80,68.96551724137932,0,1
@@ edu.stanford.nlp.classify.LogisticClassifierFactory.trainWeightedData,10,13,25,23,92.0,0,0
@@ edu.stanford.nlp.classify.LogisticClassifierFactory.trainClassifier,19,25,50,38,76.0,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.readModel,18,23,49,36,73.46938775510205,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.getWeights,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.convertWeights,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.convertSVMLightWeights,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.convertSVMStructWeights,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.fitSigmoid,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.trainClassifier,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.trainClassifierBasic,51,73,149,141,94.63087248322147,0,1
@@ edu.stanford.nlp.classify.SVMLightClassifierFactory.lambda$crossValidateSetC$1,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainClassifier,14,17,63,34,53.96825396825397,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainClassifier,11,13,29,22,75.86206896551724,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainWeights,8,10,27,27,100.0,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainWeightsJL,23,29,89,49,55.0561797752809,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainWeightsUCL,11,13,47,32,68.08510638297872,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory.numberValues,10,12,21,11,52.38095238095239,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainClassifier,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.ShiftParamsLogisticObjectiveFunction.calculate,23,30,105,63,60.0,0,0
@@ edu.stanford.nlp.classify.ShiftParamsLogisticObjectiveFunction.getRegularizerParamRange,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.classify.PRCurve.<init>,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.classify.PRCurve.<init>,7,8,8,7,87.5,0,0
@@ edu.stanford.nlp.classify.PRCurve.init,8,9,27,19,70.37037037037037,0,0
@@ edu.stanford.nlp.classify.PRCurve.initMC,8,9,28,20,71.42857142857143,0,0
@@ edu.stanford.nlp.classify.PRCurve.init,14,17,43,27,62.7906976744186,0,1
@@ edu.stanford.nlp.classify.PRCurve.precision,7,8,23,13,56.52173913043478,0,0
@@ edu.stanford.nlp.classify.PRCurve.f1,6,7,16,13,81.25,0,0
@@ edu.stanford.nlp.classify.PRCurve.logPrecision,14,19,63,30,47.61904761904761,0,0
@@ edu.stanford.nlp.classify.PRCurve.optFmeasure,7,8,21,11,52.38095238095239,0,0
@@ edu.stanford.nlp.classify.PRCurve.fmeasure,15,20,66,33,50.0,0,0
@@ edu.stanford.nlp.classify.PRCurve.logLikelihood,8,9,24,13,54.166666666666664,0,0
@@ edu.stanford.nlp.classify.PRCurve.cwa,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.classify.PRCurve.cwaArray,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.PRCurve.optimalCwaArray,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.classify.PRCurve.optimalCwa,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.classify.PRCurve.correct,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.PRCurve.main,5,5,10,6,60.0,0,1
@@ edu.stanford.nlp.classify.NaiveBayesClassifier.scoresOf,12,15,31,26,83.87096774193549,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifier.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifier.accuracy,7,8,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifier.initZeros,8,9,12,9,75.0,0,0
@@ edu.stanford.nlp.classify.SemiSupervisedLogConditionalObjectiveFunction.calculate,9,11,34,26,76.47058823529412,0,1
@@ edu.stanford.nlp.classify.SemiSupervisedLogConditionalObjectiveFunction.<init>,5,6,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset$1.hasNext,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.RVFDataset$1.next,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.NaiveBayesClassifierFactory$NBWeights.<init>,17,21,67,35,52.23880597014925,0,0
@@ edu.stanford.nlp.classify.BiasedLogisticObjectiveFunction.calculate,18,23,60,35,58.333333333333336,0,0
@@ edu.stanford.nlp.classify.BiasedLogisticObjectiveFunction.calculateRVF,17,21,66,32,48.484848484848484,0,0
@@ edu.stanford.nlp.classify.LogConditionalObjectiveFunction$CLBatchDerivativeCalculation.run,30,39,122,96,78.68852459016394,0,1
@@ edu.stanford.nlp.classify.LinearClassifierFactory$LinearClassifierCreator.createLinearClassifier,5,5,16,14,87.5,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.weight,10,14,24,24,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoresOf,12,15,21,18,85.71428571428571,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoresOf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoreOf,7,8,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoresOf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoresOfRVFDatum,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoreOfRVFDatum,5,5,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoreOfRVFDatum,5,5,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoreOf,8,10,14,11,78.57142857142857,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.probabilityOf,7,8,8,8,100.0,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.probabilityOfRVFDatum,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.probabilityOf,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.logProbabilityOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.probabilityOf,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.getLabelIndices,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.getFeatureCount,13,16,11,8,72.72727272727273,0,2
@@ edu.stanford.nlp.classify.LinearClassifier.getFeatureCount,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.getFeatureCountLabelIndices,13,16,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.getTopFeatures,4,4,13,13,100.0,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.getTopFeaturesLabelIndices,25,34,88,51,57.95454545454546,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.topFeaturesToString,15,19,24,19,79.16666666666666,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.toBiggestWeightFeaturesString,37,49,118,70,59.32203389830508,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.toDistributionString,8,9,4,4,100.0,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.toHistogramString,27,39,115,73,63.47826086956522,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.toString,15,21,26,26,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.bucketizeValue,9,11,16,4,25.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.printHistCounts,19,24,53,18,33.9622641509434,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.justificationOfRVFDatum,46,60,113,67,59.29203539823009,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.justificationOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.justificationOf,55,73,132,82,62.121212121212125,0,1
@@ edu.stanford.nlp.classify.LinearClassifier.weightsAsMapOfCounters,8,9,10,10,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.scoresOf,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.classOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.<init>,7,8,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.makeWeightCounter,8,9,20,10,50.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.<init>,14,17,44,31,70.45454545454545,0,0
@@ edu.stanford.nlp.classify.LinearClassifier.saveToFilename,11,13,25,15,60.0,0,0
@@ edu.stanford.nlp.classify.LinearClassifierFactory$9.create,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.classify.demo.MnistConverter.main,22,29,63,51,80.95238095238095,0,0
@@ edu.stanford.nlp.classify.demo.ClassifierDemo.main,7,8,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.classify.demo.ClassifierDemo.demonstrateSerialization,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.classify.demo.ClassifierDemo.demonstrateSerializationColumnDataClassifier,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass$LabelWithSeedWords.<init>,5,5,16,16,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass$LabelWithSeedWords.call,59,85,167,144,86.22754491017965,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt$PhrasePair.<init>,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt$PhrasePair.equals,7,9,11,11,100.0,0,0
@@ edu.stanford.nlp.patterns.PatternFactory.setUp,18,24,27,24,88.88888888888889,0,0
@@ edu.stanford.nlp.patterns.PatternFactory.doNotUse,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.PatternFactory.getPatternsAroundTokens,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.createOrGet,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.createOrGet,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.createOrGet,9,12,25,24,96.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.<init>,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.equals,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.compareTo,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.convertStringPhrases,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.convertToString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.addFeature,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.patterns.CandidatePhrase.addFeatures,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.patterns.EditDistanceDamerauLevenshteinLike.editDistance,20,31,33,33,100.0,0,1
@@ edu.stanford.nlp.patterns.EditDistanceDamerauLevenshteinLike.editDistanceWithBuffers,23,31,81,47,58.0246913580247,0,0
@@ edu.stanford.nlp.patterns.EditDistanceDamerauLevenshteinLike.iterateOverStripe,13,18,56,30,53.57142857142857,0,0
@@ edu.stanford.nlp.patterns.EditDistanceDamerauLevenshteinLike.initMemoiseTables,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.patterns.EditDistanceDamerauLevenshteinLike.min,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesAverageFeatures.scorePhrases,81,118,291,265,91.06529209621993,0,1
@@ edu.stanford.nlp.patterns.Data.computeRawFreqIfNull,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.Data.computeRawFreqIfNull,18,24,17,14,82.35294117647058,0,0
@@ edu.stanford.nlp.patterns.Data.loadDomainNGrams,11,15,12,12,100.0,0,1
@@ edu.stanford.nlp.patterns.InvertedIndexByTokens.add,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.InvertedIndexByTokens.add,11,14,16,16,100.0,0,0
@@ edu.stanford.nlp.patterns.InvertedIndexByTokens.add,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.patterns.InvertedIndexByTokens.getFileSentIds,14,18,26,14,53.84615384615385,0,1
@@ edu.stanford.nlp.patterns.InvertedIndexByTokens.getFileSentIdsFromPats,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.InvertedIndexByTokens.createIndex,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.PhraseScorer.getPatTFIDFScore,10,13,29,26,89.65517241379311,0,0
@@ edu.stanford.nlp.patterns.PhraseScorer.getGoogleNgramScore,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.PhraseScorer.getDomainNgramScore,9,11,31,14,45.16129032258064,0,0
@@ edu.stanford.nlp.patterns.PhraseScorer.getDistSimWtScore,21,30,85,53,62.35294117647059,0,1
@@ edu.stanford.nlp.patterns.PhraseScorer.wordShape,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.patterns.PhraseScorer.getWordShapeScore,7,8,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.patterns.PhraseScorer.getDictOddsScore,8,10,17,15,88.23529411764706,0,0
@@ edu.stanford.nlp.patterns.PhraseScorer.getPhraseWeightFromWords,15,20,40,24,60.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.<init>,23,35,67,59,88.05970149253731,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.learnClassifier,23,31,70,65,92.85714285714286,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.printReasonForChoosing,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.scorePhrases,9,11,16,16,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.scorePhrases,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.getRandomBoolean,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.wordClass,16,23,53,20,37.735849056603776,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.getAllLabeledWordsCluster,11,13,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.computeSimWithWordVectors,39,54,145,91,62.758620689655174,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.computeSimWithWordVectors,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.computeSimWithWordCluster,22,31,58,34,58.620689655172406,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.chooseUnknownAsNegatives,17,23,31,31,100.0,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.chooseUnknownPhrases,34,48,116,85,73.27586206896551,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.hasElement,9,11,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.numLabeledTokens,16,20,12,12,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.getAllPossibleNegativePhrases,9,11,23,23,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.choosedatums,104,155,334,210,62.874251497005986,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.getPhraseFeaturesForPattern,46,68,161,160,99.37888198757764,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.scoreUsingClassifer,27,37,114,102,89.47368421052632,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.getFeatures,62,92,229,211,92.13973799126637,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.lambda$chooseUnknownPhrases$1,5,6,14,14,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt.lambda$computeSimWithWordVectors$0,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getAllOptions,13,17,22,22,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.hasSeedWordOrOtherSem,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.<init>,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.<init>,7,8,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.<init>,7,8,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.setUp,91,130,198,174,87.87878787878788,0,4
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.listFileIncludingItself,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.readGoldEntities,14,18,15,15,100.0,0,2
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.addWordShapes,10,12,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getLearnedWords,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getLearnedWordsAsJson,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getLearnedWordsAsJsonLastIteration,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getSetWordsAsJson,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getEditDist,13,17,28,15,53.57142857142857,0,1
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getEditDistanceFromThisClass,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getEditDistanceFromOtherClasses,14,19,34,23,67.64705882352942,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getEditDistanceScoresOtherClass,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getEditDistanceScoresOtherClassThreshold,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getEditDistanceScoresThisClassThreshold,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.getEditDistanceScoresThisClass,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.isFuzzyMatch,7,9,13,13,100.0,0,1
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.containsFuzzy,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.addSeedWords,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables.lambda$getAllOptions$0,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.getAllAnnotations,17,22,30,19,63.33333333333333,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.getAllAnnotations,12,15,23,16,69.56521739130434,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.suggestPhrasesTest,22,29,40,40,100.0,0,1
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.resetPatternLabelsInSents,11,13,5,5,100.0,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.setProperties,16,22,22,22,100.0,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.setUpProperties,29,40,65,60,92.3076923076923,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.processText,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.changeAnnotation,14,17,14,11,78.57142857142857,0,1
@@ edu.stanford.nlp.patterns.TextAnnotationPatterns.doNewPhrases,8,9,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.setIndexReaderSearcher,6,7,13,13,100.0,0,1
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.queryIndexGetSentences,16,21,28,28,100.0,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.add,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.queryIndex,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.listAllDocuments,5,5,13,9,69.23076923076923,0,1
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.readProtoBufAnnotation,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.getProtoBufAnnotation,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.add,14,19,32,32,100.0,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.finishUpdating,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.setIndexWriter,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.closeIndexWriter,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.saveIndex,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.LuceneSentenceIndex.createIndex,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass$CalculateSufficientStatsThreads.call,76,113,273,217,79.48717948717949,0,1
@@ edu.stanford.nlp.patterns.ScorePatternsRatioModifiedFreq.score,26,38,146,120,82.1917808219178,0,1
@@ edu.stanford.nlp.patterns.ScorePatternsRatioModifiedFreq.convert2OneDim,86,131,350,294,84.0,0,2
@@ edu.stanford.nlp.patterns.ConstantsAndVariables$DataSentsIterator.<init>,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.patterns.ConstantsAndVariables$DataSentsIterator.hasNext,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables$DataSentsIterator.next,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.chooseTopWords,26,37,84,74,88.09523809523809,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.removeKeys,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.numNonRedundantPatterns,13,17,38,21,55.26315789473685,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.learnNewPhrases,6,8,21,21,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.runParallelApplyPats,34,45,124,88,70.96774193548387,0,1
@@ edu.stanford.nlp.patterns.ScorePhrases.getSentences,32,43,39,39,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.applyPats,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.statsWithoutApplyingPatterns,17,22,20,15,75.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrases.learnNewPhrasesPrivate,91,130,256,240,93.75,0,1
@@ edu.stanford.nlp.patterns.ScorePhrases.lambda$learnNewPhrasesPrivate$0,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.DataInstance.getNewInstance,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass$1.apply,12,17,23,12,52.17391304347826,0,0
@@ edu.stanford.nlp.patterns.Pattern.sameGenre,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.patterns.Pattern.subsumes,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.patterns.Pattern.getContext,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.Pattern.getRelevantWordsBase,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.patterns.Pattern.getRelevantWordsBase,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.<init>,5,5,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.<init>,6,7,11,11,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.setUpConstructor,113,165,338,308,91.12426035502959,0,2
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.removeOverLappingLabels,22,29,30,15,50.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.runPOSNERParseOnTokens,15,20,27,27,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.runPOSNEROnTokens,15,20,29,29,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.tokenize,38,55,83,71,85.54216867469879,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.inferParentParseTag,10,12,5,5,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getSubListIndex,65,103,356,125,35.1123595505618,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getThreadBatches,11,13,34,25,73.52941176470588,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.runLabelSeedWords,5,5,17,17,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getFeatures,12,16,19,13,68.42105263157895,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.addToMatchedTokensByPhrase,9,11,25,21,84.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.processSents,5,5,17,17,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.readSavedPatternsAndIndex,8,11,26,26,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getPatterns,121,180,439,363,82.6879271070615,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getPatternScoringClass,20,34,60,60,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.calculateSufficientStats,11,13,25,25,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.addStats,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.enforceMinSupportRequirements,12,15,32,32,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.removeLearnedPatterns,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.normalizeSoftMaxMinMaxScores,22,29,63,20,31.746031746031743,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.labelWords,65,92,186,145,77.95698924731182,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.iterateExtractApply,88,125,232,217,93.53448275862068,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writeMatchedTokensAndSents,22,28,37,37,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.matchedTokensByPhraseJsonString,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.matchedTokensByPhraseJsonString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.jsonArrayBuilderFromMapCounter,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.iterateExtractApply4Label,31,46,133,131,98.49624060150376,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writePatternsToFile,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writeWordsToFile,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.readLearnedWordsFromFile,11,14,26,7,26.923076923076923,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.countResultsPerEntity,57,90,255,51,20.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.countResultsPerToken,28,44,73,73,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.countResults,5,5,22,22,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writeLabelDataSents,27,35,46,35,76.08695652173914,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writeLabeledData,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writeColumnOutput,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writeColumnOutputSents,16,20,17,17,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.evaluate,17,21,40,40,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getAllFiles,13,16,16,16,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getPrecisionRecall,17,22,35,20,57.14285714285714,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getNonBackgroundLabels,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.readSeedWordsFromJSONString,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.readSeedWords,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.readSeedWords,19,25,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.getAllOptions,11,14,14,14,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.processSents,89,130,184,133,72.28260869565217,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.saveModel,13,16,33,25,75.75757575757575,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.evaluate,13,18,36,36,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.run,6,7,6,6,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.runNineYards,19,27,65,65,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.addFolder,15,19,33,33,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.loadFromSavedPatternsWordsDir,52,76,137,127,92.7007299270073,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.readClassesInEnv,15,20,24,24,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.writeClassesInEnv,15,19,11,11,100.0,0,1
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.lambda$labelWords$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass.lambda$setUpConstructor$0,8,10,11,11,100.0,0,1
@@ edu.stanford.nlp.patterns.TextAnnotationPatternsInterface$PerformActionUpdateModel.run,23,38,95,69,72.63157894736842,0,1
@@ edu.stanford.nlp.patterns.ConstantsAndVariables$ScorePhraseMeasures.create,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.patterns.ConstantsAndVariables$ScorePhraseMeasures.equals,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.ConstantsAndVariables$ScorePhraseMeasures.compareTo,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt$ComputeSim.call,4,4,20,20,100.0,0,0
@@ edu.stanford.nlp.patterns.SPIEDServlet.quote,19,29,40,35,87.5,0,1
@@ edu.stanford.nlp.patterns.SPIEDServlet.run,16,23,45,37,82.22222222222221,0,0
@@ edu.stanford.nlp.patterns.SPIEDServlet.doGet,8,10,16,16,100.0,0,0
@@ edu.stanford.nlp.patterns.TextAnnotationPatternsInterface.main,3,2,3,2,66.66666666666666,0,1
@@ edu.stanford.nlp.patterns.ScorePhrasesLearnFeatWt$ChooseDatumsThread.call,64,99,272,162,59.55882352941176,0,1
@@ edu.stanford.nlp.patterns.ScorePatternsFreqBased.score,30,40,78,73,93.58974358974359,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.toString,6,7,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.toString,6,7,20,17,85.0,0,1
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.getPrevContextStr,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.getNextContextStr,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.equalContext,19,27,49,31,63.26530612244898,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.equals,22,35,67,67,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.getSimplerTokens,10,13,23,15,65.21739130434783,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.toStringSimple,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.subsumesArray,22,32,62,32,51.61290322580645,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.subsumes,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.subsumesEitherWay,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.sameRestrictions,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.compareTo,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.getPreviousContextLen,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.getNextContextLen,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePattern.sameLength,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.LearnImportantFeatures.setUp,14,19,26,26,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.LearnImportantFeatures.getRandomBoolean,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.LearnImportantFeatures.sample,19,26,58,40,68.96551724137932,0,0
@@ edu.stanford.nlp.patterns.surface.LearnImportantFeatures.getTopFeatures,14,18,45,36,80.0,0,0
@@ edu.stanford.nlp.patterns.surface.LearnImportantFeatures.getDatum,19,25,58,41,70.6896551724138,0,0
@@ edu.stanford.nlp.patterns.surface.ApplyPatternsMulti.call,52,78,193,118,61.13989637305699,0,0
@@ edu.stanford.nlp.patterns.surface.ApplyPatternsMulti.containsStopWord,7,10,14,14,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.AnnotatedTextReader.parseColumnFile,22,32,57,34,59.64912280701754,0,0
@@ edu.stanford.nlp.patterns.surface.AnnotatedTextReader.parseFile,27,37,66,45,68.18181818181817,0,1
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenInMemory.<init>,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenInMemory.addPatterns,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenInMemory.addPatterns,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenInMemory.getPatternsForAllTokens,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenInMemory.getPatternsForAllTokens,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.<init>,8,10,20,16,80.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.checkClean,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.setIndexReaderSearcher,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.addPatterns,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.setIndexWriter,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.closeIndexWriter,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.load,5,6,3,3,100.0,0,1
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.addPatterns,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.getPatternsForAllTokens,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenLucene.getPatternsForAllTokens,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.patterns.surface.ScorePatternsF1.score,11,14,23,23,100.0,0,1
@@ edu.stanford.nlp.patterns.surface.CreatePatterns.getAllPatterns,16,20,42,33,78.57142857142857,0,1
@@ edu.stanford.nlp.patterns.surface.PatternToken.<init>,11,15,23,23,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternToken.toStringToWrite,10,13,39,25,64.1025641025641,0,0
@@ edu.stanford.nlp.patterns.surface.PatternToken.getTokenStr,13,18,31,31,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternToken.equals,18,28,71,71,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternToken.copy,5,5,12,12,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePatternFactory.setUp,9,12,12,12,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.SurfacePatternFactory.getContext,105,157,337,183,54.3026706231454,0,1
@@ edu.stanford.nlp.patterns.surface.SurfacePatternFactory.getContextTokenStr,20,28,59,33,55.932203389830505,0,1
@@ edu.stanford.nlp.patterns.surface.SurfacePatternFactory.getPatternsAroundTokens,8,9,22,15,68.18181818181817,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachToken.updatePatterns,7,8,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachToken.getPatternsInstance,6,8,15,12,80.0,0,0
@@ edu.stanford.nlp.patterns.surface.CreatePatterns$CreatePatternsThread.call,13,17,57,55,96.49122807017544,0,0
@@ edu.stanford.nlp.patterns.surface.Token.classORRestrictionsAsString,8,10,13,13,100.0,0,1
@@ edu.stanford.nlp.patterns.surface.Token.toString,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.Token.toStringDep,13,17,38,23,60.526315789473685,0,0
@@ edu.stanford.nlp.patterns.surface.Token.toStringSurface,20,28,66,43,65.15151515151516,0,0
@@ edu.stanford.nlp.patterns.surface.Token.getSimple,17,24,42,29,69.04761904761905,0,0
@@ edu.stanford.nlp.patterns.surface.Token.equals,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.Token.addORRestriction,10,14,22,20,90.9090909090909,0,0
@@ edu.stanford.nlp.patterns.surface.Token.setEnvBindRestriction,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.Token.isEmpty,8,11,16,16,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.Token.getKeyForClass,10,13,20,13,65.0,0,0
@@ edu.stanford.nlp.patterns.surface.Token.toStringClass2KeyMapping,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.Token.setClass2KeyMapping,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.ApplyPatterns.call,68,104,238,159,66.80672268907563,0,1
@@ edu.stanford.nlp.patterns.surface.ApplyPatterns.lemmaExists,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.ApplyPatterns.containsStopWord,11,18,24,24,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.<init>,15,22,31,31,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.createTable,5,6,14,14,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.addPatterns,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.addPattern,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.getPatternsForAllTokens,4,4,6,5,83.33333333333334,0,1
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.containsSentId,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.createIndexIfUsingDBAndNotExists,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.DBTableExists,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.patterns.surface.PatternsForEachTokenDB.getPatternsForAllTokens,23,31,79,24,30.37974683544304,0,0
@@ edu.stanford.nlp.patterns.dep.ApplyDepPatterns.call,65,101,242,153,63.22314049586777,0,1
@@ edu.stanford.nlp.patterns.dep.ApplyDepPatterns.matchedRestriction,34,47,82,61,74.39024390243902,0,0
@@ edu.stanford.nlp.patterns.dep.ApplyDepPatterns.containsStopWord,8,12,16,16,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.ApplyDepPatterns$2.apply,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.patterns.dep.ExtractedPhrase.equals,8,11,27,27,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPatternFactory.setUp,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPatternFactory.getPatternsForAllPhrases,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPatternFactory.patternToDepPattern,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPatternFactory.ifIgnoreRel,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPatternFactory.getContext,16,23,43,33,76.74418604651163,0,1
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.checkIfSatisfiedMaxDepth,18,24,24,24,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.processSentenceForType,10,12,14,14,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.getSemGrexPatternNodes,11,14,35,34,97.14285714285714,0,1
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.printSubGraph,34,49,139,103,74.10071942446042,0,0
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.descendants,7,9,20,20,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.checkIfSatisfiesRelConstrains,12,18,19,19,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.descendantsHelper,32,48,86,66,76.74418604651163,0,1
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.descendantsWithReln,17,23,34,34,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.ExtractPhraseFromPattern.printMatchedGraphsForPattern,10,12,10,9,90.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPattern.getRelevantWords,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPattern.toString,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.patterns.dep.DepPattern.equals,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.IntTuple.compareTo,14,18,28,23,82.14285714285714,0,1
@@ edu.stanford.nlp.util.IntTuple.equals,11,14,31,24,77.41935483870968,0,0
@@ edu.stanford.nlp.util.IntTuple.hashCode,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.util.IntTuple.getIntTuple,10,13,9,9,100.0,0,0
@@ edu.stanford.nlp.util.IntTuple.getIntTuple,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.IntTuple.toString,7,8,24,15,62.5,0,0
@@ edu.stanford.nlp.util.IntTuple.concat,8,9,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.util.Filters$ConjFilter.test,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.util.XMLUtils.getTextContentFromTagsFromFileSAXException,14,18,44,19,43.18181818181818,0,0
@@ edu.stanford.nlp.util.XMLUtils.getTagElementsFromFileSAXException,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.XMLUtils.getTagElementTriplesFromFileNumBoundedSAXException,13,17,53,25,47.16981132075472,0,0
@@ edu.stanford.nlp.util.XMLUtils.stripTags,18,25,47,30,63.829787234042556,0,1
@@ edu.stanford.nlp.util.XMLUtils.readUntilTag,8,10,16,9,56.25,0,0
@@ edu.stanford.nlp.util.XMLUtils.readAndParseTag,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.XMLUtils.unescapeStringForXML,5,5,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.util.XMLUtils.escapeXML,16,21,29,24,82.75862068965517,0,0
@@ edu.stanford.nlp.util.XMLUtils.escapeElementXML,12,15,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.util.XMLUtils.escapeAttributeXML,10,12,20,15,75.0,0,1
@@ edu.stanford.nlp.util.XMLUtils.escapeTextAroundXMLTags,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.util.XMLUtils.findSpace,8,11,12,12,100.0,0,1
@@ edu.stanford.nlp.util.XMLUtils.readTag,11,14,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.util.XMLUtils.parseTag,8,11,9,9,100.0,0,1
@@ edu.stanford.nlp.util.XMLUtils.main,11,15,20,14,70.0,0,0
@@ edu.stanford.nlp.util.Filters$CategoricalFilter.equals,9,11,12,12,100.0,0,1
@@ edu.stanford.nlp.util.DeltaMap.containsKey,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.util.DeltaMap.get,8,10,14,14,100.0,0,1
@@ edu.stanford.nlp.util.DeltaMap.put,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.util.DeltaMap.clear,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.UnorderedPair.equals,24,37,71,71,100.0,0,0
@@ edu.stanford.nlp.util.UnorderedPair.hashCode,10,12,19,19,100.0,0,0
@@ edu.stanford.nlp.util.UnorderedPair.compareTo,10,13,30,23,76.66666666666667,0,0
@@ edu.stanford.nlp.util.ErasureUtils.mkT2DArray,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass.createInstance,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass.equals,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass.type2class,10,13,13,13,100.0,0,1
@@ edu.stanford.nlp.util.MetaClass.cast,125,194,298,131,43.95973154362416,0,2
@@ edu.stanford.nlp.util.MetaClass.castWithoutKnowingType,14,20,17,17,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass.argmin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass.argmin,8,10,31,12,38.70967741935484,0,1
@@ edu.stanford.nlp.util.CommandLineTokenizer.appendToBuffer,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.CommandLineTokenizer.tokenize,23,32,63,34,53.96825396825397,0,0
@@ edu.stanford.nlp.util.CoreMaps$2.get,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.util.CoreMaps$2.put,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.util.CoreMaps$2.remove,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.util.ArrayMap.<init>,7,8,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.util.ArrayMap.isEmpty,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ArrayMap.resize,4,4,7,6,85.71428571428571,0,2
@@ edu.stanford.nlp.util.ArrayMap.put,9,11,37,28,75.67567567567568,0,0
@@ edu.stanford.nlp.util.ArrayMap.get,10,13,34,20,58.82352941176471,0,2
@@ edu.stanford.nlp.util.ArrayMap.remove,12,16,46,30,65.21739130434783,0,0
@@ edu.stanford.nlp.util.ArrayMap.hashCode,7,8,24,16,66.66666666666666,0,0
@@ edu.stanford.nlp.util.ArrayMap.equals,14,19,42,29,69.04761904761905,0,1
@@ edu.stanford.nlp.util.MutableDouble.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.util.MutableDouble.compareTo,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.ThreeDimensionalCollectionValuedMap.getTwoDimensionalCollectionValuedMap,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.util.IntPair.equals,8,10,15,15,100.0,0,1
@@ edu.stanford.nlp.util.ConfusionMatrix$ConfusionGrid$Grid.onMouseOver,7,8,16,14,87.5,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix$ConfusionGrid$Grid.paintComponent,30,42,135,68,50.37037037037037,0,1
@@ edu.stanford.nlp.util.ThreeDimensionalMap.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.util.ThreeDimensionalMap.isEmpty,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.util.ThreeDimensionalMap.contains,8,10,24,24,100.0,0,0
@@ edu.stanford.nlp.util.ThreeDimensionalMap.getTwoDimensionalMap,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.util.ThreeDimensionalMap.values,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.ThreeDimensionalMap.secondKeySet,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.ThreeDimensionalMap.thirdKeySet,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.util.FilePathProcessor.processPath,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap$TwoDimensionalMapIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap$TwoDimensionalMapIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap$TwoDimensionalMapIterator.primeNext,9,12,31,18,58.06451612903226,0,1
@@ edu.stanford.nlp.util.Iterables$10$1$1.hasNext,14,19,47,35,74.46808510638297,0,0
@@ edu.stanford.nlp.util.Iterables$10$1$1.next,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.OneToOneMap.put,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.OneToOneMap.removeLeftAsKey,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.OneToOneMap.removeRightAsKey,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalCollectionValuedMap.getCollectionValuedMap,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalCollectionValuedMap.add,4,4,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.util.TwoDimensionalCollectionValuedMap.add,7,8,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.util.TwoDimensionalCollectionValuedMap.addKey,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalCollectionValuedMap.retainAll,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalCollectionValuedMap.secondKeySet,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalCollectionValuedMap.values,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.containsIgnoreCase,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.mapStringToArray,10,12,40,20,50.0,0,1
@@ edu.stanford.nlp.util.StringUtils.mapStringToMap,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.regexesToPatterns,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.regexGroups,9,11,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.util.StringUtils.stringToSet,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.joinWords,11,13,12,9,75.0,0,0
@@ edu.stanford.nlp.util.StringUtils.join,8,9,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.util.StringUtils.joinWithOriginalWhiteSpace,9,11,23,16,69.56521739130434,0,1
@@ edu.stanford.nlp.util.StringUtils.join,8,9,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.util.StringUtils.join,8,9,11,8,72.72727272727273,0,1
@@ edu.stanford.nlp.util.StringUtils.join,8,9,22,11,50.0,0,0
@@ edu.stanford.nlp.util.StringUtils.splitLinesKeepNewlines,10,13,35,13,37.142857142857146,0,1
@@ edu.stanford.nlp.util.StringUtils.splitOnChar,8,10,33,15,45.45454545454545,0,0
@@ edu.stanford.nlp.util.StringUtils.splitFieldsFast,10,12,21,12,57.14285714285714,0,0
@@ edu.stanford.nlp.util.StringUtils.splitOnChar,9,11,36,16,44.44444444444444,0,0
@@ edu.stanford.nlp.util.StringUtils.valueSplit,11,14,32,20,62.5,0,0
@@ edu.stanford.nlp.util.StringUtils.pad,7,8,17,12,70.58823529411765,0,0
@@ edu.stanford.nlp.util.StringUtils.padOrTrim,11,14,31,20,64.51612903225806,0,0
@@ edu.stanford.nlp.util.StringUtils.padLeftOrTrim,11,14,31,20,64.51612903225806,0,0
@@ edu.stanford.nlp.util.StringUtils.padLeft,7,8,18,11,61.111111111111114,0,1
@@ edu.stanford.nlp.util.StringUtils.trim,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.trimWithEllipsis,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.util.StringUtils.repeat,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.util.StringUtils.repeat,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.StringUtils.fileNameClean,17,26,24,24,100.0,0,1
@@ edu.stanford.nlp.util.StringUtils.nthIndex,9,11,22,12,54.54545454545454,0,0
@@ edu.stanford.nlp.util.StringUtils.truncate,8,9,22,10,45.45454545454545,0,1
@@ edu.stanford.nlp.util.StringUtils.argsToMap,27,37,95,53,55.78947368421052,0,0
@@ edu.stanford.nlp.util.StringUtils.argsToProperties,57,86,162,75,46.2962962962963,0,1
@@ edu.stanford.nlp.util.StringUtils.propFileToProperties,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.stringToProperties,8,9,11,7,63.63636363636363,0,1
@@ edu.stanford.nlp.util.StringUtils.checkRequiredProperties,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.printToFile,10,12,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.util.StringUtils.printToFileLn,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.parseCommandLineArguments,15,19,40,25,62.5,0,0
@@ edu.stanford.nlp.util.StringUtils.stripNonAlphaNumerics,12,18,26,21,80.76923076923077,0,0
@@ edu.stanford.nlp.util.StringUtils.printStringOneCharPerLine,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.util.StringUtils.escapeString,12,15,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.util.StringUtils.splitOnCharWithQuoting,20,28,121,40,33.057851239669425,0,1
@@ edu.stanford.nlp.util.StringUtils.longestCommonSubstring,21,27,63,37,58.730158730158735,0,0
@@ edu.stanford.nlp.util.StringUtils.longestCommonContiguousSubstring,22,29,83,34,40.963855421686745,0,0
@@ edu.stanford.nlp.util.StringUtils.editDistance,21,27,60,38,63.33333333333333,0,0
@@ edu.stanford.nlp.util.StringUtils.pennPOSToWordnetPOS,10,13,8,8,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.getShortClassName,6,7,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.util.StringUtils.columnStringToObject,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.util.StringUtils.objectToColumnString,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.capitalize,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.toTitleCase,9,11,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.util.StringUtils.isTitleCase,8,10,4,4,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.isAllUpperCase,8,10,16,11,68.75,0,0
@@ edu.stanford.nlp.util.StringUtils.makeHTMLTable,14,17,49,25,51.02040816326531,0,0
@@ edu.stanford.nlp.util.StringUtils.makeTextTable,23,31,72,45,62.5,0,0
@@ edu.stanford.nlp.util.StringUtils.makeAsciiTableCell,8,10,18,9,50.0,0,0
@@ edu.stanford.nlp.util.StringUtils.main,8,9,16,6,37.5,0,0
@@ edu.stanford.nlp.util.StringUtils.toAscii,75,117,126,95,75.39682539682539,0,1
@@ edu.stanford.nlp.util.StringUtils.toCSVString,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.tr,14,19,39,21,53.84615384615385,0,1
@@ edu.stanford.nlp.util.StringUtils.chomp,10,14,21,21,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.getBaseName,6,7,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.util.StringUtils.getNotNullString,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.util.StringUtils.isNullOrEmpty,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.resolveVars,16,20,25,19,76.0,0,0
@@ edu.stanford.nlp.util.StringUtils.argsToPropertiesWithResolve,33,50,102,42,41.17647058823529,0,0
@@ edu.stanford.nlp.util.StringUtils.propFileToLinkedHashMap,11,14,13,13,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.getNgrams,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.getNgramsFromTokens,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.getCharacterNgrams,10,13,36,16,44.44444444444444,0,0
@@ edu.stanford.nlp.util.StringUtils.levenshteinDistance,16,21,67,24,35.82089552238806,0,0
@@ edu.stanford.nlp.util.StringUtils.levenshteinDistance,16,21,67,24,35.82089552238806,0,1
@@ edu.stanford.nlp.util.StringUtils.unescapeHtml3,34,50,222,43,19.36936936936937,0,0
@@ edu.stanford.nlp.util.StringUtils.decodeArray,41,62,170,59,34.705882352941174,0,1
@@ edu.stanford.nlp.util.StringUtils.decodeMap,61,94,295,67,22.71186440677966,0,0
@@ edu.stanford.nlp.util.StringUtils.expandEnvironmentVariables,8,9,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.util.StringUtils.logInvocationString,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.util.StringUtils.containsJsonEscape,9,12,17,12,70.58823529411765,0,0
@@ edu.stanford.nlp.util.StringUtils.escapeJsonString,18,25,36,31,86.11111111111111,0,0
@@ edu.stanford.nlp.util.StringUtils.indexOfRegex,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.indexOfRegex,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.lambda$joinMultipleFields$1,10,12,13,13,100.0,0,0
@@ edu.stanford.nlp.util.StringUtils.lambda$joinFields$0,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.util.Quintuple.equals,31,47,87,87,100.0,0,0
@@ edu.stanford.nlp.util.Quintuple.hashCode,17,21,26,26,100.0,0,0
@@ edu.stanford.nlp.util.Quintuple.compareTo,10,13,20,20,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap$1.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap$1.lambda$iterator$1,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap$1.lambda$iterator$0,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.IterableIterator.iterator,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.util.IterableIterator.spliterator,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.util.FilteredIterator$1.test,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.util.Iterables$10$1.hasNext,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.<init>,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.isTrue,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.isFalse,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.isKnown,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.isUnknown,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.toBoolean,6,8,9,9,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.toBooleanOrNull,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.and,8,11,19,19,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.or,8,11,19,19,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.not,6,8,11,11,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.equals,12,15,16,16,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.hashCode,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.toString,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.from,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Trilean.fromString,21,37,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Filters$DisjFilter.test,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ArraySet.<init>,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.util.ArraySet.add,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.ScoredComparator.compare,13,18,26,26,100.0,0,1
@@ edu.stanford.nlp.util.ScoredComparator.equals,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.util.ScoredComparator.hashCode,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ScoredComparator.toString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Pair.equals,14,20,27,27,100.0,0,0
@@ edu.stanford.nlp.util.Pair.hashCode,8,9,13,13,100.0,0,0
@@ edu.stanford.nlp.util.Pair.compareTo,10,14,15,15,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils$1.hasNext,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils$1.next,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils$1.remove,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap$SimpleEntry.equals,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap$SimpleEntry.hashCode,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap$SimpleEntry.eq,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.util.Iterables$4$1.hasNext,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.util.StreamGobbler.run,8,10,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.util.ProcessProtobufRequest.processMultipleInputs,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.util.ProcessProtobufRequest.process,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.util.ProcessProtobufRequest.lambda$leftoverArgs$0,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Comparators.nullSafeCompare,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Comparators.compareLists,10,13,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.util.Comparators.lambda$chain$1,6,7,11,6,54.54545454545454,0,1
@@ edu.stanford.nlp.util.Comparators.lambda$chain$0,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalSet.add,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalSet.addAll,7,8,10,8,80.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalSet.addAllKeys,7,8,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.util.TwoDimensionalSet.containsAll,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalSet.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalSet.removeAll,7,8,10,8,80.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.asList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.asList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.asIntArray,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.asDoubleArray,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.intersection,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.union,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.unionAsSet,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.unionAsSet,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.diff,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.diffAsSet,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.loadCollection,6,7,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.util.CollectionUtils.loadCollection,6,7,14,7,50.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.getMapFromString,10,12,26,19,73.07692307692307,0,0
@@ edu.stanford.nlp.util.CollectionUtils.containsObject,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.removeObject,7,8,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.util.CollectionUtils.getIndex,7,8,8,5,62.5,0,0
@@ edu.stanford.nlp.util.CollectionUtils.getIndex,9,11,11,10,90.9090909090909,0,1
@@ edu.stanford.nlp.util.CollectionUtils.sampleWithoutReplacement,9,11,23,19,82.6086956521739,0,1
@@ edu.stanford.nlp.util.CollectionUtils.sampleWithReplacement,7,8,17,13,76.47058823529412,0,1
@@ edu.stanford.nlp.util.CollectionUtils.isSubList,15,21,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.util.CollectionUtils.toVerticalString,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.util.CollectionUtils.compareLists,17,24,33,28,84.84848484848484,0,0
@@ edu.stanford.nlp.util.CollectionUtils.addAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.getNGrams,13,16,48,18,37.5,0,0
@@ edu.stanford.nlp.util.CollectionUtils.getPrefixesAndSuffixes,26,38,57,39,68.42105263157895,0,0
@@ edu.stanford.nlp.util.CollectionUtils.mergeList,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.mergeListWithSortedMatched,9,11,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.util.CollectionUtils.mergeListWithSortedMatchedPreAggregated,9,11,25,15,60.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.flatten,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.uniqueNonhashableObjects,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.containsAny,7,8,4,4,100.0,0,1
@@ edu.stanford.nlp.util.CollectionUtils.partitionIntoFolds,7,8,25,11,44.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.trainTestFoldsForCV,10,12,35,16,45.714285714285715,0,0
@@ edu.stanford.nlp.util.CollectionUtils.transformAsSet,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.transformAsList,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.filterAsList,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.getAll,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.CollectionUtils.maxIndex,8,10,17,4,23.52941176470588,0,0
@@ edu.stanford.nlp.util.IdentityHashSet.add,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.IdentityHashSet.clone,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.util.IdentityHashSet.remove,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.IdentityHashSet.writeObject,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.IdentityHashSet.readObject,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.util.Functions.invert,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex$1.hasNext,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex$1.next,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.gapEncode,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.gapEncodeList,32,44,153,29,18.954248366013072,0,0
@@ edu.stanford.nlp.util.ArrayUtils.gapDecode,5,5,4,3,75.0,0,1
@@ edu.stanford.nlp.util.ArrayUtils.gapDecodeList,23,31,90,21,23.333333333333332,0,1
@@ edu.stanford.nlp.util.ArrayUtils.deltaEncode,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.deltaEncodeList,42,58,218,40,18.34862385321101,0,1
@@ edu.stanford.nlp.util.ArrayUtils.deltaDecode,5,5,4,3,75.0,0,1
@@ edu.stanford.nlp.util.ArrayUtils.deltaDecodeList,28,39,115,26,22.608695652173914,0,1
@@ edu.stanford.nlp.util.ArrayUtils.byteArrayToBitSet,29,37,35,34,97.14285714285714,0,0
@@ edu.stanford.nlp.util.ArrayUtils.flatten,11,13,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.util.ArrayUtils.to2D,8,9,27,13,48.148148148148145,0,0
@@ edu.stanford.nlp.util.ArrayUtils.removeAt,14,19,39,23,58.97435897435898,0,0
@@ edu.stanford.nlp.util.ArrayUtils.removeAt,14,19,39,23,58.97435897435898,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toString,7,8,20,11,55.00000000000001,0,0
@@ edu.stanford.nlp.util.ArrayUtils.equalContents,16,21,25,18,72.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.equals,16,21,25,18,72.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.equalContents,9,11,19,12,63.1578947368421,0,0
@@ edu.stanford.nlp.util.ArrayUtils.equals,14,19,25,18,72.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.contains,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.filter,9,11,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.util.ArrayUtils.asImmutableSet,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.fill,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.fill,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.fill,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.fill,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.fill,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.fill,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toDouble,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toDouble,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.ArrayUtils.asList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.asPrimitiveDoubleArray,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.asPrimitiveIntArray,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ArrayUtils.copy,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toString,7,8,20,11,55.00000000000001,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toString,7,8,20,11,55.00000000000001,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toPrimitive,10,12,20,15,75.0,0,1
@@ edu.stanford.nlp.util.ArrayUtils.toPrimitive,10,12,20,15,75.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toPrimitive,10,12,20,15,75.0,0,1
@@ edu.stanford.nlp.util.ArrayUtils.toPrimitive,10,12,20,15,75.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toDoubleArray,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toPrimitive,10,12,20,15,75.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.indexOf,7,8,18,9,50.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.getSubListIndex,20,29,86,31,36.04651162790697,0,0
@@ edu.stanford.nlp.util.ArrayUtils.normalize,8,9,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.util.ArrayUtils.subArray,11,15,26,23,88.46153846153845,0,0
@@ edu.stanford.nlp.util.ArrayUtils.compareBooleanArrays,15,21,40,20,50.0,0,0
@@ edu.stanford.nlp.util.ArrayUtils.toString,8,9,25,7,28.000000000000004,0,0
@@ edu.stanford.nlp.util.Pair$MutableInternedPair.internStrings,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.add,5,5,14,14,100.0,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.get,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.uniqueLabels,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.util.ConfusionMatrix.getContingency,15,21,36,24,66.66666666666666,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.sortKeys,23,30,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.goldMarginal,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.guessMarginal,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.getPlaceHolder,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix.printTable,21,27,74,60,81.08108108108108,0,1
@@ edu.stanford.nlp.util.ConcatenationIterator.current,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.ConcatenationIterator.main,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree$TreeNodeIterator.<init>,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree$TreeNodeIterator.hasNext,7,8,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.IntervalTree$TreeNodeIterator.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree$TreeNodeIterator.getNext,20,29,74,46,62.16216216216216,0,2
@@ edu.stanford.nlp.util.FourDimensionalMap.getThreeDimensionalMap,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.util.FourDimensionalMap.values,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.FourDimensionalMap.secondKeySet,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.FourDimensionalMap.thirdKeySet,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.util.FourDimensionalMap.fourthKeySet,11,13,6,6,100.0,0,0
@@ edu.stanford.nlp.util.Filters$RandomFilter.test,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.hasNext,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.next,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.parent,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.leftChild,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.rightChild,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.compare,7,9,16,16,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.compare,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.getFirst,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.getPriority,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.getObject,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.getPriority,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.add,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.add,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.remove,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.removeEntry,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.relaxPriority,6,7,18,8,44.44444444444444,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.decreasePriority,6,7,18,8,44.44444444444444,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.changePriority,6,7,18,8,44.44444444444444,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.toSortedList,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.deepCopy,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.toString,11,15,40,16,40.0,0,0
@@ edu.stanford.nlp.util.BinaryHeapPriorityQueue.toVerticalString,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.util.Interval.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Interval.toInterval,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.Interval.toValidInterval,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Interval.max,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Interval.min,5,5,4,4,100.0,0,2
@@ edu.stanford.nlp.util.Interval.contains,20,27,32,32,100.0,0,0
@@ edu.stanford.nlp.util.Interval.containsOpen,12,15,16,16,100.0,0,1
@@ edu.stanford.nlp.util.Interval.contains,12,15,12,12,100.0,0,0
@@ edu.stanford.nlp.util.Interval.expand,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.Interval.intersect,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Interval.overlaps,15,23,22,22,100.0,0,1
@@ edu.stanford.nlp.util.Interval.includesBegin,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Interval.includesEnd,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.Interval.isIntervalComparable,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.util.Interval.compareIntervalOrder,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Interval.toRelFlags,7,8,8,5,62.5,0,0
@@ edu.stanford.nlp.util.Interval.getRelationFlags,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.Interval.addIntervalRelationFlags,30,47,81,37,45.67901234567901,0,1
@@ edu.stanford.nlp.util.Interval.checkMultipleBitSet,9,11,14,3,21.428571428571427,0,0
@@ edu.stanford.nlp.util.Interval.checkFlagSet,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Interval.checkFlagExclusiveSet,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Interval.getRelation,28,41,49,49,100.0,0,0
@@ edu.stanford.nlp.util.Interval.equals,11,15,23,23,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.hasProperty,9,12,9,9,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.hasPropertyPrefix,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.asProperties,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.printProperties,11,14,13,13,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.asMap,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.checkProperties,9,11,7,7,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.extractPrefixedProperties,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.extractSelectedProperties,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.get,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getDirPath,5,6,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getInt,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getLong,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getDouble,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getBool,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getStringArray,6,7,10,8,80.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getStringArray,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.overWriteProperties,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.util.PropertiesUtils.noClobberWriteProperties,7,8,8,8,100.0,0,1
@@ edu.stanford.nlp.util.PropertiesUtils.getSignature,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.util.PropertiesUtils.getSignature,28,41,39,34,87.17948717948718,0,1
@@ edu.stanford.nlp.util.Characters.asCharacterArray,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.Characters.unicodeBlockStringOf,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.util.Characters.unicodeBlockStringOf,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.Characters.isPunctuation,11,17,14,14,100.0,0,1
@@ edu.stanford.nlp.util.Characters.isSymbol,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Characters.isControl,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.util.TwoDimensionalMap.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap.isEmpty,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap.contains,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap.getMap,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap.values,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.util.TwoDimensionalMap.secondKeySet,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.util.TwoDimensionalMap.addAll,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap.replaceAll,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.TwoDimensionalMap.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.util.ArrayMap$Entry.hashCode,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.util.ArrayMap$Entry.equals,16,23,23,23,100.0,0,0
@@ edu.stanford.nlp.util.Iterables$7.hasNext,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.util.EditDistance.clear,9,12,23,22,95.65217391304348,0,0
@@ edu.stanford.nlp.util.EditDistance.better,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.EditDistance.substituteCost,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.EditDistance.transposeCost,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.util.EditDistance.score,24,34,115,37,32.17391304347826,0,1
@@ edu.stanford.nlp.util.EditDistance.score,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.util.EditDistance.main,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap$1$1.hasNext,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.util.XMLUtils$XMLTag.<init>,39,57,138,81,58.69565217391305,0,0
@@ edu.stanford.nlp.util.XMLUtils$XMLTag.getFirstNonNullAttributeFromList,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.util.Maps.putIntoValueCollection,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.util.Maps.compose,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.Maps.invert,5,5,2,2,100.0,0,5
@@ edu.stanford.nlp.util.Maps.invertSet,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.Maps.toStringSorted,7,8,10,5,50.0,0,0
@@ edu.stanford.nlp.util.Maps.removeKeys,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.Maps.addAll,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.Maps.getAll,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Maps.toString,7,8,13,8,61.53846153846154,0,0
@@ edu.stanford.nlp.util.DataFilePaths.convert,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.util.MemoryMonitor.getMaxAvailableMemory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.MemoryMonitor.getUsedMemory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.MemoryMonitor.getUsedMemoryString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.MemoryMonitor.getSystemFreeMemory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.MemoryMonitor.parseFields,13,18,36,27,75.0,0,1
@@ edu.stanford.nlp.util.MemoryMonitor.pollFree,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.util.MemoryMonitor.pollVMstat,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.util.MemoryMonitor.systemIsSwapping,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex.get,4,4,13,13,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex.indexOf,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex.addToIndex,9,11,23,15,65.21739130434783,0,0
@@ edu.stanford.nlp.util.DeltaIndex.indexOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex.objectsList,5,5,16,16,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex.objects,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex.contains,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.util.DeltaIndex.add,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.DeltaIndex.addAll,7,8,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.util.DeltaIndex.isEmpty,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.util.ArrayMap$1.remove,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.FilteredIterator.advanceCandidate,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.util.FilteredIterator.main,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.connect,7,9,9,9,100.0,0,0
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.existsTable,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.getCount,8,10,15,12,80.0,0,0
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.getCounts,17,23,37,30,81.08108108108108,0,1
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.populateTablesInSQL,10,12,8,8,100.0,0,0
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.getTotalCount,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.get1GramRank,10,13,16,13,81.25,0,1
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.closeConnection,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.GoogleNGramsSQLBacked.main,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Filters$CombinedFilter.test,12,16,28,28,100.0,0,0
@@ edu.stanford.nlp.util.AcronymMatcher.getTokenStrs,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.AcronymMatcher.getMainTokenStrs,9,12,9,9,100.0,0,1
@@ edu.stanford.nlp.util.AcronymMatcher.getMainTokenStrs,9,12,9,9,100.0,0,1
@@ edu.stanford.nlp.util.AcronymMatcher.isAcronymImpl,12,16,40,15,37.5,0,0
@@ edu.stanford.nlp.util.AcronymMatcher.isAcronym,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.util.AcronymMatcher.isAcronym,15,21,28,27,96.42857142857143,0,1
@@ edu.stanford.nlp.util.AcronymMatcher.isAcronym,15,21,28,27,96.42857142857143,0,0
@@ edu.stanford.nlp.util.AcronymMatcher.isFancyAcronym,9,12,14,14,100.0,0,0
@@ edu.stanford.nlp.util.AcronymMatcher.isFancyAcronymImpl,9,11,21,15,71.42857142857143,0,1
@@ edu.stanford.nlp.util.AcronymMatcher.lambda$isAcronymImpl$1,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.AcronymMatcher.lambda$getMainStrs$0,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.util.ConfusionMatrix$Contingency.toString,14,17,24,24,100.0,0,0
@@ edu.stanford.nlp.util.HashableCoreMap.<init>,5,5,11,5,45.45454545454545,0,1
@@ edu.stanford.nlp.util.HashableCoreMap.<init>,5,5,11,5,45.45454545454545,0,1
@@ edu.stanford.nlp.util.HashableCoreMap.set,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.util.HashableCoreMap.equals,11,14,21,21,100.0,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.writeLongToByteArr,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.writeBooleanToByteArr,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.writeUStringToByteArr,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.writeUStringToByteArr,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToInt,5,5,16,9,56.25,0,1
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToLong,5,5,16,9,56.25,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToBoolean,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToUString,8,9,16,10,62.5,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToUString,8,9,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToAString,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.stringUToByteArr,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.intArrToByteArr,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.intArrToByteArr,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.longArrToByteArr,8,9,22,12,54.54545454545454,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.longArrToByteArr,8,9,22,12,54.54545454545454,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.booleanArrToByteArr,8,9,21,9,42.857142857142854,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.booleanArrToByteArr,8,9,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.charArrToByteArr,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.charArrToByteArr,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.floatArrToByteArr,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.floatArrToByteArr,5,5,14,10,71.42857142857143,0,1
@@ edu.stanford.nlp.util.ConvertByteArray.doubleArrToByteArr,8,9,25,14,56.00000000000001,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.doubleArrToByteArr,8,9,25,14,56.00000000000001,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.shortArrToByteArr,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.shortArrToByteArr,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.uStringArrToByteArr,13,16,53,24,45.28301886792453,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.uStringArrToByteArr,8,9,27,11,40.74074074074074,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.aStringArrToByteArr,13,16,53,24,45.28301886792453,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.aStringArrToByteArr,8,9,27,11,40.74074074074074,0,1
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToIntArr,8,9,28,17,60.71428571428571,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToIntArr,8,9,30,19,63.33333333333333,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToLongArr,8,9,23,12,52.17391304347826,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToLongArr,8,9,24,13,54.166666666666664,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToBooleanArr,8,9,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToBooleanArr,8,9,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToCharArr,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToCharArr,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToShortArr,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToShortArr,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToFloatArr,8,9,28,15,53.57142857142857,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToFloatArr,8,9,28,15,53.57142857142857,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToDoubleArr,8,9,24,11,45.83333333333333,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToDoubleArr,8,9,24,11,45.83333333333333,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToUStringArr,11,13,32,21,65.625,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToUStringArr,8,9,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToUStringArr,8,9,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToAStringArr,11,13,32,21,65.625,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToAStringArr,8,9,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.util.ConvertByteArray.byteArrToAStringArr,8,9,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.util.PaddedList.get,5,6,11,11,100.0,0,1
@@ edu.stanford.nlp.util.PaddedList.sameInnerList,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.readName,7,9,22,15,68.18181818181817,0,1
@@ edu.stanford.nlp.util.StringParsingTask.readJavaIdentifier,8,11,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.util.StringParsingTask.readLeftParen,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.readRightParen,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.readDot,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.readWhiteSpace,6,7,10,7,70.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.read,5,6,14,14,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.isWhiteSpace,9,13,10,10,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.isPunct,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.isLeftParen,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.isRightParen,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.StringParsingTask.isDot,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.Filters$CollectionAcceptFilter.test,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.util.TreeShapedStack.pop,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.TreeShapedStack.peek,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.TreeShapedStack.asList,5,5,16,10,62.5,0,0
@@ edu.stanford.nlp.util.TreeShapedStack.internalToString,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.util.TreeShapedStack.hashCode,5,6,8,7,87.5,0,0
@@ edu.stanford.nlp.util.TreeShapedStack.equals,15,21,38,30,78.94736842105263,0,0
@@ edu.stanford.nlp.util.Iterables$8$1.hasNext,7,8,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.util.Iterables$8$1.next,5,6,8,8,100.0,0,1
@@ edu.stanford.nlp.util.Iterables$8$1.nextPair,15,20,49,25,51.02040816326531,0,0
@@ edu.stanford.nlp.util.MutableLong.equals,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.util.MutableLong.compareTo,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.DeltaMap$1.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.util.DeltaMap$1.lambda$iterator$1,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.DeltaMap$1.lambda$iterator$0,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.RegexStringFilter.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.util.DeltaMap$SimpleEntry.equals,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.util.DeltaMap$SimpleEntry.hashCode,8,9,11,11,100.0,0,1
@@ edu.stanford.nlp.util.DeltaMap$SimpleEntry.eq,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.util.CacheMap.create,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.util.CacheMap.write,10,13,19,19,100.0,0,0
@@ edu.stanford.nlp.util.CacheMap.removeEldestEntry,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.CacheMap.get,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.util.CacheMap.put,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Interner.intern,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.util.Interner.internAll,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.util.Interner.main,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.util.FuzzyInterval.toInterval,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.FuzzyInterval.toValidInterval,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.FuzzyInterval.getRelationFlags,18,23,73,41,56.16438356164384,0,1
@@ edu.stanford.nlp.util.FuzzyInterval.restrictFlags,26,37,155,12,7.741935483870968,0,0
@@ edu.stanford.nlp.util.FuzzyInterval.getRelation,18,25,27,27,100.0,0,1
@@ edu.stanford.nlp.util.ArrayCoreMap.<init>,5,5,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.get,9,11,28,19,67.85714285714286,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.set,12,15,47,36,76.59574468085107,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.keySetNotNull,7,8,22,12,54.54545454545454,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.remove,9,11,42,26,61.904761904761905,0,1
@@ edu.stanford.nlp.util.ArrayCoreMap.containsKey,7,8,20,13,65.0,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.compact,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.setCapacity,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.toString,12,15,38,29,76.31578947368422,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.toShorterString,25,35,73,39,53.42465753424658,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.toShortString,21,28,47,29,61.702127659574465,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.equals,22,31,35,35,100.0,0,1
@@ edu.stanford.nlp.util.ArrayCoreMap.equals,29,42,119,66,55.46218487394958,0,0
@@ edu.stanford.nlp.util.ArrayCoreMap.hashCode,23,31,70,36,51.42857142857142,0,1
@@ edu.stanford.nlp.util.ArrayCoreMap.prettyLog,8,9,10,10,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap.get,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap.add,6,7,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap.addAll,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap.removeMapping,8,11,23,17,73.91304347826086,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap.containsKey,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap.clear,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.DeltaCollectionValuedMap.isEmpty,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.MutableInteger.equals,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.MutableInteger.compareTo,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.UTF8EquivalenceFunction.apply,7,9,8,8,100.0,0,0
@@ edu.stanford.nlp.util.MaxSizeConcurrentHashSet.add,8,10,16,16,100.0,0,0
@@ edu.stanford.nlp.util.MaxSizeConcurrentHashSet.remove,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.MaxSizeConcurrentHashSet.addAll,7,8,10,8,80.0,0,1
@@ edu.stanford.nlp.util.Quadruple.equals,26,39,71,71,100.0,0,0
@@ edu.stanford.nlp.util.Quadruple.hashCode,14,17,21,21,100.0,0,0
@@ edu.stanford.nlp.util.Quadruple.compareTo,8,10,15,15,100.0,0,1
@@ edu.stanford.nlp.util.SystemUtils$WriterThread.run,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.util.HashIndex.indices,5,5,5,4,80.0,0,0
@@ edu.stanford.nlp.util.HashIndex.get,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.util.HashIndex.indexOf,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.HashIndex.addToIndex,8,10,21,19,90.47619047619048,0,0
@@ edu.stanford.nlp.util.HashIndex.addToIndexUnsafe,8,10,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.util.HashIndex.indexOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.HashIndex.addAll,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.util.HashIndex.add,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.util.HashIndex.saveToFilename,9,11,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.util.HashIndex.loadFromFilename,12,16,18,18,100.0,0,0
@@ edu.stanford.nlp.util.HashIndex.saveToWriter,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.util.HashIndex.loadFromReader,9,12,24,13,54.166666666666664,0,0
@@ edu.stanford.nlp.util.HashIndex.toString,11,14,35,18,51.42857142857142,0,1
@@ edu.stanford.nlp.util.HashIndex.toStringOneEntryPerLine,11,14,35,18,51.42857142857142,0,0
@@ edu.stanford.nlp.util.HashIndex.loadFromFileWithList,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.util.HashIndex.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.util.Filters.filter,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Filters.retainAll,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.XMLUtils$SAXErrorHandler.makeBetterErrorString,8,10,16,15,93.75,0,0
@@ edu.stanford.nlp.util.IntervalTree$TreeNode.isEmpty,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ByteStreamGobbler.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.ByteStreamGobbler.run,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.util.FiveDimensionalMap.getFourDimensionalMap,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.util.FiveDimensionalMap.values,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.FiveDimensionalMap.secondKeySet,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.FiveDimensionalMap.thirdKeySet,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.util.FiveDimensionalMap.fourthKeySet,11,13,6,6,100.0,0,0
@@ edu.stanford.nlp.util.FiveDimensionalMap.fifthKeySet,14,17,7,7,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.add,26,37,150,36,24.0,0,1
@@ edu.stanford.nlp.util.IntervalTree.removeAll,7,8,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.util.IntervalTree.remove,42,61,134,134,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.adjustUpwards,18,24,87,19,21.839080459770116,0,0
@@ edu.stanford.nlp.util.IntervalTree.check,57,85,195,126,64.61538461538461,0,1
@@ edu.stanford.nlp.util.IntervalTree.isAlphaBalanced,12,15,23,23,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.balance,16,22,39,30,76.92307692307693,0,0
@@ edu.stanford.nlp.util.IntervalTree.rotateUp,14,19,86,8,9.30232558139535,0,1
@@ edu.stanford.nlp.util.IntervalTree.rightRotate,14,20,48,48,100.0,0,1
@@ edu.stanford.nlp.util.IntervalTree.leftRotate,14,20,48,48,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.height,10,12,19,19,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.getLeftmostNode,5,5,14,4,28.57142857142857,0,0
@@ edu.stanford.nlp.util.IntervalTree.getRightmostNode,5,5,14,4,28.57142857142857,0,0
@@ edu.stanford.nlp.util.IntervalTree.getNode,16,21,75,16,21.333333333333336,0,0
@@ edu.stanford.nlp.util.IntervalTree.addNonOverlapping,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.addNonNested,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.getOverlapping,18,25,46,46,100.0,0,1
@@ edu.stanford.nlp.util.IntervalTree.overlaps,18,25,43,43,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.contains,18,25,43,43,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.getNonOverlapping,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree.getNonOverlappingMaxScore,34,48,139,44,31.654676258992804,0,0
@@ edu.stanford.nlp.util.IntervalTree.getNonNested,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.Generics.getHashSetClass,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.Generics.newHashSet,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Generics.getHashMapClass,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.Generics.newHashMap,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.<init>,5,5,11,5,45.45454545454545,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.hasNext,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.add,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.getFirst,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.getPriority,7,8,22,13,59.09090909090909,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.getPriority,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.toSortedList,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.grow,4,4,13,13,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.heapifyUp,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.heapifyDown,11,16,43,34,79.06976744186046,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.toString,15,20,39,23,58.97435897435898,0,0
@@ edu.stanford.nlp.util.FixedPrioritiesPriorityQueue.clone,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.Triple.equals,11,15,31,31,100.0,0,0
@@ edu.stanford.nlp.util.Triple.hashCode,11,13,16,16,100.0,0,0
@@ edu.stanford.nlp.util.Triple.compareTo,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.util.MapList.size,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.MapList.get,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.util.MapList.ensureList,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.util.SystemUtils.run,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.SystemUtils.consume,6,7,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.util.SystemUtils.runShellCommand,18,25,24,24,100.0,0,0
@@ edu.stanford.nlp.util.SystemUtils.main,5,5,8,4,50.0,0,1
@@ edu.stanford.nlp.util.Sets.map,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.Sets.cross,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Sets.diff,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.Sets.symmetricDiff,12,15,14,14,100.0,0,0
@@ edu.stanford.nlp.util.Sets.intersects,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Sets.powerSet,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.util.Sets.assertEquals,26,36,40,40,100.0,0,0
@@ edu.stanford.nlp.util.Beam.asSortedList,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.Beam.add,7,8,10,8,80.0,0,0
@@ edu.stanford.nlp.util.ArrayStringFilter.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.ArrayStringFilter.test,23,32,76,55,72.36842105263158,0,0
@@ edu.stanford.nlp.util.ArrayStringFilter.hashCode,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.util.ArrayStringFilter.equals,9,12,27,27,100.0,0,1
@@ edu.stanford.nlp.util.ArgumentParser.fillField,22,30,52,44,84.61538461538461,0,0
@@ edu.stanford.nlp.util.ArgumentParser.filePathToClass,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.getVisibleClasses,30,42,32,32,100.0,0,1
@@ edu.stanford.nlp.util.ArgumentParser.scrapeFields,6,7,12,5,41.66666666666667,0,1
@@ edu.stanford.nlp.util.ArgumentParser.threadRootClass,8,11,27,9,33.33333333333333,0,1
@@ edu.stanford.nlp.util.ArgumentParser.bufferString,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.fillOptionsImpl,80,122,208,142,68.26923076923077,0,1
@@ edu.stanford.nlp.util.ArgumentParser.fillOptions,4,4,5,4,80.0,0,1
@@ edu.stanford.nlp.util.ArgumentParser.fillOptions,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.updatePropertiesWithOptions,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.usage,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.lambda$usage$11,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.lambda$usage$4,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.lambda$listOptions$3,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.ArgumentParser.lambda$listOptions$2,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.util.FastDisjointSet.linkElements,6,7,22,22,100.0,0,1
@@ edu.stanford.nlp.util.FastDisjointSet.findElement,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.util.FastDisjointSet.find,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.FastDisjointSet.union,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.util.FastDisjointSet.<init>,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.MapFactory$TreeMapFactory.newMap,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.MapFactory$TreeMapFactory.newSet,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.util.MapFactory$TreeMapFactory.setMap,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.util.MapFactory$TreeMapFactory.setMap,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Iterables.chain,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.Iterables.toString,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.util.Iterables.sample,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.util.CoreMaps.merge,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.util.CoreMaps.merge,8,9,6,6,100.0,0,1
@@ edu.stanford.nlp.util.CoreMaps.asMap,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.CoreMaps.dumpCoreMapToStringBuilder,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.samePrimitive,9,12,12,12,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.superDistance,17,23,28,21,75.0,0,1
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.construct,26,34,83,49,59.036144578313255,0,0
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.<init>,7,8,21,12,57.14285714285714,0,0
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.<init>,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.createInstance,6,7,16,12,75.0,0,0
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.MetaClass$ClassFactory.equals,11,14,33,26,78.78787878787878,0,1
@@ edu.stanford.nlp.util.LeastRecentlyUsedCache.getOrDefault,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.util.LeastRecentlyUsedCache.add,6,7,21,21,100.0,0,1
@@ edu.stanford.nlp.util.BoundedPriorityQueue.add,11,15,23,23,100.0,0,0
@@ edu.stanford.nlp.util.ArrayHeap.parent,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.ArrayHeap.leftChild,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.util.ArrayHeap.rightChild,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.util.ArrayHeap.getEntry,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.util.ArrayHeap.heapifyUp,8,9,19,16,84.21052631578947,0,0
@@ edu.stanford.nlp.util.ArrayHeap.extractMin,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.util.ArrayHeap.decreaseKey,5,6,20,20,100.0,0,0
@@ edu.stanford.nlp.util.ArrayHeap.iterator,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.util.ArrayHeap.dump,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.util.ArrayHeap.verify,10,13,35,17,48.57142857142857,0,1
@@ edu.stanford.nlp.util.ArrayHeap.toString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.Iterables$2$1.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.Iterables$2$1.prepare,8,10,20,20,100.0,0,0
@@ edu.stanford.nlp.util.IntervalTree$ContainsIntervalFunction.test,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.util.Lazy.simulateGC,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.Lazy.get,9,12,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.util.Lazy.getIfDefined,7,9,14,14,100.0,0,1
@@ edu.stanford.nlp.util.Lazy.isGarbageCollected,7,9,10,10,100.0,0,1
@@ edu.stanford.nlp.util.CollectionValuedMap.get,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.add,10,12,33,30,90.9090909090909,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.addAll,13,17,36,35,97.22222222222221,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.addKey,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.addAll,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.addAll,17,23,48,39,81.25,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.removeAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.removeMapping,11,14,31,29,93.54838709677419,0,1
@@ edu.stanford.nlp.util.CollectionValuedMap.allValues,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.equals,17,24,28,28,100.0,0,1
@@ edu.stanford.nlp.util.CollectionValuedMap.toString,13,16,18,18,100.0,0,1
@@ edu.stanford.nlp.util.CollectionValuedMap.<init>,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.util.CollectionValuedMap.<init>,8,9,2,2,100.0,0,1
@@ edu.stanford.nlp.util.DeltaMap$1$1NullingIterator.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.LeastRecentlyUsedCache$LinkedList.pop,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex$2.hasNext,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.get,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.indexOf,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.addToIndex,11,15,38,37,97.36842105263158,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.indexOf,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.add,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.addAll,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.saveToWriter,7,8,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.saveToFilename,9,11,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.toString,10,13,32,17,53.125,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashIndex.contains,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.MulticoreWrapper$QueueItem.equals,9,11,15,15,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.InterruptibleMulticoreWrapper$NamedTask.<init>,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashCounter$2.isEmpty,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashCounter$2.contains,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.MulticoreWrapper.<init>,8,9,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.util.concurrent.MulticoreWrapper.put,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.MulticoreWrapper.join,12,15,31,23,74.19354838709677,0,1
@@ edu.stanford.nlp.util.concurrent.MulticoreWrapper.peek,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.MulticoreWrapper.poll,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashCounter.getCount,5,5,5,5,100.0,0,1
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashCounter.remove,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.ConcurrentHashCounter.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.InterruptibleMulticoreWrapper.getProcessor,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.InterruptibleMulticoreWrapper.joinWithTimeout,15,20,50,27,54.0,0,0
@@ edu.stanford.nlp.util.concurrent.InterruptibleMulticoreWrapper.shutdownNow,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.SynchronizedInterner.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.SynchronizedInterner.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.concurrent.SynchronizedInterner.main,11,13,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.util.concurrent.SynchronizedInterner.lambda$main$0,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration$1.matches,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$Util.revConcat,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$Util.fail,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$Util.endTrackIfOpen,5,6,3,3,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood$Util.threadAndRun,13,18,15,15,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$Util.printChannels,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler$ExactRepeatSemantics.equals,9,13,24,24,100.0,0,1
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$6.<init>,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.util.logging.JavaUtilLoggingAdaptor$RedwoodHandler.publish,11,14,29,17,58.620689655172406,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$5.<init>,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood$Util$1.next,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood$Util$1.lambda$next$0,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodPrintStream.log,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodPrintStream.logf,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodPrintStream.logB,11,13,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.util.logging.RedwoodPrintStream.println,13,16,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.util.logging.RedwoodPrintStream.println,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler$ApproximateRepeatSemantics.equals,12,15,20,20,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers.lambda$branch$5,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$7.buildChain,5,5,14,14,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration$Handlers$7.apply,5,5,12,12,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$FileHandler.print,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler.flush,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler.flushParents,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler.recordVerdict,10,13,27,21,77.77777777777779,0,0
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler.internalHandle,12,16,50,50,100.0,0,1
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler.handle,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler.signalStartTrack,9,11,20,20,100.0,0,1
@@ edu.stanford.nlp.util.logging.RepeatedRecordHandler.signalEndTrack,8,10,24,24,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$Record.sort,14,22,42,42,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$Record.force,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$Record.lambda$sort$0,12,17,18,18,100.0,0,1
@@ edu.stanford.nlp.util.logging.JavaUtilLoggingAdaptor.adapt,12,16,15,9,60.0,0,1
@@ edu.stanford.nlp.util.logging.JavaUtilLoggingAdaptor.main,6,7,7,7,100.0,0,1
@@ edu.stanford.nlp.util.logging.OutputHandler.getSourceStringAndLevel,17,23,31,14,45.16129032258064,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.colorChannel,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.styleChannel,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.setColorChannels,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.style,11,16,27,27,100.0,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.formatChannel,18,26,64,56,87.5,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.writeContent,7,8,20,16,80.0,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.handle,76,110,306,157,51.307189542483655,0,1
@@ edu.stanford.nlp.util.logging.OutputHandler.signalStartTrack,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.util.logging.OutputHandler.signalEndTrack,19,25,63,59,93.65079365079364,0,0
@@ edu.stanford.nlp.util.logging.JavaUtilLoggingHandler.print,8,12,23,23,100.0,0,0
@@ edu.stanford.nlp.util.logging.LogFilter$HasChannel.matches,7,8,6,6,100.0,0,1
@@ edu.stanford.nlp.util.logging.StanfordRedwoodConfiguration.apply,6,7,7,7,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood.queueTask,15,23,35,35,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood.releaseThreadControl,10,15,14,14,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood.attemptThreadControl,12,16,20,16,80.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.attemptThreadControlThreadsafe,34,54,86,55,63.95348837209303,0,1
@@ edu.stanford.nlp.util.logging.Redwood.getHandler,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.captureSystemStreams,8,9,10,10,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood.log,9,11,16,16,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.startTrack,13,16,13,13,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood.endTrack,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.startThreads,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.finishThread,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.endThreads,50,76,77,60,77.92207792207793,0,0
@@ edu.stanford.nlp.util.logging.Redwood.hideChannelsEverywhere,9,11,5,5,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.stop,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.formatTimeDifference,22,30,31,31,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood.main,59,77,135,59,43.7037037037037,0,1
@@ edu.stanford.nlp.util.logging.Redwood.lambda$main$8,5,5,8,4,50.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood.lambda$endTrack$4,13,20,26,26,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.lambda$startTrack$3,13,19,26,26,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood.lambda$log$0,10,15,18,18,100.0,0,0
@@ edu.stanford.nlp.util.logging.Style.apply,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.util.logging.SLF4JHandler.handle,12,19,33,33,100.0,0,0
@@ edu.stanford.nlp.util.logging.SLF4JHandler.print,12,18,41,33,80.48780487804879,0,0
@@ edu.stanford.nlp.util.logging.VisibilityHandler.<init>,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.util.logging.VisibilityHandler.alsoShow,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.util.logging.VisibilityHandler.alsoHide,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.util.logging.VisibilityHandler.handle,25,34,47,33,70.2127659574468,0,0
@@ edu.stanford.nlp.util.logging.PrettyLogger.log,59,81,165,123,74.54545454545455,0,1
@@ edu.stanford.nlp.util.logging.PrettyLogger.dispatchable,11,16,12,12,100.0,0,1
@@ edu.stanford.nlp.util.logging.PrettyLogger.log,25,34,43,38,88.37209302325581,0,0
@@ edu.stanford.nlp.util.logging.PrettyLogger.log,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.util.logging.PrettyLogger.log,16,21,30,21,70.0,0,0
@@ edu.stanford.nlp.util.logging.PrettyLogger.log,12,15,20,15,75.0,0,0
@@ edu.stanford.nlp.util.logging.PrettyLogger.lambda$log$0,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedirectOutputHandler.shouldLogChannels,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedirectOutputHandler.print,16,21,37,22,59.45945945945946,0,1
@@ edu.stanford.nlp.util.logging.RedirectOutputHandler.formatChannel,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.util.logging.RerouteChannel.handle,7,8,29,22,75.86206896551724,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree$1.<init>,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree$1.next,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree$1.remove,12,16,26,26,100.0,0,0
@@ edu.stanford.nlp.util.logging.BooleanLogRecordHandler.handle,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree.addChild,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree.addChildTree,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree.removeChild,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree.find,9,11,13,13,100.0,0,1
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree.append,4,4,7,6,85.71428571428571,0,1
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree.process,25,37,66,60,90.9090909090909,0,0
@@ edu.stanford.nlp.util.logging.Redwood$RecordHandlerTree.toStringHelper,11,13,20,16,80.0,0,0
@@ edu.stanford.nlp.util.logging.FilterHandler.propagateRecord,14,19,17,17,100.0,0,1
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.capture,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.restore,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.output,11,15,14,14,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.handlers,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.parse,26,37,84,60,71.42857142857143,0,1
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.lambda$restore$3,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.lambda$restore$2,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.lambda$capture$1,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.util.logging.RedwoodConfiguration.lambda$capture$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.util.logging.Color.apply,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhatIs,84,139,316,113,35.75949367088608,0,1
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhNNWill,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhNNIs,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhNNHaveIs,30,47,61,61,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhNNHaveNN,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhatIsThere,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhereDo,19,27,42,36,85.71428571428571,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhereIs,14,19,33,33,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhoIs,25,37,73,53,72.6027397260274,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhoDid,26,40,74,40,54.054054054054056,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhatDo,19,28,39,39,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhenDo,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processWhatHave,9,11,20,20,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processHow,14,21,37,27,72.97297297297297,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.processHowMuchDo,6,7,14,14,100.0,0,1
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.postProcess,121,205,86,51,59.30232558139535,0,1
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.toStatement,32,46,177,177,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.main,11,13,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.lambda$main$5,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.lambda$main$4,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.lambda$postProcess$3,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.naturalli.QuestionToStatementTranslator.lambda$processWhatIs$0,8,11,10,10,100.0,0,0
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter$4.<init>,8,9,12,12,100.0,0,1
@@ edu.stanford.nlp.naturalli.NaturalLogicRelation.byFixedIndex,10,16,16,16,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicRelation.join,29,54,87,87,100.0,0,1
@@ edu.stanford.nlp.naturalli.NaturalLogicRelation.applyToTruthValue,12,16,24,24,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicRelation.forDependencyInsertion,24,38,24,24,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicRelation.insertionToDeletion,10,16,24,24,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.getGeneralizedSubtreeSpan,11,15,22,16,72.72727272727273,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.getModifierSubtreeSpan,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.excludeFromSpan,9,12,42,42,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.computeScope,24,33,151,66,43.70860927152318,0,15
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.validateQuantifierByHead,18,24,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.addNegationToDependencyGraph,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.annotateOperators,71,103,178,92,51.68539325842697,0,3
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.annotateUnaries,28,40,67,54,80.59701492537313,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.annotatePolarity,43,61,88,67,76.13636363636364,0,1
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.doOneSentence,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.requirementsSatisfied,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.lambda$validateQuantifierByHead$2,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicAnnotator.lambda$getGeneralizedSubtreeSpan$0,7,9,8,8,100.0,0,0
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter$2.<init>,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.naturalli.ForwardEntailer.apply,8,10,10,10,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$8.isSimpleSplit,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$8.apply,43,60,109,84,77.06422018348624,0,1
@@ edu.stanford.nlp.naturalli.Operator.isUnary,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.naturalli.Operator.monoFromString,25,45,15,15,100.0,0,0
@@ edu.stanford.nlp.naturalli.Operator.monotonicitySignature,14,24,30,30,100.0,0,0
@@ edu.stanford.nlp.naturalli.Operator.fromString,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$State.withIsDone,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.naturalli.ForwardEntailerSearchProblem.searchImplementation,122,184,298,226,75.83892617449665,0,1
@@ edu.stanford.nlp.naturalli.ForwardEntailerSearchProblem.aggregateDeletedEdges,12,15,25,8,32.0,0,1
@@ edu.stanford.nlp.naturalli.ForwardEntailerSearchProblem.lambda$searchImplementation$5,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.naturalli.ForwardEntailerSearchProblem.lambda$searchImplementation$4,11,15,15,15,100.0,0,1
@@ edu.stanford.nlp.naturalli.ForwardEntailerSearchProblem.lambda$searchImplementation$3,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.naturalli.ForwardEntailerSearchProblem.lambda$searchImplementation$2,11,17,14,14,100.0,0,0
@@ edu.stanford.nlp.naturalli.ForwardEntailerSearchProblem.lambda$search$1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.Util.guessNER,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.naturalli.Util.extractNER,39,59,163,75,46.012269938650306,0,1
@@ edu.stanford.nlp.naturalli.Util.verifyRemoval,12,16,16,16,100.0,0,0
@@ edu.stanford.nlp.naturalli.Util.cleanTree,120,174,212,139,65.56603773584906,0,2
@@ edu.stanford.nlp.naturalli.Util.stripPrepCases,20,28,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.naturalli.Util.isCyclic,14,18,36,15,41.66666666666667,0,0
@@ edu.stanford.nlp.naturalli.Util.isTree,34,47,39,31,79.48717948717949,0,5
@@ edu.stanford.nlp.naturalli.Util.tokensToSpan,10,13,24,2,8.333333333333332,0,0
@@ edu.stanford.nlp.naturalli.Util.lambda$dumpAccuracy$1,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.naturalli.Util.lambda$dumpAccuracy$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIEDemo.main,14,17,16,13,81.25,0,0
@@ edu.stanford.nlp.naturalli.SentenceFragment.<init>,5,5,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.naturalli.SentenceFragment.paddedWords,11,13,19,8,42.10526315789473,0,0
@@ edu.stanford.nlp.naturalli.SentenceFragment.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.naturalli.SentenceFragment.toString,12,15,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.<init>,13,16,29,29,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.clausesInSentence,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.entailmentsFromClause,24,35,57,57,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.entailmentsFromClauses,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.canonicalizeCoref,17,23,31,26,83.87096774193549,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.annotateSentence,14,20,38,31,81.57894736842105,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.annotate,30,44,77,53,68.83116883116884,0,1
@@ edu.stanford.nlp.naturalli.OpenIE.requires,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.tripleToString,7,10,18,18,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.processDocument,15,19,16,12,75.0,0,1
@@ edu.stanford.nlp.naturalli.OpenIE.main,41,58,75,53,70.66666666666667,0,9
@@ edu.stanford.nlp.naturalli.OpenIE.lambda$main$9,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.lambda$main$7,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.lambda$grokCorefMention$5,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.OpenIE.lambda$grokCorefMention$3,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.CreateClauseDataset.toSpan,12,17,24,6,25.0,0,0
@@ edu.stanford.nlp.naturalli.CreateClauseDataset.process,17,23,19,19,100.0,0,0
@@ edu.stanford.nlp.naturalli.CreateClauseDataset.subjectObjectPairs,43,63,77,65,84.4155844155844,0,1
@@ edu.stanford.nlp.naturalli.CreateClauseDataset.findTraceTargets,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.naturalli.CreateClauseDataset.findTraceSources,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.naturalli.CreateClauseDataset.countDatums,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.naturalli.CreateClauseDataset.processDirectory,10,12,16,13,81.25,0,0
@@ edu.stanford.nlp.naturalli.Polarity.<init>,13,16,39,21,53.84615384615385,0,1
@@ edu.stanford.nlp.naturalli.Polarity.<init>,10,13,25,15,60.0,0,0
@@ edu.stanford.nlp.naturalli.Polarity.project,42,78,127,127,100.0,0,1
@@ edu.stanford.nlp.naturalli.Polarity.isUpwards,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.naturalli.Polarity.isDownwards,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.naturalli.Polarity.toString,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.naturalli.Polarity.equals,39,68,18,18,100.0,0,0
@@ edu.stanford.nlp.naturalli.Polarity.hashCode,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$6.prerequisitesMet,10,13,8,8,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$6.applyTo,11,14,20,20,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$6.lambda$applyTo$0,11,16,19,19,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$4.prerequisitesMet,17,24,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$4.applyTo,11,13,17,17,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$4.lambda$applyTo$0,8,11,13,13,100.0,0,0
@@ edu.stanford.nlp.naturalli.Operator$2.<init>,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$3.prerequisitesMet,9,13,10,10,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$3.applyTo,11,13,16,16,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$3.lambda$applyTo$0,10,14,15,15,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.<init>,11,14,15,15,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.splitToChildOfEdge,23,31,30,30,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.simpleClause,16,21,20,20,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.addSubtree,26,36,48,48,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.stripAuxMark,12,16,12,12,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.search,7,8,18,18,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.search,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.orderActions,10,12,13,13,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.search,60,90,159,121,76.10062893081762,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.lambda$null$2,16,23,24,24,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem.lambda$topClauses$0,16,24,28,28,100.0,0,0
@@ edu.stanford.nlp.naturalli.OperatorSpec.<init>,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.naturalli.OperatorSpec.isExplicit,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.naturalli.OperatorSpec.isBinary,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.naturalli.OperatorSpec.merge,11,16,45,45,100.0,0,0
@@ edu.stanford.nlp.naturalli.OperatorSpec.equals,22,31,71,71,100.0,0,0
@@ edu.stanford.nlp.naturalli.OperatorSpec.hashCode,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitter$ClauseClassifierLabel.fromIndex,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$5.prerequisitesMet,10,13,8,8,100.0,0,1
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$5.applyTo,8,10,17,17,100.0,0,0
@@ edu.stanford.nlp.naturalli.ClauseSplitterSearchProblem$5.lambda$applyTo$0,11,16,19,19,100.0,0,1
@@ edu.stanford.nlp.naturalli.NaturalLogicWeights.<init>,44,61,65,65,100.0,0,1
@@ edu.stanford.nlp.naturalli.NaturalLogicWeights.deletionProbability,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicWeights.subjDeletionProbability,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicWeights.objDeletionProbability,19,27,50,25,50.0,0,0
@@ edu.stanford.nlp.naturalli.NaturalLogicWeights.ppDeletionProbability,24,35,90,35,38.88888888888889,0,5
@@ edu.stanford.nlp.naturalli.NaturalLogicWeights.deletionProbability,15,20,26,26,100.0,0,0
@@ edu.stanford.nlp.naturalli.VerbTense.of,18,26,26,26,100.0,0,0
@@ edu.stanford.nlp.naturalli.VerbTense.conjugateEnglish,18,25,40,34,85.0,0,0
@@ edu.stanford.nlp.naturalli.VerbTense.lambda$static$0,12,16,15,15,100.0,0,0
@@ edu.stanford.nlp.naturalli.Operator$3.<init>,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter.extract,116,169,278,156,56.11510791366906,0,1
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter.getValidChunk,50,76,81,61,75.30864197530865,0,1
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter.segmentVerb,77,120,173,128,73.98843930635837,0,1
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter.segmentACL,47,70,85,70,82.35294117647058,0,8
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter.segment,33,52,64,38,59.375,0,0
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter.lambda$segmentACL$1,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.RelationTripleSegmenter.lambda$extract$0,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.Operator$1.<init>,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.doFilter,13,19,43,43,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.init,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.handleSimpleCORS,18,26,59,59,100.0,0,1
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.handlePreflightCORS,32,47,89,89,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.handleInvalidCORS,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.decorateCORSProperties,13,19,26,25,96.15384615384616,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.join,14,18,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.checkRequestType,33,49,66,55,83.33333333333334,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.isOriginAllowed,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.log,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.parseAndStore,26,36,45,45,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.parseStringToSet,10,13,13,7,53.84615384615385,0,0
@@ edu.stanford.nlp.naturalli.demo.CORSFilter.isValidOrigin,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.OpenIEServlet.init,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.OpenIEServlet.annotate,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.OpenIEServlet.quote,19,29,40,35,87.5,0,0
@@ edu.stanford.nlp.naturalli.demo.OpenIEServlet.runWithPipeline,11,13,3,3,100.0,0,0
@@ edu.stanford.nlp.naturalli.demo.OpenIEServlet.doGet,10,14,24,23,95.83333333333334,0,0
@@ edu.stanford.nlp.naturalli.demo.OpenIEServlet.doGet,8,10,14,14,100.0,0,1
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.createTADetector,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.createOutDict,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.createNonDict,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.getCliqueFeatures,10,13,33,33,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.isEnglish,27,44,36,36,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.isEngPU,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.featuresC,53,79,213,213,100.0,0,1
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.dictionaryFeaturesCpC,6,7,30,30,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.featuresCpC,160,246,553,489,88.42676311030742,0,2
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.featuresCnC,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.featuresCpCp2C,33,46,126,112,88.88888888888889,0,0
@@ edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory.featuresCpCp2Cp3C,27,37,75,75,100.0,0,0
@@ edu.stanford.nlp.wordseg.NonDict2.<init>,15,21,50,41,82.0,0,1
@@ edu.stanford.nlp.wordseg.NonDict2.checkDic,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.wordseg.NonDict2.main,13,16,24,14,58.333333333333336,0,1
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$HKPostProcessor.postProcessingAnswer,5,5,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter.init,11,14,38,38,100.0,0,0
@@ edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter.shapeOf,21,30,59,50,84.7457627118644,0,0
@@ edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter.addDictionaryFeatures,36,51,165,66,40.0,0,1
@@ edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter.printConlluAnswer,8,9,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter.printAnswers,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter.tagLatticeToAnswerLattice,56,88,166,118,71.08433734939759,0,0
@@ edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter$CTBDocumentParser.apply,42,62,155,89,57.41935483870968,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$PKPostProcessor.postProcessingAnswer,6,7,20,13,65.0,0,0
@@ edu.stanford.nlp.wordseg.CorpusChar.readDict,7,8,16,15,93.75,0,0
@@ edu.stanford.nlp.wordseg.CorpusChar.getTag,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.wordseg.CorpusDictionary.<init>,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.wordseg.CorpusDictionary.readDict,19,25,32,30,93.75,0,1
@@ edu.stanford.nlp.wordseg.CorpusDictionary.getW,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.wordseg.TagAffixDetector.<init>,21,31,64,39,60.9375,0,0
@@ edu.stanford.nlp.wordseg.TagAffixDetector.checkDic,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.wordseg.TagAffixDetector.checkInDic,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils.isLetterASCII,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils.combineSegmentedSentence,56,90,126,96,76.19047619047619,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils.postProcessingAnswer,10,13,30,30,100.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.separatePuncs,5,5,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.compilePunctuationPatterns,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.getEscapedPuncPattern,6,7,8,6,75.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.processColons,11,13,46,26,56.52173913043478,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.compileColonsWhitePatterns,6,7,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.compileColonPatterns,6,7,20,16,80.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.processDots,11,13,36,15,41.66666666666667,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$BaseChinesePostProcessor.processCommas,4,4,5,4,80.0,0,1
@@ edu.stanford.nlp.wordseg.ChineseSegmenterFeatureFactory.getCliqueFeatures,6,7,17,17,100.0,0,1
@@ edu.stanford.nlp.wordseg.ChineseSegmenterFeatureFactory.isEnglish,27,44,36,36,100.0,0,1
@@ edu.stanford.nlp.wordseg.ChineseSegmenterFeatureFactory.isEngPU,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseSegmenterFeatureFactory.featuresC,4,4,13,13,100.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseSegmenterFeatureFactory.featuresCpC,122,187,382,189,49.47643979057592,0,2
@@ edu.stanford.nlp.wordseg.ChineseSegmenterFeatureFactory.featuresCnC,9,13,40,40,100.0,0,0
@@ edu.stanford.nlp.wordseg.AffixDictionary.readDict,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.wordseg.AffixDictionary.getInDict,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseDictionary.loadDictionary,5,5,8,4,50.0,0,1
@@ edu.stanford.nlp.wordseg.ChineseDictionary.<init>,23,29,44,29,65.9090909090909,0,1
@@ edu.stanford.nlp.wordseg.ChineseDictionary.addDict,10,13,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.wordseg.ChineseDictionary.addOneDict,11,14,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.wordseg.ChineseDictionary.contains,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseDictionary.main,6,7,10,7,70.0,0,0
@@ edu.stanford.nlp.wordseg.ChineseStringUtils$CTPPostProcessor.postProcessingAnswer,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.train,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.train,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.segment,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.addStringToLexicon,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.addLexicon,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.buildSegmentationLattice,23,31,72,41,56.94444444444444,0,1
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.segmentWords,29,40,100,71,71.0,0,12
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.greedilySegmentWords,13,16,56,20,35.714285714285715,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.main,16,20,35,31,88.57142857142857,0,0
@@ edu.stanford.nlp.wordseg.MaxMatchSegmenter.postProcessSentence,9,12,14,14,100.0,0,1
@@ edu.stanford.nlp.wordseg.demo.SegDemo.main,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.optimization.SMDMinimizer.init,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.optimization.SMDMinimizer.takeStep,10,12,45,36,80.0,0,1
@@ edu.stanford.nlp.optimization.SMDMinimizer.main,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.optimization.ResultStoringMonitor.<init>,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.optimization.ResultStoringMonitor.valueAt,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.optimization.GoldenSectionLineSearch.minimize,52,73,190,89,46.8421052631579,0,1
@@ edu.stanford.nlp.optimization.GoldenSectionLineSearch.dumpMemory,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.optimization.GoldenSectionLineSearch.discretizeCompute,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.optimization.GoldenSectionLineSearch.goldenMean,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.optimization.GoldenSectionLineSearch.lambda$main$1,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffUpdateFunction.getSample,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.<init>,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.terminateOnMaxItr,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.newQNInfo,5,5,12,12,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.computeDir,10,12,32,24,75.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.plusAndConstMult,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.doEvaluation,10,13,20,18,90.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.minimize,90,134,375,284,75.73333333333333,0,1
@@ edu.stanford.nlp.optimization.QNMinimizer.projectOWL,14,18,32,22,68.75,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.l1NormOWL,10,12,13,8,61.53846153846154,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.constrainSearchDir,14,18,31,21,67.74193548387096,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.pseudoGradientOWL,20,27,85,49,57.647058823529406,0,1
@@ edu.stanford.nlp.optimization.QNMinimizer.lineSearchBacktrackOWL,22,28,79,51,64.55696202531645,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.lineSearchBacktrack,16,21,66,46,69.6969696969697,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer.lineSearchMinPack,62,101,276,180,65.21739130434783,0,1
@@ edu.stanford.nlp.optimization.QNMinimizer.getStep,51,73,201,139,69.15422885572139,0,1
@@ edu.stanford.nlp.optimization.CGMinimizer.arrayToString,11,14,34,17,50.0,0,1
@@ edu.stanford.nlp.optimization.CGMinimizer.fabs,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.CGMinimizer.fmax,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.CGMinimizer.sign,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.CGMinimizer.mnbrak,19,26,157,45,28.662420382165603,0,0
@@ edu.stanford.nlp.optimization.CGMinimizer.dbrent,75,108,450,73,16.22222222222222,0,25
@@ edu.stanford.nlp.optimization.CGMinimizer.lineMinimize,15,22,49,49,100.0,0,1
@@ edu.stanford.nlp.optimization.CGMinimizer.minimize,44,61,167,97,58.08383233532935,0,1
@@ edu.stanford.nlp.optimization.StochasticCalculateMethods.parseMethod,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.optimization.SQNMinimizer.plusAndConstMult,5,5,13,9,69.23076923076923,0,1
@@ edu.stanford.nlp.optimization.SQNMinimizer.computeDir,14,18,47,39,82.97872340425532,0,0
@@ edu.stanford.nlp.optimization.SQNMinimizer.takeStep,13,17,75,54,72.0,0,0
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer$lagrange.applyAsDouble,5,5,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.optimization.InefficientSGDMinimizer$1.derivativeAt,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.optimization.InefficientSGDMinimizer$1.valuePow,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.toContinue,10,12,25,25,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.getPrior,25,45,8,8,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.<init>,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.getNorm,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.doEvaluation,11,14,19,17,89.47368421052632,0,1
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.pospart,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.computeLearningRate,11,13,47,45,95.74468085106383,0,1
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.minimize,154,228,599,359,59.933222036727884,0,3
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.sayln,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDWithAdaGradAndFOBOS.say,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.<init>,8,11,28,28,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.sayln,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.primeFactors,17,23,96,18,18.75,0,1
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.getTestBatchSize,9,11,20,12,60.0,0,1
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.testSumOfBatches,13,16,74,54,72.97297297297297,0,1
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.testDerivatives,14,18,69,53,76.81159420289855,0,1
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.testConditionNumber,21,28,80,42,52.5,0,1
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.getVariance,5,5,38,19,50.0,0,0
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.testVariance,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.listToFile,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticDiffFunctionTester.arrayToFile,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.optimization.HybridMinimizer.setEvaluators,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.optimization.CGMinimizer$OneDimDiffFunction.vectorOf,5,5,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.optimization.CGMinimizer$OneDimDiffFunction.derivativeAt,5,5,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.optimization.AbstractCachingDiffFloatFunction.ensure,8,10,20,18,90.0,0,0
@@ edu.stanford.nlp.optimization.AbstractCachingDiffFloatFunction.norm2,5,5,4,1,25.0,0,1
@@ edu.stanford.nlp.optimization.SparseAdaGradMinimizer.minimize,16,20,56,43,76.78571428571429,0,0
@@ edu.stanford.nlp.optimization.SparseAdaGradMinimizer.getSample,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.optimization.SparseAdaGradMinimizer.sayln,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.CmdEvaluator.getCmd,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.CmdEvaluator.evaluateCmd,7,8,19,13,68.42105263157895,0,0
@@ edu.stanford.nlp.optimization.SGDToQNMinimizer.minimize,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDToQNMinimizer.sayln,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDToQNMinimizer.say,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.SMDMinimizer$1.derivativeAt,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.optimization.SMDMinimizer$1.valuePow,5,5,14,7,50.0,0,1
@@ edu.stanford.nlp.optimization.StochasticMinimizer.smooth,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticMinimizer.initFiles,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.optimization.StochasticMinimizer.tuneDouble,26,35,84,79,94.04761904761905,0,0
@@ edu.stanford.nlp.optimization.StochasticMinimizer.tuneBatch,12,16,56,25,44.642857142857146,0,0
@@ edu.stanford.nlp.optimization.StochasticMinimizer.tune,10,12,64,28,43.75,0,0
@@ edu.stanford.nlp.optimization.StochasticMinimizer.doEvaluation,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticMinimizer.minimize,41,60,180,135,75.0,0,0
@@ edu.stanford.nlp.optimization.StochasticMinimizer.sayln,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.StochasticMinimizer.say,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$QNInfo.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$QNInfo.setHistory,5,5,11,7,63.63636363636363,0,1
@@ edu.stanford.nlp.optimization.QNMinimizer$QNInfo.update,8,9,44,23,52.27272727272727,0,0
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.tuneFixedGain,14,19,75,32,42.66666666666667,0,0
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.tune,5,5,17,9,52.94117647058824,0,1
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.takeStep,10,13,50,44,88.0,0,0
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.init,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.updateDiag,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.updateDiagBFGS,13,16,49,27,55.10204081632652,0,0
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.updateDiagMinErr,13,16,60,40,66.66666666666666,0,1
@@ edu.stanford.nlp.optimization.ScaledSGDMinimizer.getRoot,13,18,45,21,46.666666666666664,0,1
@@ edu.stanford.nlp.optimization.AbstractCachingDiffFunction.gradientCheck,32,44,109,74,67.88990825688074,0,8
@@ edu.stanford.nlp.optimization.AbstractCachingDiffFunction.clearCache,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.optimization.AbstractCachingDiffFunction.randomInitial,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.optimization.AbstractCachingDiffFunction.ensure,8,10,21,19,90.47619047619048,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$Record.start,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$Record.writeToFile,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$Record.add,15,20,61,57,93.44262295081968,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$Record.monitorX,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$Record.toContinue,37,55,131,110,83.96946564885496,0,1
@@ edu.stanford.nlp.optimization.QNMinimizer$DiagonalQNInfo.applyInitialHessian,8,10,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$DiagonalQNInfo.update,33,46,139,75,53.956834532374096,0,1
@@ edu.stanford.nlp.optimization.ResultStoringFloatMonitor.<init>,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.optimization.ResultStoringFloatMonitor.valueAt,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.<init>,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.<init>,10,12,21,21,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.tryEta,8,9,39,25,64.1025641025641,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.tune,21,29,70,31,44.285714285714285,0,1
@@ edu.stanford.nlp.optimization.SGDMinimizer.getNorm,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.rescale,7,8,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.doEvaluation,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.minimize,33,47,136,99,72.79411764705883,0,0
@@ edu.stanford.nlp.optimization.SGDMinimizer.sayln,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.optimization.QNMinimizer$ScalarQNInfo.update,12,16,34,34,100.0,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.incrementRandom,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.clearCache,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.decrementBatch,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.getBatch,36,50,136,100,73.52941176470588,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.stochasticEnsure,34,51,149,110,73.8255033557047,0,1
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.getHdotVFiniteDifference,14,18,58,44,75.86206896551724,0,1
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.HdotVAt,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.HdotVAt,5,5,16,16,100.0,0,0
@@ edu.stanford.nlp.optimization.AbstractStochasticCachingDiffFunction.HdotVAt,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.optimization.InefficientSGDMinimizer.takeStep,5,5,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.optimization.InefficientSGDMinimizer.main,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.swing.FontDetector.supportedFonts,15,20,31,20,64.51612903225806,0,0
@@ edu.stanford.nlp.swing.FontDetector.hasFont,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.swing.FontDetector.main,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.swing.TooltipJList.getToolTipText,18,24,58,17,29.310344827586203,0,0
@@ edu.stanford.nlp.io.IOUtils$GetLinesIterable.getStream,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.io.NumberRangesFileFilter.<init>,10,12,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.io.NumberRangesFileFilter.accept,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.io.NumberRangesFileFilter.accept,20,29,50,26,52.0,0,1
@@ edu.stanford.nlp.io.NumberRangesFileFilter.toString,13,16,26,18,69.23076923076923,0,0
@@ edu.stanford.nlp.io.IOUtils$GetLinesIterable$1.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils$GetLinesIterable$1.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils$GetLinesIterable$1.getLine,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils$GetLinesIterable$1.getReader,6,7,23,19,82.6086956521739,0,1
@@ edu.stanford.nlp.io.IOUtils$GetLinesIterable$1.finalize,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.io.IOUtils$LineReaderIterable$1.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils$LineReaderIterable$1.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.io.ReaderInputStream.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.io.ReaderInputStream.read,13,18,38,29,76.31578947368422,0,1
@@ edu.stanford.nlp.io.ReaderInputStream.read,14,19,62,32,51.61290322580645,0,0
@@ edu.stanford.nlp.io.ReaderInputStream.available,8,10,15,15,100.0,0,1
@@ edu.stanford.nlp.io.ReaderInputStream.reset,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.io.ReaderInputStream.close,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.io.FileFilters$ConjunctionFileFilter.accept,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.io.EncodingPrintWriter$out.setupOutWriter,7,9,9,3,33.33333333333333,0,0
@@ edu.stanford.nlp.io.IOUtils$EolPreservingLineReaderIterable$1.copyUntilEol,13,17,58,35,60.3448275862069,0,0
@@ edu.stanford.nlp.io.IOUtils$EolPreservingLineReaderIterable$1.hasNext,11,14,22,14,63.63636363636363,0,1
@@ edu.stanford.nlp.io.IOUtils$EolPreservingLineReaderIterable$1.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.io.FileSystem.copyFile,12,16,13,13,100.0,0,0
@@ edu.stanford.nlp.io.FileSystem.gzipFile,13,17,17,17,100.0,0,0
@@ edu.stanford.nlp.io.FileSystem.deleteDir,10,13,10,10,100.0,0,1
@@ edu.stanford.nlp.io.FileSystem.existsAndNonEmpty,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.io.FileSystem.mkdirOrFail,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.io.FileSystem.checkExistsOrFail,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.io.FileSystem.checkNotExistsOrFail,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.io.FileSystem.main,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.io.NumberRangeFileFilter.accept,22,33,65,33,50.76923076923077,0,1
@@ edu.stanford.nlp.io.RecordIterator.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.io.RecordIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.io.RecordIterator.firstRecord,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.io.RecordIterator.determineNumFields,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.io.RecordIterator.advance,15,21,35,28,80.0,0,0
@@ edu.stanford.nlp.io.RecordIterator.main,11,14,17,7,41.17647058823529,0,1
@@ edu.stanford.nlp.io.IOUtils.writeObjectToFile,4,4,7,6,85.71428571428571,0,1
@@ edu.stanford.nlp.io.IOUtils.getBufferedOutputStream,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.io.IOUtils.writeStringToFileNoExceptions,5,5,8,6,75.0,0,0
@@ edu.stanford.nlp.io.IOUtils.writeStringToTempFile,5,5,9,7,77.77777777777779,0,1
@@ edu.stanford.nlp.io.IOUtils.writeStringToTempFileNoExceptions,5,5,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.io.IOUtils.readObjectFromFile,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readObjectFromURLOrClasspathOrFileSystem,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.lineCount,9,11,10,7,70.0,0,1
@@ edu.stanford.nlp.io.IOUtils.writeStreamFromString,5,5,6,4,66.66666666666666,0,0
@@ edu.stanford.nlp.io.IOUtils.findStreamInClassLoader,12,16,20,20,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.findStreamInClasspathOrFileSystem,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.io.IOUtils.existsInClasspathOrFileSystem,6,7,3,3,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.getInputStreamFromURLOrClasspathOrFileSystem,9,11,13,8,61.53846153846154,0,0
@@ edu.stanford.nlp.io.IOUtils.inputStreamFromFile,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readerFromFile,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.io.IOUtils.readerFromStdin,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readerFromString,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.getLineIterable,7,8,7,7,100.0,0,1
@@ edu.stanford.nlp.io.IOUtils.getLineIterable,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.closeIgnoringExceptions,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.io.IOUtils.slurpURL,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.getUrlEncoding,7,8,7,5,71.42857142857143,0,0
@@ edu.stanford.nlp.io.IOUtils.slurpURL,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.slurpReader,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.writeStreamToStream,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readCSVWithHeader,14,18,34,17,50.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readCSVStrictly,27,38,105,37,35.23809523809524,0,0
@@ edu.stanford.nlp.io.IOUtils.getFileInputStream,6,7,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.io.IOUtils.getFileOutputStream,6,7,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.io.IOUtils.getFileOutputStream,6,7,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.io.IOUtils.getPrintWriter,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.io.IOUtils.getPrintWriter,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readColumnSet,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readObjectFromColumns,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.readMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.stringFromFile,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.linesFromFile,8,10,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.io.IOUtils.ensureDir,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.deleteDirRecursively,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.getExtension,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.encodedInputStreamReader,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.encodedOutputStreamWriter,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.encodedOutputStreamPrintWriter,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.copyFile,5,5,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.io.IOUtils.cp,37,55,75,41,54.666666666666664,0,1
@@ edu.stanford.nlp.io.IOUtils.tail,24,32,78,43,55.12820512820513,0,0
@@ edu.stanford.nlp.io.IOUtils.deleteRecursively,16,22,25,15,60.0,0,0
@@ edu.stanford.nlp.io.IOUtils.console,18,28,8,8,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils.throwableToStackTrace,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.io.FileSequentialCollection$FileSequentialCollectionIterator.<init>,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.io.FileSequentialCollection$FileSequentialCollectionIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.io.FileSequentialCollection$FileSequentialCollectionIterator.next,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.io.EncodingFileReader.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.io.EncodingFileReader.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.io.FileFilters$NegationFileFilter.accept,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.io.EncodingPrintWriter$err.setupErrWriter,7,9,9,3,33.33333333333333,0,1
@@ edu.stanford.nlp.io.ExtensionFileFilter.<init>,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.io.ExtensionFileFilter.accept,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.io.FileSequentialCollection.<init>,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.io.FileSequentialCollection.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.io.FileSequentialCollection.main,20,25,15,15,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils$1$1.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils$1$1.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.io.IOUtils$1$1.findNext,10,14,37,26,70.27027027027027,0,0
@@ edu.stanford.nlp.io.ui.OpenPageDialog.browseFiles,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.io.ui.OpenPageDialog.enableOpenButton,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.io.ui.OpenPageDialog.urlTextFieldActionPerformed,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.<init>,14,17,16,16,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.addVertex,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getOutgoingEdgesMap,4,4,9,8,88.88888888888889,0,1
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getIncomingEdgesMap,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.add,6,7,15,12,80.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.removeEdges,8,10,25,25,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.removeEdge,32,50,129,129,100.0,0,1
@@ edu.stanford.nlp.graph.DirectedMultiGraph.removeVertex,10,12,22,22,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.removeVertices,7,8,6,4,66.66666666666666,0,1
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getOutgoingEdges,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getIncomingEdges,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getNumEdges,8,9,4,1,25.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getParents,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getChildren,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getNeighbors,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.isEdge,11,15,12,12,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.isNeighbor,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getAllEdges,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.removeZeroDegreeNodes,11,14,18,18,100.0,0,1
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getEdges,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getShortestPath,5,6,15,15,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getShortestPath,5,6,16,16,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.convertPath,14,19,28,19,67.85714285714286,0,1
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getInDegree,7,8,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.getOutDegree,7,8,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.deleteDuplicateEdges,11,13,11,11,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.topologicalSort,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.topologicalSortHelper,10,13,20,20,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.toMap,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph.toString,14,17,13,13,100.0,0,1
@@ edu.stanford.nlp.graph.DirectedMultiGraph$EdgeIterator.<init>,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.graph.DirectedMultiGraph$EdgeIterator.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph$EdgeIterator.primeIterator,12,17,30,30,100.0,0,0
@@ edu.stanford.nlp.graph.DirectedMultiGraph$EdgeIterator.remove,6,8,31,31,100.0,0,0
@@ edu.stanford.nlp.graph.ConnectedComponents.getConnectedComponents,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.graph.ConnectedComponents.bfs,10,12,14,14,100.0,0,0
@@ edu.stanford.nlp.graph.DijkstraShortestPath.getShortestPath,23,31,52,48,92.3076923076923,0,1
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionTest.testPP,11,13,13,13,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionTest.main,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.ChapterAnnotator.annotate,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.quoteattribution.ExtractQuotesUtil.rangeContains,8,11,32,32,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.getRemainderInSentence,15,22,22,21,95.45454545454545,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.addEnhancedSentences,7,8,18,13,72.22222222222221,0,1
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.getTokenRangePrecedingQuote,21,31,63,51,80.95238095238095,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.getTokenRangeFollowingQuote,19,28,61,61,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.constructCoreMap,6,7,18,9,50.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.annotateForDependencyParse,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.getParagraphRank,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.getSentsInParagraph,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.getSentsForQuoteParagraphs,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.readGenderedNounList,8,9,7,7,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.readFamilyRelations,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.readAnimacyList,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.readPersonMap,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.readCharacterList,11,13,18,14,77.77777777777779,0,1
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.isPronominal,7,9,6,6,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.setupCoref,12,15,16,16,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.mapBammanToCharacterMap,46,63,96,46,47.91666666666667,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionUtils.rangeContains,8,11,32,32,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.ExtractQuotesClassifier.scoreBestMentionNew,18,24,64,41,64.0625,0,0
@@ edu.stanford.nlp.quoteattribution.Person.<init>,10,12,19,17,89.47368421052632,0,1
@@ edu.stanford.nlp.quoteattribution.XMLToAnnotation.getJustText,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.quoteattribution.XMLToAnnotation.processCoreNLPIfDoesNotExist,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.XMLToAnnotation.readConnection,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.XMLToAnnotation.getEndIndex,9,11,27,21,77.77777777777779,0,0
@@ edu.stanford.nlp.quoteattribution.XMLToAnnotation.readXMLCharacterList,10,12,20,15,75.0,0,0
@@ edu.stanford.nlp.quoteattribution.XMLToAnnotation.writeCharacterList,12,16,24,21,87.5,0,1
@@ edu.stanford.nlp.quoteattribution.XMLToAnnotation.readXMLFormat,38,51,140,81,57.85714285714286,0,1
@@ edu.stanford.nlp.quoteattribution.BammanCorefReader.readTokenFile,16,22,33,28,84.84848484848484,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionEvaluation.outputMapResultsDefaultKeys,17,21,20,20,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionEvaluation.evaluate,32,47,139,97,69.7841726618705,0,3
@@ edu.stanford.nlp.quoteattribution.QuoteAttributionEvaluation.main,4,4,5,5,100.0,0,2
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve$MentionData.equals,13,19,43,43,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.resolveAmbiguities,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.getNamesInParagraph,13,17,44,34,77.27272727272727,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.doCoreference,9,12,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.createNameMatcher,13,16,54,17,31.48148148148148,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.scanForNamesNew,15,21,119,25,21.008403361344538,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.scanForNames,21,29,119,29,24.369747899159663,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.scanForPronouns,9,12,32,15,46.875,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.scanForPronouns,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.tokenRangeToString,9,13,38,24,63.1578947368421,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.findClosestMentionInSpanForward,18,24,72,14,19.444444444444446,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.findClosestMentionInSpanBackward,18,24,72,14,19.444444444444446,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.findClosestMentionsInSpanForward,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.findClosestMentionsInSpanBackward,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.scanForAnimates,8,10,29,19,65.51724137931035,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.oneSpeakerSentence,28,39,38,23,60.526315789473685,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.Sieve.rangeContainsCharIndex,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.MajoritySpeakerSieve.getTopSpeakerList,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.MajoritySpeakerSieve.doMentionToSpeaker,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.LooseConversationalSpeakerSieve.doMentionToSpeaker,20,27,58,31,53.44827586206896,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.makeMentionData,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.topSpeakerInRange,21,29,74,54,72.97297297297297,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.removeQuoteNames,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.getGender,16,24,54,50,92.5925925925926,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.getTopSpeakers,32,50,106,106,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.updatePredictions,5,6,14,14,100.0,0,3
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.getFamilyAnimateVocative,13,20,36,36,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.getConversationalPreviousPrediction,14,19,38,24,63.1578947368421,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.getConversationalNextPrediction,14,19,41,27,65.85365853658537,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.BaselineTopSpeakerSieve.getQuoteContainingRange,8,10,30,16,53.333333333333336,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.MSSieves.DeterministicSpeakerSieve.doMentionToSpeaker,15,20,31,27,87.09677419354838,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.SupervisedSieve.doQuoteToMention,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.ConversationalSieve.doQuoteToMention,30,46,110,63,57.27272727272727,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.TrigramSieve.trigramPatterns,56,90,210,180,85.71428571428571,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.VocativeSieve.vocativeQuoteToMention,79,129,158,144,91.13924050632912,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.ClosestMentionSieve.getClosestMention,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.ClosestMentionSieve.doQuoteToMention,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.DependencyParseSieve.inRange,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.DependencyParseSieve.dependencyParses,47,69,101,90,89.10891089108911,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.LooseConversationalSieve.doQuoteToMention,23,32,63,36,57.14285714285714,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.ParagraphEndQuoteClosestSieve.paragraphEndQuoteClosestBefore,21,32,57,51,89.47368421052632,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.QMSieves.OneNameSentenceSieve.oneNameSentence,13,18,21,21,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.training.SupervisedSieveTraining.getParagraphBeginToken,6,7,16,9,56.25,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.training.SupervisedSieveTraining.getParagraphEndToken,6,7,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.training.SupervisedSieveTraining.getQuotesInParagraph,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.training.SupervisedSieveTraining.getRangeExclusion,11,14,46,22,47.82608695652174,0,0
@@ edu.stanford.nlp.quoteattribution.Sieves.training.SupervisedSieveTraining.featurize,151,225,561,374,66.66666666666666,0,2
@@ edu.stanford.nlp.quoteattribution.Sieves.training.SupervisedSieveTraining.eliminateDuplicates,8,10,13,13,100.0,0,1
@@ edu.stanford.nlp.quoteattribution.Sieves.training.SupervisedSieveTraining.main,6,7,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.maxent.CGRunner$MonitorFunction.valueAt,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.maxent.Feature.<init>,12,16,42,25,59.523809523809526,0,0
@@ edu.stanford.nlp.maxent.Feature.<init>,18,23,75,35,46.666666666666664,0,0
@@ edu.stanford.nlp.maxent.Feature.print,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.maxent.Feature.setSum,5,5,3,2,66.66666666666666,0,0
@@ edu.stanford.nlp.maxent.Feature.len,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.maxent.Feature.getVal,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.maxent.Feature.initHashVals,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.maxent.Feature.ftilde,5,5,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.maxent.Problem.print,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.maxent.Problem.print,5,5,13,9,69.23076923076923,0,1
@@ edu.stanford.nlp.maxent.CGRunner.<init>,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.maxent.CGRunner.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.maxent.CGRunner.printOptimizationResults,9,11,34,23,67.64705882352942,0,0
@@ edu.stanford.nlp.maxent.CGRunner$LikelihoodFunction.<init>,7,8,14,14,100.0,0,1
@@ edu.stanford.nlp.maxent.CGRunner$LikelihoodFunction.valueAt,6,7,20,14,70.0,0,0
@@ edu.stanford.nlp.maxent.CGRunner$LikelihoodFunction.derivativeAt,13,17,47,32,68.08510638297872,0,0
@@ edu.stanford.nlp.maxent.Experiments.createIndex,8,9,25,14,56.00000000000001,0,0
@@ edu.stanford.nlp.maxent.Experiments.<init>,23,32,50,46,92.0,0,0
@@ edu.stanford.nlp.maxent.Experiments.ptilde,36,48,142,83,58.45070422535211,0,1
@@ edu.stanford.nlp.maxent.Experiments.ptilde,34,45,131,74,56.48854961832062,0,0
@@ edu.stanford.nlp.maxent.Experiments.ptildeX,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.maxent.Experiments.ptildeY,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.maxent.Experiments.ptildeXY,7,8,30,21,70.0,0,0
@@ edu.stanford.nlp.maxent.Experiments.print,11,13,37,25,67.56756756756756,0,0
@@ edu.stanford.nlp.maxent.Experiments.print,11,13,37,25,67.56756756756756,0,1
@@ edu.stanford.nlp.maxent.Features.print,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.<init>,10,12,50,42,84.0,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.transformValues,24,31,182,90,49.45054945054945,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.initCondsZlambdaEtc,25,32,123,78,63.41463414634146,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.improvedIterative,13,17,38,21,55.26315789473685,0,1
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.improvedIterative,14,18,42,29,69.04761904761905,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.iterate,12,15,56,34,60.71428571428571,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.newton,16,22,49,47,95.91836734693877,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.g,5,5,27,20,74.07407407407408,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.gprime,5,5,24,17,70.83333333333334,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.fExpected,5,5,16,9,56.25,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.checkCorrectness,22,29,122,70,57.377049180327866,0,1
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.ZAlfa,5,5,20,13,65.0,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.GSF,5,5,27,20,74.07407407407408,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.GSF,5,5,25,18,72.0,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.GSFPrime,5,5,19,12,63.1578947368421,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.GSFPrime,5,5,19,12,63.1578947368421,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.GSFSecond,11,13,67,39,58.2089552238806,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.GainCompute,10,12,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.print,8,9,32,19,59.375,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.read_lambdas,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.save_problem,14,17,51,36,70.58823529411765,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.logLikelihood,5,5,16,9,56.25,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.main,14,17,42,27,64.28571428571429,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.logLikelihoodNeg,27,35,137,80,58.3941605839416,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.logLikelihoodScratch,27,35,137,80,58.3941605839416,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.getDerivatives,11,13,51,35,68.62745098039215,0,1
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.getDerivativesNeg,11,13,54,38,70.37037037037037,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.expectedValue,25,32,126,82,65.07936507936508,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.getDerivativesExpectedValue,8,9,31,20,64.51612903225806,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.lossDomination,46,62,290,155,53.44827586206896,0,0
@@ edu.stanford.nlp.maxent.iis.LambdaSolve.getDerivativesLossDomination,13,16,58,45,77.58620689655173,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph$Arc.equals,20,30,55,55,100.0,0,1
@@ edu.stanford.nlp.fsm.TransducerGraph$NormalizingGraphProcessor.processGraph,14,17,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph$SetToStringNodeProcessor.processNode,14,19,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.fsm.QuasiDeterminizer.computeLambda,21,29,46,40,86.95652173913044,0,0
@@ edu.stanford.nlp.fsm.QuasiDeterminizer.pushLambdas,16,21,15,15,100.0,0,0
@@ edu.stanford.nlp.fsm.DFSAMinimizer.unweightedMinimize,80,112,211,123,58.29383886255924,0,0
@@ edu.stanford.nlp.fsm.DFSAMinimizer.unweightedMinimizeOld,81,114,172,136,79.06976744186046,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.buildMinimizedFA,10,12,19,19,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.hasSplit,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.sortIntoBlocks,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.makeBlock,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.addSplits,11,13,6,6,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.removeAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.difference,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.getBlock,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.getInverseImages,10,12,9,9,100.0,0,1
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.getInverseArcs,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.getInverseArcs,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.fsm.FastExactAutomatonMinimizer.minimize,13,17,21,20,95.23809523809523,0,0
@@ edu.stanford.nlp.fsm.DFSA.printTrieDFSAHelper,10,12,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.fsm.DFSA.printAttFsmFormat,15,20,27,27,100.0,0,0
@@ edu.stanford.nlp.fsm.DFSA.printTrieAsRulesHelper,15,19,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.fsm.DFSAState.successorStates,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.fsm.DFSAState.isContinuable,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.fsm.DFSAState.hashCode,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.fsm.DFSAState.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.buildMinimizedFA,10,12,19,19,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.hasActivePair,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.sortIntoBlocks,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.makeBlock,10,12,11,11,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.removeAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.difference,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.getBlock,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.getInverseImages,14,18,26,17,65.38461538461539,0,0
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer.minimize,15,20,23,22,95.65217391304348,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.<init>,22,30,40,29,72.5,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.ensure,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.getArc,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.addArc,11,16,41,41,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.removeArc,20,28,49,49,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.canAddArc,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.asDOTString,33,45,77,52,67.53246753246754,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.sumOutputs,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.getSourceTotal,7,8,9,6,66.66666666666666,0,1
@@ edu.stanford.nlp.fsm.TransducerGraph.getOutputOfPathInGraph,7,8,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.sampleUniformPathFromGraph,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.samplePathsFromGraph,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.printPathOutputs,11,13,10,9,90.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.getPathOutputs,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.testGraphPaths,7,8,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.canAddPath,9,11,25,17,68.0,0,1
@@ edu.stanford.nlp.fsm.TransducerGraph.createGraphFromPaths,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.createGraphFromPaths,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.addOnePathToGraph,18,23,53,27,50.943396226415096,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.createRandomGraph,8,9,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.createRandomPaths,8,9,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.depthFirstSearch,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.fsm.TransducerGraph.depthFirstSearchHelper,21,27,49,39,79.59183673469387,0,1
@@ edu.stanford.nlp.fsm.ExactAutomatonMinimizer$ExactBlock.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.getContextWords,6,7,12,12,100.0,0,1
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.concatenateContextWords,8,9,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.score,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.forwardPropagateTree,22,30,75,70,93.33333333333333,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.getAllHighestScoringTreesTest,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.getHighestScoringTree,13,18,38,23,60.526315789473685,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.calculate,36,48,131,111,84.7328244274809,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParserCostAndGradient.backpropDerivative,16,22,94,92,97.87234042553192,0,0
@@ edu.stanford.nlp.parser.dvparser.FilterConfusingRules.<init>,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.FilterConfusingRules.test,18,26,27,27,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParser.getTopParsesForOneTree,11,14,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParser.getTopParses,10,13,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParser.train,33,48,164,125,76.21951219512195,0,1
@@ edu.stanford.nlp.parser.dvparser.DVParser.executeOneTrainingBatch,16,21,66,52,78.78787878787878,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParser.<init>,15,19,79,79,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParser.getModelFromLexicalizedParser,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVParser.main,71,106,662,67,10.120845921450151,0,1
@@ edu.stanford.nlp.parser.dvparser.CacheParseHypotheses.convertToBytes,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.CacheParseHypotheses.convertToBytes,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.CacheParseHypotheses.convertToTrees,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.parser.dvparser.CacheParseHypotheses.convertToTrees,10,12,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.CacheParseHypotheses.main,36,51,194,55,28.350515463917525,0,0
@@ edu.stanford.nlp.parser.dvparser.DumpMatrices.dumpMatrix,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.dvparser.DumpMatrices.main,30,40,92,42,45.65217391304348,0,0
@@ edu.stanford.nlp.parser.dvparser.AverageDVModels.getBinaryMatrixNames,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.AverageDVModels.getUnaryMatrixNames,8,9,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.AverageDVModels.averageBinaryMatrices,13,16,28,13,46.42857142857143,0,1
@@ edu.stanford.nlp.parser.dvparser.AverageDVModels.averageUnaryMatrices,13,16,28,13,46.42857142857143,0,0
@@ edu.stanford.nlp.parser.dvparser.AverageDVModels.main,21,29,84,29,34.523809523809526,0,1
@@ edu.stanford.nlp.parser.dvparser.DVModelReranker$Query.score,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.CombinedDVModelReranker$Query.<init>,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.CombinedDVModelReranker$Query.score,7,8,15,12,80.0,0,0
@@ edu.stanford.nlp.parser.dvparser.CombineDVModels.main,29,41,148,39,26.351351351351347,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.<init>,10,12,19,19,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.<init>,8,9,22,22,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.randomTransformMatrix,14,19,80,68,85.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.addRandomUnaryMatrix,7,8,37,35,94.5945945945946,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.addRandomBinaryMatrix,7,8,42,40,95.23809523809523,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.setRulesForTrainingSet,14,17,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.filterRulesForBatch,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.filterRulesForBatch,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.filterRulesForBatch,31,46,63,63,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.searchRulesForBatch,11,14,22,22,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.basicCategory,7,9,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.readWordVectors,67,99,330,184,55.757575757575765,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.totalParamSize,4,4,16,15,93.75,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.paramsToVector,4,4,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.paramsToVector,4,4,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.vectorToParams,5,5,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.getWForNode,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.getScoreWForNode,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.getVocabWord,28,44,142,89,62.676056338028175,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.printMatrixNames,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.printMatrixStats,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.printAllMatrices,14,17,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.binaryTransformIndex,8,10,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.unaryTransformIndex,7,8,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.binaryScoreIndex,8,10,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.unaryScoreIndex,7,8,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.indexToBinaryTransform,8,10,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.indexToUnaryTransform,9,12,25,21,84.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.indexToBinaryScore,9,12,25,21,84.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.indexToUnaryScore,9,12,25,21,84.0,0,0
@@ edu.stanford.nlp.parser.dvparser.DVModel.printParameterType,10,13,51,51,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.ParseAndPrintMatrices.outputMatrix,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.parser.dvparser.ParseAndPrintMatrices.outputTreeMatrices,8,10,17,13,76.47058823529412,0,1
@@ edu.stanford.nlp.parser.dvparser.ParseAndPrintMatrices.findRootTree,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.ParseAndPrintMatrices.main,29,40,144,42,29.166666666666668,0,0
@@ edu.stanford.nlp.parser.dvparser.UnknownWordPrinter.evaluate,8,10,21,20,95.23809523809523,0,0
@@ edu.stanford.nlp.parser.dvparser.UnknownWordPrinter.display,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.dvparser.FindNearestNeighbors.main,66,92,217,87,40.09216589861751,0,1
@@ edu.stanford.nlp.parser.dvparser.CacheParseHypotheses$CacheProcessor.process,13,18,45,36,80.0,0,1
@@ edu.stanford.nlp.parser.dvparser.CrossValidateTestOptions.main,19,25,97,34,35.051546391752574,0,1
@@ edu.stanford.nlp.parser.metrics.EvaluateExternalParser.getGoldTrees,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateExternalParser.getResults,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.EvaluateExternalParser.convertDataset,10,12,22,17,77.27272727272727,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateExternalParser.buildResponse,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateExternalParser.scoreDataset,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.metrics.ExternalParserQuery.<init>,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.ExternalParserQuery.getPCFGScore,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.ExternalParserQuery.getBestParse,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.ExternalParserQuery.getKBestParses,6,7,15,15,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.ExternalParserQuery.restoreOriginalWords,12,16,24,24,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.ExternalParserQuery.parseUnparsable,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvalbFormatWriter.writeTree,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvalbFormatWriter.writeTrees,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvalbFormatWriter.closeFiles,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank$TreebankEvaluationDataset.getInputSentence,13,17,42,42,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank$TreebankEvaluationDataset.dataset,16,20,37,37,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluationMetric.update,8,10,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluationMetric.toString,21,27,54,54,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.TopMatchEval.makeObjects,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.BestOfTopKEval.evaluate,8,10,21,11,52.38095238095239,0,0
@@ edu.stanford.nlp.parser.metrics.Evalb.makeObjects,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.Evalb.evaluate,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.Evalb.main,39,55,104,83,79.8076923076923,0,0
@@ edu.stanford.nlp.parser.metrics.Evalb.emitSortedTrees,14,18,31,27,87.09677419354838,0,0
@@ edu.stanford.nlp.parser.metrics.Evalb.storeTrees,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank.<init>,57,83,238,236,99.15966386554622,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank.getLBScore,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank.getTagScore,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank.getPCFGTopKF1,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank.hasPCFGTopKF1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank.processResults,117,175,485,425,87.62886597938144,0,0
@@ edu.stanford.nlp.parser.metrics.EvaluateTreebank.testOnTreebank,111,168,460,309,67.17391304347827,0,1
@@ edu.stanford.nlp.parser.metrics.TaggingEval.<init>,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.TaggingEval.makeObjects,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.TaggingEval.makeObjectsByCat,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.TaggingEval.evaluate,25,37,78,71,91.02564102564102,0,1
@@ edu.stanford.nlp.parser.metrics.TaggingEval.measureOOV,11,15,42,26,61.904761904761905,0,1
@@ edu.stanford.nlp.parser.metrics.TaggingEval.display,31,41,63,55,87.3015873015873,0,1
@@ edu.stanford.nlp.parser.metrics.TaggingEval.main,39,56,103,66,64.07766990291263,0,0
@@ edu.stanford.nlp.parser.metrics.CollinsDepEval.makeCollinsObjects,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.CollinsDepEval.evaluate,22,32,67,60,89.55223880597015,0,0
@@ edu.stanford.nlp.parser.metrics.CollinsDepEval.display,23,30,45,37,82.22222222222221,0,0
@@ edu.stanford.nlp.parser.metrics.CollinsDepEval.main,27,37,63,44,69.84126984126983,0,0
@@ edu.stanford.nlp.parser.metrics.TsarfatyEval.makeObjects,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.TsarfatyEval.extractDeps,11,15,33,28,84.84848484848484,0,0
@@ edu.stanford.nlp.parser.metrics.TsarfatyEval.main,51,78,116,49,42.241379310344826,0,1
@@ edu.stanford.nlp.parser.metrics.AbstractEval.precision,10,12,16,6,37.5,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval.evaluate,16,22,72,70,97.22222222222221,0,1
@@ edu.stanford.nlp.parser.metrics.AbstractEval$RuleErrorEval.localize,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$RuleErrorEval.makeObjects,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$RuleErrorEval.evaluate,12,15,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$RuleErrorEval.display,7,8,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$RuleErrorEval.display,8,9,10,10,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.EvalbByCat.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvalbByCat.makeObjectsByCat,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvalbByCat.evaluate,27,39,77,77,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.EvalbByCat.getEvalLabelSet,9,11,18,18,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.EvalbByCat.display,25,33,72,52,72.22222222222221,0,0
@@ edu.stanford.nlp.parser.metrics.UnlabeledAttachmentEval.evaluate,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.UnlabeledAttachmentEval.makeObjects,6,7,13,13,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.UnlabeledAttachmentEval.main,35,50,95,58,61.05263157894737,0,1
@@ edu.stanford.nlp.parser.metrics.Evalb$F1Comparator.compare,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.Evalb$CBEval.checkCrossing,9,11,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.parser.metrics.Evalb$CBEval.evaluate,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.TreeSpanScoring.countSpanErrors,17,22,41,24,58.536585365853654,0,1
@@ edu.stanford.nlp.parser.metrics.TreeSpanScoring.simplifyConstituents,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.makeLineages,17,22,24,24,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.updateCatAverages,5,5,16,16,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.evaluate,13,17,46,39,84.78260869565217,0,0
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.editDistance,17,21,52,26,50.0,0,0
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.display,18,23,49,41,83.6734693877551,0,0
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.validateCommandLine,21,33,11,11,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.LeafAncestorEval.main,20,28,68,47,69.11764705882352,0,0
@@ edu.stanford.nlp.parser.metrics.FilteredEval.makeObjects,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.parser.metrics.AbstractEval$ScoreEval.recordScore,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$ScoreEval.display,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$CatErrorEval.myMakeObjects,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$CatErrorEval.evaluate,12,15,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.metrics.AbstractEval$CatErrorEval.display,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.ui.TreeJPanel.nodeToString,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.ui.TreeJPanel.widthResult,15,20,66,29,43.93939393939394,0,0
@@ edu.stanford.nlp.parser.ui.TreeJPanel.height,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.ui.TreeJPanel.pickFont,10,12,33,28,84.84848484848484,0,0
@@ edu.stanford.nlp.parser.ui.TreeJPanel.paintTree,11,14,42,31,73.80952380952381,0,0
@@ edu.stanford.nlp.parser.ui.TreeJPanel.paintComponent,10,13,34,28,82.35294117647058,0,0
@@ edu.stanford.nlp.parser.ui.TreeJPanel.main,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.highlightText,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.highlightSentence,20,26,51,46,90.19607843137256,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.nearestDelimiter,30,44,64,48,75.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.setFont,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.setChineseFont,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.parse,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.loadFile,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.loadFile,22,31,58,32,55.172413793103445,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.saveOutput,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.saveOutput,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.loadParser,8,10,18,18,100.0,0,1
@@ edu.stanford.nlp.parser.ui.ParserPanel.loadParser,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.startProgressMonitor,7,9,22,16,72.72727272727273,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel.stopProgressMonitor,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.parser.ui.ParserPanel.initComponents,8,9,25,25,100.0,0,1
@@ edu.stanford.nlp.parser.ui.ParserPanel$LoadParserThread.run,7,8,20,20,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel$ParseThread.run,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.ui.ParserPanel$SaveOutputThread.run,17,22,40,29,72.5,0,1
@@ edu.stanford.nlp.parser.ui.Parser.<init>,6,7,11,11,100.0,0,1
@@ edu.stanford.nlp.parser.ui.Parser.main,7,9,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.parser.tools.RuleBranchingFactor.treeToRuleString,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.parser.tools.RuleBranchingFactor.main,19,26,46,33,71.73913043478261,0,0
@@ edu.stanford.nlp.parser.tools.RuleBranchingFactor.standardDeviation,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.parser.tools.UpdateParserOptions.main,9,11,51,12,23.52941176470588,0,0
@@ edu.stanford.nlp.parser.tools.VocabFrequency.main,32,45,59,23,38.983050847457626,0,0
@@ edu.stanford.nlp.parser.tools.PunctFrequencyDist.main,34,48,69,28,40.57971014492754,0,0
@@ edu.stanford.nlp.parser.tools.PrintTagList.main,21,27,45,30,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.setLabels,14,19,27,27,100.0,0,0
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.setLabels,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.writeTrees,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.readLabelMap,9,11,20,13,65.0,0,0
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.readSentences,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.loadParser,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.parseSentences,9,11,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.parser.tools.ParseAndSetLabels.main,48,70,780,46,5.897435897435897,0,0
@@ edu.stanford.nlp.parser.tools.RHSFrequency.main,35,49,69,30,43.47826086956522,0,0
@@ edu.stanford.nlp.parser.tools.CountTrees.main,23,32,41,38,92.6829268292683,0,0
@@ edu.stanford.nlp.parser.tools.PunctEquivalenceClasser.getPunctClass,24,35,42,42,100.0,0,0
@@ edu.stanford.nlp.parser.tools.ManipulateTopBracket.main,18,24,36,31,86.11111111111111,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams.pw,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams.parsevalObjectify,15,21,28,28,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams.dependencyObjectify,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams.dependencyObjectifyHelper,10,13,19,19,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams.subcategoryStripper,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams.setGenerateOriginalDependencies,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams.lambda$typedDependencyClasser$0,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.NodePruner.prune,21,29,66,46,69.6969696969697,0,0
@@ edu.stanford.nlp.parser.lexparser.NodePruner.helper,5,5,5,4,80.0,0,0
@@ edu.stanford.nlp.parser.lexparser.NodePruner.prune,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser$Arc.equals,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser$Arc.hashCode,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeCollinizer.transformTree,35,54,126,81,64.28571428571429,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.<init>,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.pruneTW,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.treeToDependencyHelper,34,45,74,74,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.scoreAll,7,8,8,5,62.5,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.tune,67,91,261,133,50.95785440613027,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.addRule,4,4,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.getCachedITW,8,10,30,23,76.66666666666667,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.expandDependency,7,9,22,22,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.tagProject,6,7,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.expandArg,4,4,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.expandStop,7,9,26,26,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.probTB,53,72,181,133,73.48066298342542,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.getStopProb,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.readObject,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.writeObject,15,21,48,48,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.readData,12,15,32,15,46.875,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammar.writeData,15,21,50,50,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.HungarianTreebankParserParams.treeReaderFactory,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.parser.lexparser.HungarianTreebankParserParams.defaultTestSentence,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams.lex,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams.treeReaderFactory,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams.setOptionFlag,31,45,105,92,87.61904761904762,0,0
@@ edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams.transformTree,44,70,85,85,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams.containsVP,9,11,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.NegraPennTreebankParserParams.childBasicCats,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModelTrainer.train,5,6,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModelTrainer.finishTraining,8,10,30,20,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.<init>,23,31,149,127,85.23489932885906,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.setConstraints,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.parseInternal,49,71,149,131,87.91946308724832,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.restoreOriginalWords,15,20,29,29,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.parse,9,12,38,38,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.getBestParse,17,25,53,48,90.56603773584906,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.getKBestParses,15,22,50,49,98.0,0,1
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.getBestScore,13,19,34,34,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.hasFactoredParse,9,12,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.getKGoodFactoredParses,12,16,34,33,97.05882352941177,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.getKBestPCFGParses,9,11,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.getBestPCFGParse,10,14,27,26,96.29629629629629,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.getBestDependencyParse,10,14,27,25,92.5925925925926,0,1
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.parse,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.parseAndReport,19,27,47,47,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParserQuery.addSentenceFinalPunctIfNeeded,19,27,55,34,61.81818181818181,0,0
@@ edu.stanford.nlp.parser.lexparser.IntDependency.hashCode,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.IntDependency.equals,12,17,39,39,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.IntDependency.toString,5,5,9,9,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.IntDependency.toString,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.<init>,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.isKnown,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.isKnown,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.tagSet,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.ruleIteratorByWord,16,21,46,44,95.65217391304348,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.initRulesWithWord,31,42,69,65,94.20289855072464,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.listToEvents,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.train,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.train,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.trainUnannotated,12,15,29,13,44.827586206896555,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.train,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.addTagging,8,10,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.buildPT_T,18,23,51,24,47.05882352941176,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.score,29,41,113,88,77.87610619469027,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.tune,18,24,64,59,92.1875,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.readData,9,11,25,15,60.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.writeData,11,13,23,19,82.6086956521739,0,1
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.numRules,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.examineIntersection,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.printLexStats,34,47,129,80,62.01550387596899,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.evaluateCoverage,14,18,36,30,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.getBaseTag,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.populateTagsToBaseTags,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseLexicon.main,23,30,74,50,67.56756756756756,0,1
@@ edu.stanford.nlp.parser.lexparser.GrammarCoverageChecker.localTreeToRule,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCoverageChecker.computeLocalTreeScore,21,29,69,41,59.42028985507246,0,0
@@ edu.stanford.nlp.parser.lexparser.Options.setOptions,5,5,10,6,60.0,0,1
@@ edu.stanford.nlp.parser.lexparser.Options.setOptionsOrWarn,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Options.setOptionOrWarn,6,7,22,13,59.09090909090909,0,0
@@ edu.stanford.nlp.parser.lexparser.Options.setOption,6,7,18,12,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.Options.setOptionFlag,392,604,1530,1390,90.84967320261438,0,6
@@ edu.stanford.nlp.parser.lexparser.Options.readData,8,10,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader$LatticeWord.merge,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader$LatticeWord.equals,10,13,27,27,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader$LatticeWord.compareTo,10,13,32,32,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Lattice.addEdge,7,8,27,27,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.Lattice.getEdgesOverSpan,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Lattice.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseSimWordAvgDepGrammar.getMap,9,11,24,23,95.83333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseSimWordAvgDepGrammar.probTBwithSimWords,44,62,128,109,85.15625,0,1
@@ edu.stanford.nlp.parser.lexparser.ChineseSimWordAvgDepGrammar.probSimilarWordAvg,57,78,208,140,67.3076923076923,0,1
@@ edu.stanford.nlp.parser.lexparser.TaggerReranker$Query.score,7,8,31,19,61.29032258064516,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.purgeRules,8,9,16,16,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.closeRulesUnderMax,8,9,32,23,71.875,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.relaxRule,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.scoreRule,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.makeCRArrays,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.closedRulesByParent,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.closedRulesByChild,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.closedRuleIteratorByParent,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.closedRuleIteratorByChild,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.ruleIteratorByParent,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.ruleIteratorByChild,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.rulesByParent,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.rulesByChild,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.readObject,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.init,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.readData,6,7,16,8,50.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.writeData,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryGrammar.writeAllData,20,25,55,45,81.81818181818183,0,0
@@ edu.stanford.nlp.parser.lexparser.ParentAnnotationStats.kidLabels,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ParentAnnotationStats.processTreeHelper,19,27,72,49,68.05555555555556,0,0
@@ edu.stanford.nlp.parser.lexparser.ParentAnnotationStats.printStats,57,78,161,119,73.91304347826086,0,1
@@ edu.stanford.nlp.parser.lexparser.ParentAnnotationStats.getSplitters,31,42,41,41,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ParentAnnotationStats.main,15,20,76,19,25.0,0,1
@@ edu.stanford.nlp.parser.lexparser.CNFTransformers$FromCNFTransformer.transformTree,12,15,36,25,69.44444444444444,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$UntypedDependencyTyper.makeDependency,8,9,14,14,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModelTrainer.train,5,6,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModelTrainer.finishTraining,8,10,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreeExtractor.tallyLocalTree,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreeExtractor.tallyTree,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreeExtractor.tallyTrees,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.CNFTransformers.main,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Edge.equals,11,17,47,47,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$AddEquivalencedConjNode.apply,8,10,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexicon.score,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams.treeReaderFactory,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.parser.lexparser.ItalianTreebankParserParams.defaultTestSentence,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$AnnotatePunctuationFunction2.apply,25,36,26,26,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$AddRelativeNodeRegexFunction.apply,10,14,40,32,80.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TueBaDZParserParams.lex,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TueBaDZParserParams.setOptionFlag,26,37,94,83,88.29787234042553,0,1
@@ edu.stanford.nlp.parser.lexparser.TueBaDZParserParams.transformTree,45,71,90,74,82.22222222222221,0,0
@@ edu.stanford.nlp.parser.lexparser.TueBaDZParserParams.childBasicCats,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TueBaDZParserParams.containsV,9,11,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseWordFeatureExtractor.setFeatureLevel,9,13,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseWordFeatureExtractor.train,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseWordFeatureExtractor.train,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseWordFeatureExtractor.loadFeatures,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseWordFeatureExtractor.applyFeatureCountThreshold,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseWordFeatureExtractor.makeFeatures,68,100,182,146,80.21978021978022,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getCoreLabel,9,12,32,32,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.oPossible,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.iPossible,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.buildOFilter,8,9,26,18,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.validateBinarizedTree,14,19,67,67,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.scoreNonBinarizedTree,5,5,11,11,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.scoreBinarizedTree,8,10,28,28,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.parse,75,110,340,270,79.41176470588235,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.parse,33,47,157,127,80.89171974522293,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.initializePossibles,20,26,101,50,49.504950495049506,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.doOutsideScores,89,126,422,297,70.37914691943128,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.doInsideScores,13,16,35,18,51.42857142857142,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.doInsideChartCell,206,312,777,596,76.7052767052767,0,2
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.initializeChart,29,41,149,115,77.18120805369128,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.initializeChart,92,144,552,311,56.34057971014492,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.hasParse,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.matches,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getBestScore,11,16,41,41,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getBestParse,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.extractBestParse,60,85,270,233,86.29629629629629,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.extractBestParses,32,46,115,107,93.04347826086956,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getKBestParses,7,8,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getTree,21,31,81,76,93.82716049382715,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getBackwardsStar,14,18,52,46,88.46153846153845,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getCandidates,20,26,56,36,64.28571428571429,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.lazyKthBest,9,12,25,13,52.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.lazyNext,10,13,41,30,73.17073170731707,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.getBestParses,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.setConstraints,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.<init>,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.nudgeDownArraySize,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.considerCreatingArrays,7,9,29,29,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser.createArrays,26,36,118,85,72.03389830508475,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$RemoveGFSubcategoryStripper.transformTree,9,11,34,30,88.23529411764706,0,0
@@ edu.stanford.nlp.parser.lexparser.Item.score,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AddTaggerToParser.main,13,17,96,16,16.666666666666664,0,1
@@ edu.stanford.nlp.parser.lexparser.FastFactoredParser.hasParse,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FastFactoredParser.getKGoodParses,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FastFactoredParser.parse,12,15,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$AddEquivalencedNodeFunction.apply,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.registerEdgeIndexes,6,7,29,24,82.75862068965517,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.registerRealEdge,6,7,25,20,80.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.getRealEdgesWithL,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.getRealEdgesWithR,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.getPreHooks,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.getPostHooks,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.getEdges,7,8,20,13,65.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.insert,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.addEdge,6,7,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart.addHook,7,8,25,23,92.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredParser.main,164,245,952,509,53.46638655462185,0,2
@@ edu.stanford.nlp.parser.lexparser.FactoredParser.cleanTags,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredParser.wordify,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotator.transformTree,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotator.transformTreeHelper,100,158,397,283,71.28463476070529,0,2
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotator.listBasicCategories,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotator.rightRec,8,10,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotator.markStrahler,13,17,43,17,39.53488372093023,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.<init>,20,25,56,56,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.dumpStats,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.addRoot,4,4,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.transformTree,22,31,75,66,88.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.printRuleCounts,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.printStateCounts,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.numSubArgs,6,7,17,8,47.05882352941176,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.removeDeleteSplittersFromSplitters,18,25,40,40,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.getAnnotatedBinaryTreebankFromTreebank,50,71,188,165,87.7659574468085,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer.main,22,30,98,35,35.714285714285715,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.headFinder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.setHeadFinder,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.lex,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.treeReaderFactory,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.transformTree,11,16,27,24,88.88888888888889,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.loadMWMap,8,10,19,16,84.21052631578947,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.setupMorphoFeatures,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams.setOptionFlag,30,43,100,90,90.0,0,1
@@ edu.stanford.nlp.parser.lexparser.UnknownGTTrainer.train,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnknownGTTrainer.train,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnknownGTTrainer.finishTraining,18,23,30,30,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.CollinsPuncTransformer.isPunc,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.CollinsPuncTransformer.preTermHelper,9,11,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.CollinsPuncTransformer.transformRoot,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.CollinsPuncTransformer.transformNode,24,35,51,51,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TregexPoweredTreebankParserParams.compileAnnotations,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TregexPoweredTreebankParserParams.addFeature,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TregexPoweredTreebankParserParams.transformTree,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TregexPoweredTreebankParserParams.getAnnotationString,7,8,11,11,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.TregexPoweredTreebankParserParams.display,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.oPossible,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.iPossible,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.parse,248,348,1200,560,46.666666666666664,0,4
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.hasParse,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.getBestScore,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.displayHeadScores,25,32,119,51,42.857142857142854,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.matches,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.extractBestParse,25,33,162,97,59.876543209876544,0,1
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.flatten,12,16,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustiveDependencyParser.getBestParse,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$AddRelativeNodeFunction.apply,13,16,28,28,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$AddRelativeNodeFunction.toString,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TrainOptions.outsideFactor,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TrainOptions.compactGrammar,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TrainOptions.toString,5,5,64,64,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TrainOptions.printTrainTree,8,10,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.extractPaths,14,18,57,52,91.22807017543859,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.runTest,82,121,2660,171,6.428571428571428,0,1
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.translateAndSort,14,17,18,18,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.changeIfNecessary,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.equalsBinary,15,19,27,24,88.88888888888889,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.equalsUnary,15,19,27,24,88.88888888888889,0,1
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.equalSets,8,10,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.numTokens,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.buildAndCompactToyGrammars,10,12,19,19,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.removeLowCountPaths,7,8,14,11,78.57142857142857,0,1
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactionTester.testGrammarCompaction,6,7,31,31,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.splitRules,24,31,72,48,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.scoreRule,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.ruleIteratorByParent,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.ruleIteratorByRightChild,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.ruleIteratorByLeftChild,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.ruleListByParent,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.ruleListByRightChild,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.ruleListByLeftChild,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.readObject,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.init,5,5,14,10,71.42857142857143,0,1
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.readData,6,7,16,8,50.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammar.writeData,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModel.score,4,4,12,10,83.33333333333334,0,1
@@ edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModel.getSignature,26,38,52,52,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SpanishUnknownWordModel.isUpperCase,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LinearGrammarSmoother.apply,18,23,34,34,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.LinearGrammarSmoother.postBasicCategoryIndex,11,15,36,15,41.66666666666667,0,1
@@ edu.stanford.nlp.parser.lexparser.LinearGrammarSmoother.basicCategory,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TregexPoweredTreebankParserParams$AnnotateHeadFunction.apply,8,10,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.RerankingParserQuery.parse,6,7,10,10,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.RerankingParserQuery.parseAndReport,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.RerankingParserQuery.rerank,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.RerankingParserQuery.getBestParse,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.RerankingParserQuery.getPCFGScore,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.RerankingParserQuery.getBestPCFGParses,9,12,29,29,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.RerankingParserQuery.getKBestPCFGParses,6,7,20,13,65.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModelTrainer.initializeTraining,23,31,60,60,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModelTrainer.train,9,12,52,52,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModelTrainer.finishTraining,12,15,27,27,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModelTrainer.buildUWM,4,4,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.parser.lexparser.RandomWalk.score,5,5,16,9,56.25,0,0
@@ edu.stanford.nlp.parser.lexparser.RandomWalk.step,10,12,21,18,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.RandomWalk.train,9,11,26,26,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.RandomWalk.<init>,10,12,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ParseFiles.<init>,13,16,42,42,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.ParseFiles.parseFiles,67,97,296,240,81.08108108108108,0,1
@@ edu.stanford.nlp.parser.lexparser.ParseFiles.processResults,35,54,108,108,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.FrenchUnknownWordModelTrainer.train,5,6,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchUnknownWordModelTrainer.finishTraining,8,10,30,20,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.tagBin,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.rootTW,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.valenceBin,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.numDistBins,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.distanceBin,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.regDistanceBin,7,8,24,15,62.5,0,1
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.coarseDistanceBin,7,8,24,15,62.5,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.setCoarseDistanceBins,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.setRegDistanceBins,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.initTagBins,8,9,29,22,75.86206896551724,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractDependencyGrammar.intern,5,6,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart$ChartIndex.equals,12,17,39,39,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser$N5BiLexPCFGParser.relaxTempHook,7,9,27,27,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexiconTraining.printStats,19,24,36,29,80.55555555555556,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexiconTraining.main,99,143,272,169,62.13235294117647,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordModel.<init>,5,6,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordModel.score,4,4,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordModel.getSignature,57,85,141,141,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordSignatures.allDigitPlus,19,28,33,20,60.60606060606061,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordSignatures.likelyAdjectivalSuffix,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordSignatures.pastTenseVerbNumberSuffix,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordSignatures.presentTenseVerbNumberSuffix,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordSignatures.taaMarbuuTaSuffix,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordSignatures.abstractionNounSuffix,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordSignatures.masdarPrefix,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SpanishTreebankParserParams.lex,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SpanishTreebankParserParams.setOptionFlag,5,6,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.headFinder,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.lex,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.collinizer,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.transformTree,16,23,32,31,96.875,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.setHeadFinder,10,12,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.setupMorphoFeatures,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.removeBaselineFeature,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.setOptionFlag,35,51,139,106,76.2589928057554,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams.main,10,12,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams$AddPOSSequenceFunction.apply,14,18,27,27,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.typedDependencyHeadFinder,10,12,18,18,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.collinizer,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.collinizerEvalb,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.lex,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.sisterSplitters,7,10,19,19,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.transformTree,1222,2131,22501,2108,9.368472512332787,0,91
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.containsVP,9,11,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.firstOfSeveralNNP,14,19,20,7,35.0,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.lastOfSeveralNNP,11,14,15,6,40.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.deduceTag,11,15,10,10,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.subCatify,23,32,43,18,41.86046511627907,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.ditrans,13,18,24,12,50.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.changeBaseCat,9,11,29,16,55.172413793103445,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.hasClausalV,16,22,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.hasV,8,10,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.hasI,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.hasC,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.setOptionFlag,127,197,520,466,89.61538461538461,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.defaultTestSentence,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.readGrammaticalStructureFromFile,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.getGrammaticalStructure,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams.lambda$treeReaderFactory$0,8,9,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SisterAnnotationStats.recurse,12,16,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SisterAnnotationStats.leftSisterLabels,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SisterAnnotationStats.rightSisterLabels,9,11,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.SisterAnnotationStats.kidLabels,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SisterAnnotationStats.sisterCounters,8,10,35,35,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SisterAnnotationStats.sideCounters,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SisterAnnotationStats.main,7,8,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseUnknownWordModelTrainer.initializeTraining,20,27,76,51,67.10526315789474,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseUnknownWordModelTrainer.train,12,17,58,56,96.55172413793103,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseUnknownWordModelTrainer.finishTraining,12,15,30,30,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon$Symbol.<init>,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon$Symbol.cannonicalSymbol,7,9,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon$Symbol.getCh,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon$Symbol.toString,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon$Symbol.readResolve,10,16,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon$Symbol.equals,15,21,39,39,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon$Symbol.hashCode,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishTreebankParserParams$EnglishSubcategoryStripper.transformTree,49,73,186,124,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams$AddRelativeNodeFunction.apply,17,21,34,32,94.11764705882352,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchTreebankParserParams$AddRelativeNodeFunction.toString,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchUnknownWordModel.score,4,4,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.FrenchUnknownWordModel.getSignature,21,31,56,56,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.NegraPennCollinizer.transformTree,20,29,58,53,91.37931034482759,0,0
@@ edu.stanford.nlp.parser.lexparser.IntTaggedWord.wordString,7,8,14,11,78.57142857142857,0,0
@@ edu.stanford.nlp.parser.lexparser.IntTaggedWord.tagString,7,8,14,11,78.57142857142857,0,0
@@ edu.stanford.nlp.parser.lexparser.IntTaggedWord.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.IntTaggedWord.compareTo,4,4,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.IntTaggedWord.toString,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.IntTaggedWord.<init>,20,31,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TwinScorer.oPossible,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TwinScorer.iPossible,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TwinScorer.parse,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammarExtractor.tallyRoot,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MLEDependencyGrammarExtractor.formResult,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryRule.equals,8,11,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryRule.compareTo,10,13,32,32,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.UnaryRule.toStringNoScore,4,4,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$ArabicSubcategoryStripper.transformTree,23,33,69,57,82.6086956521739,0,0
@@ edu.stanford.nlp.parser.lexparser.Hook.isPreHook,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Hook.isPostHook,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Hook.toString,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Hook.equals,12,19,55,55,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.better,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.getBestScore,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.extractParse,13,17,56,54,96.42857142857143,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.hasParse,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.getKGoodParses,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.combine,5,5,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.relaxTempEdge,7,9,34,34,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.discoverHook,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.buildOScore,10,12,48,35,72.91666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.projectHooks,42,59,262,234,89.31297709923665,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.triggerHooks,22,29,81,81,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.triggerAllHooks,22,29,87,87,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.relaxTempHook,9,12,46,40,86.95652173913044,0,1
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.projectUnaries,7,8,20,20,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.processEdge,14,18,35,35,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.processHook,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.processItem,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.discoverItem,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.makeInitialItems,17,23,71,54,76.05633802816901,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.initialize,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.parse,43,63,218,197,90.36697247706422,0,0
@@ edu.stanford.nlp.parser.lexparser.BiLexPCFGParser.postMortem,9,11,28,18,64.28571428571429,0,0
@@ edu.stanford.nlp.parser.lexparser.Options$LexOptions.readData,17,27,59,29,49.152542372881356,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.DEBUG,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.neginfDoubles,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.outputTransitions,36,48,99,61,61.61616161616161,0,1
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.outputBetas,32,41,69,43,62.31884057971014,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.state,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.countOriginalStates,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.countOriginalStates,10,12,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.initialBetasAndLexicon,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.initialBetasAndLexicon,18,24,50,47,94.0,0,1
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.splitStateCounts,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.splitBetas,63,84,214,122,57.009345794392516,0,1
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recalculateBetas,12,16,22,22,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.useNewBetas,8,10,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recalculateTemporaryBetas,7,8,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.testConvergence,36,47,80,52,65.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recalculateTemporaryBetas,6,7,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recalculateTemporaryBetas,57,77,211,136,64.45497630331754,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.rescaleTemporaryBetas,54,71,141,65,46.09929078014184,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recountTree,4,4,11,11,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recountWeights,60,80,219,117,53.42465753424658,0,1
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recurseOutside,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recountOutside,8,9,25,15,60.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recountOutside,11,13,39,23,58.97435897435898,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recountInside,53,73,208,138,66.34615384615384,0,1
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.mergeStates,16,20,34,30,88.23529411764706,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.recalculateMergedBetas,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.mergeTransitions,90,120,337,180,53.41246290801187,0,1
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.buildMergeCorrespondence,14,17,26,18,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.countMergeEffects,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.countMergeEffects,19,25,41,32,78.04878048780488,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.buildStateIndex,8,9,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.buildGrammars,36,47,95,61,64.21052631578948,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.saveTrees,11,14,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor.extract,11,14,39,24,61.53846153846154,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractUnknownWordModelTrainer.train,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractUnknownWordModelTrainer.train,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LatticeXMLReader.load,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LatticeXMLReader.load,26,35,75,47,62.66666666666667,0,0
@@ edu.stanford.nlp.parser.lexparser.LatticeXMLReader.main,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter.train,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter.numSubArgs,6,7,17,8,47.05882352941176,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter.getSegmenterDataFromTreebank,35,49,133,117,87.96992481203007,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter.printArgs,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter.saveSegmenterDataToText,7,8,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter.makeTreebank,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseLexiconAndWordSegmenter.getSegmenterDataFromSerializedFile,8,9,13,7,53.84615384615385,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$SubcategoryStripper.transformTree,9,11,34,30,88.23529411764706,0,0
@@ edu.stanford.nlp.parser.lexparser.HungarianTreebankParserParams$HungarianSubcategoryStripper.normalizeNonterminal,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Interner.intern,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.HookChart$WeakChartIndex.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.Debinarizer.transformTreeHelper,11,14,30,25,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.Debinarizer.transformTree,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMarkovWordSegmenter.train,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMarkovWordSegmenter.train,8,9,15,9,60.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMarkovWordSegmenter.finishTraining,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMarkovWordSegmenter.basicSegmentWords,39,52,170,88,51.76470588235295,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMarkovWordSegmenter.segmentWordsWithMarkov,52,70,209,117,55.980861244019145,0,1
@@ edu.stanford.nlp.parser.lexparser.ChineseMarkovWordSegmenter.getSegmentedWordLengthDistribution,11,13,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GermanUnknownWordModel.score,6,7,7,7,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.PathExtractor.getList,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.PathExtractor.tallyInternalNode,25,33,89,55,61.79775280898876,0,0
@@ edu.stanford.nlp.parser.lexparser.BoundaryRemover.transformTree,5,6,6,6,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.PostSplitter.transformTreeHelper,37,56,152,104,68.42105263157895,0,1
@@ edu.stanford.nlp.parser.lexparser.PostSplitter.dumpStats,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordModelTrainer.train,5,6,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ArabicUnknownWordModelTrainer.finishTraining,8,10,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams$1.formResult,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.train,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.train,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.finishTraining,51,69,149,81,54.36241610738255,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.isForeign,8,10,15,10,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.unknownCharClass,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.score,21,29,70,48,68.57142857142857,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.getBackedOffDist,7,8,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.sampleFrom,16,22,47,34,72.3404255319149,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.getWordLengthDistribution,7,8,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseCharacterBasedLexicon.tagSet,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.ruleIteratorByWord,9,11,22,22,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.score,11,14,27,27,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.probWordTag,9,11,27,23,85.18518518518519,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.probLemmaTag,9,11,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.probMorphTag,6,7,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.train,27,38,100,90,90.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.initRulesWithWord,23,30,61,57,93.44262295081968,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.treebankToLexiconEvents,17,22,48,39,81.25,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.getTuningSet,10,12,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.getOptions,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.FactoredLexicon.main,39,52,84,63,75.0,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.reverse,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.buildFA,11,13,36,21,58.333333333333336,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.init,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.advanceRight,13,16,42,24,57.14285714285714,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.leftAccepting,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.advanceLeft,13,16,42,24,57.14285714285714,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.rightAccepting,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter.<init>,24,33,85,34,40.0,0,1
@@ edu.stanford.nlp.parser.lexparser.ArabicTreebankParserParams$AddEquivalencedNodeFunctionVar.apply,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExactGrammarCompactor.doCompaction,6,7,18,18,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.setDoSelectiveSplit,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.join,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.localTreeString,10,13,27,19,70.37037037037037,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.isSynthetic,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.binarizeLocalTree,9,11,32,30,93.75,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.markovOutsideBinarizeLocalTree,31,42,119,113,94.9579831932773,0,1
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.markovInsideBinarizeLocalTreeNew,30,44,109,97,88.9908256880734,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.makeSyntheticLabel,7,8,23,20,86.95652173913044,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.makeSyntheticLabel1,19,25,67,27,40.298507462686565,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.makeSyntheticLabel2,22,32,98,39,39.795918367346935,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.insideBinarizeLocalTree,17,25,79,76,96.20253164556962,0,1
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.outsideBinarizeLocalTree,21,29,96,88,91.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.transformTree,19,26,67,56,83.5820895522388,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeBinarizer.main,30,43,125,41,32.800000000000004,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser$Vertex.equals,9,12,27,27,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser$Vertex.hashCode,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.parser.lexparser.CNFTransformers$ToCNFTransformer.transformTree,30,42,78,56,71.7948717948718,0,0
@@ edu.stanford.nlp.parser.lexparser.SplittingGrammarExtractor$1.equals,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.<init>,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.score,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.scoreProbTagGivenWordSignature,4,4,10,8,80.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature,11,18,45,45,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature7,31,45,60,31,51.66666666666667,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature6,57,87,123,72,58.536585365853654,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature5,60,93,129,78,60.46511627906976,0,1
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature4,43,64,85,44,51.76470588235295,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature3,26,36,65,27,41.53846153846154,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature2,29,43,56,35,62.5,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature1,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.EnglishUnknownWordModel.getSignature8,19,28,45,30,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseUnknownWordModel.<init>,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseUnknownWordModel.score,35,51,82,56,68.29268292682927,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseUnknownWordModel.main,17,21,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$AnnotatePunctuationFunction.apply,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.StringUnaryRule.equals,18,26,47,47,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.StringUnaryRule.hashCode,8,9,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.loadModel,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.parseStrings,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.parse,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.parseMultiple,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.parseMultiple,11,13,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.parseTree,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.getExtraEvals,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.parserQuery,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromFile,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.makeTreebank,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.makeSecondaryTreebank,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.saveParserToTextFile,12,15,38,36,94.73684210526315,0,1
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.confirmBeginBlock,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTextFile,8,10,26,26,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.printOptions,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainBinarizer,16,20,32,32,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.buildTrainTransformer,8,10,28,28,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.getAnnotatedBinaryTreebankFromTreebank,29,42,124,113,91.12903225806451,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.removeDeleteSplittersFromSplitters,18,25,40,40,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.getParserFromTreebank,37,52,188,100,53.191489361702125,0,0
@@ edu.stanford.nlp.parser.lexparser.LexicalizedParser.main,144,215,2255,148,6.563192904656319,0,1
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.readInput,26,35,90,63,70.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.mergeSimultaneousNodes,17,23,69,46,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.removeEmptyNodes,17,22,77,52,67.53246753246754,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.buildWordsAtTime,11,13,27,19,70.37037037037037,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.buildWordsStartAt,8,9,16,12,75.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.buildWordsEndAt,8,9,16,12,75.0,0,1
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.removeRedundency,19,25,46,31,67.3913043478261,0,1
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.removeRedundentPair,30,43,107,79,73.83177570093457,0,1
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.changeStartTimes,22,29,76,64,84.21052631578947,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.changeEndTimes,22,29,76,64,84.21052631578947,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.removeSilence,22,29,43,39,90.69767441860465,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.mergeDuplicates,15,19,67,44,65.67164179104478,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.printWords,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.processLattice,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.<init>,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.getWordsOverSpan,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.HTKLatticeReader.main,18,24,61,18,29.508196721311474,0,0
@@ edu.stanford.nlp.parser.lexparser.IterativeCKYPCFGParser.doInsideScores,5,5,8,4,50.0,0,1
@@ edu.stanford.nlp.parser.lexparser.IterativeCKYPCFGParser.doInsideScoresHelper,245,368,1104,715,64.76449275362319,0,2
@@ edu.stanford.nlp.parser.lexparser.GermanUnknownWordModelTrainer.buildUWM,4,4,17,16,94.11764705882352,0,1
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.headFinder,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.typedDependencyHeadFinder,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.lex,11,14,43,35,81.3953488372093,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.diskTreebank,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.memoryTreebank,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.transformTree,233,380,980,385,39.285714285714285,0,2
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.display,7,8,35,35,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.listBasicCategories,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.hasV,7,8,2,2,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.setOptionFlag,123,186,427,370,86.65105386416862,0,1
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.dependencyGrammarExtractor,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.readGrammaticalStructureFromFile,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.getGrammaticalStructure,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseTreebankParserParams.main,8,9,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryRule.hashCode,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryRule.equals,9,13,31,31,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryRule.toStringNoScore,4,4,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryRule.compareTo,14,19,48,48,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreeAnnotatorAndBinarizer$TreeNullAnnotator.transformTreeHelper,14,18,29,23,79.3103448275862,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.compactGrammar,15,20,51,47,92.15686274509804,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.computeInputPrior,11,13,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.smartNegate,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.writeFile,7,9,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.convertGrammarToGraphs,14,18,29,22,75.86206896551724,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.getGraphFromMap,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.getTopCategoryOfSyntheticState,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.addOneUnaryRule,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.addOneBinaryRule,17,22,44,26,59.09090909090909,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.isSyntheticState,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.GrammarCompactor.convertGraphsToGrammar,46,64,119,110,92.43697478991596,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel.<init>,12,15,38,38,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel.score,19,27,64,52,81.25,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel.scoreGT,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel.getSignature,14,19,30,30,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BaseUnknownWordModel.addTagging,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.LatticeEdge.toString,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter$FA.input,7,8,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.parser.lexparser.OutsideRuleFilter$FA.advance,8,10,30,16,53.333333333333336,0,0
@@ edu.stanford.nlp.parser.lexparser.TestTagProjection.project,11,14,24,13,54.166666666666664,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammarExtractor.tallyInternalNode,5,5,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryGrammarExtractor.formResult,12,15,37,37,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.MaxMatchSegmenter.train,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.MaxMatchSegmenter.train,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.MaxMatchSegmenter.segment,15,19,81,24,29.629629629629626,0,0
@@ edu.stanford.nlp.parser.lexparser.AbstractTreebankParserParams$TypedDependencyTyper.makeDependency,8,9,17,17,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser$Derivation.equals,15,23,43,43,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ExhaustivePCFGParser$Derivation.hashCode,7,8,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.tagSet,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.ensureProbs,16,21,47,47,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.ruleIteratorByWord,7,8,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.numRules,8,9,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.initializeTraining,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.train,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.train,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.finishTraining,12,16,31,30,96.7741935483871,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.applyThresholds,18,27,74,74,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.main,13,16,20,19,95.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.testOnTreebank,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.ChineseMaxentLexicon.score,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.StringBinaryRule.equals,23,34,63,63,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.StringBinaryRule.hashCode,11,13,18,18,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryHeadFinder.determineHead,7,9,16,10,62.5,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryHeadFinder.determineHead,7,9,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.parser.lexparser.BinaryHeadFinder.determineBinaryHead,10,14,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreebankAnnotator.annotateTrees,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.TreebankAnnotator.deannotateTrees,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreebankAnnotator.getTrees,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreebankAnnotator.removeDependencyRoots,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreebankAnnotator.removeDependencyRoot,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.lexparser.TreebankAnnotator.<init>,5,5,8,8,100.0,0,1
@@ edu.stanford.nlp.parser.lexparser.demo.ParserDemo.main,10,12,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.parser.lexparser.demo.ParserDemo.demoDP,9,11,14,8,57.14285714285714,0,0
@@ edu.stanford.nlp.parser.lexparser.demo.ParserDemo2.main,26,33,40,34,85.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter$ScoredParsesIterator.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter$ScoredParsesIterator.getNext,19,27,76,38,50.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter$ScoredParsesIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter$ScoredParsesIterator.next,7,9,24,24,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter.stringToParses,5,6,8,7,87.5,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter.parsesToString,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter.printScoredTrees,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakScoredParsesReaderWriter.printScoredTrees,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakParser.getBestParse,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakParser.getBestScoredParse,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakParser.getKBestParses,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakParser.getKBestParses,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakParser.printSentences,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.charniak.CharniakParser.runCharniak,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.WeightMap.writeObject,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.WeightMap.readObject,8,9,25,17,68.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CompoundUnaryTransition.<init>,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CompoundUnaryTransition.isLegal,33,49,65,61,93.84615384615384,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CompoundUnaryTransition.apply,5,5,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CompoundUnaryTransition.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CompoundUnaryTransition.toString,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.<init>,11,13,29,20,68.96551724137932,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.averageScoredModels,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.averageModels,21,27,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.condenseFeatures,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.filterFeatures,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.numWeights,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.maxAbs,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.outputStats,8,9,15,12,80.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.tagSet,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.findHighestScoringTransition,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.findHighestScoringTransitions,14,19,40,30,75.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.trainTree,79,121,344,215,62.5,0,1
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.trainBatch,13,16,19,19,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.augmentSubsentences,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.outputFirstErrors,9,12,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.outputReordererStats,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.outputTransitionStats,11,13,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.trainModel,73,109,286,186,65.03496503496503,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.pruneFeatures,10,13,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.PerceptronModel.trainModel,15,21,77,62,80.51948051948052,0,0
@@ edu.stanford.nlp.parser.shiftreduce.TransitionTypeEval.evaluate,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.TransitionTypeEval.display,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.FeatureFactory.getFeatureFromCoreLabel,16,21,21,18,85.71428571428571,0,1
@@ edu.stanford.nlp.parser.shiftreduce.FeatureFactory.getRecentDependent,28,40,67,39,58.2089552238806,0,0
@@ edu.stanford.nlp.parser.shiftreduce.FeatureFactory.getStackLabel,23,32,74,19,25.675675675675674,0,0
@@ edu.stanford.nlp.parser.shiftreduce.FeatureFactory.getQueueLabel,7,9,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.FeatureFactory.getCoreLabel,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.<init>,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.pack,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.Weight.pack,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.score,7,8,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.addScaled,5,5,11,7,63.63636363636363,0,1
@@ edu.stanford.nlp.parser.shiftreduce.Weight.condense,20,27,61,31,50.81967213114754,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.getScore,9,11,24,15,62.5,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.updateWeight,15,20,55,42,76.36363636363637,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.maxAbs,7,8,18,11,61.111111111111114,0,1
@@ edu.stanford.nlp.parser.shiftreduce.Weight.l1Reg,10,12,26,19,73.07692307692307,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.l2Reg,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.toString,7,8,16,8,50.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.writeBytes,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.shiftreduce.Weight.readBytes,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.shiftreduce.FinalizeTransition.isLegal,19,28,46,46,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.FinalizeTransition.equals,6,7,6,6,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParserQuery.parseInternal,38,54,118,67,56.779661016949156,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParserQuery.restoreOriginalWords,12,16,24,24,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BinaryTransition.isLegal,58,91,147,147,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BinaryTransition.isBinarized,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BinaryTransition.apply,8,10,31,25,80.64516129032258,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BinaryTransition.equals,10,13,19,19,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BinaryTransition.hashCode,5,6,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BinaryTransition.toString,11,14,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.getStackNode,7,8,20,13,65.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.State.getQueueNode,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.getSeparatorBetween,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.getSeparatorBetween,8,11,15,15,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.getSeparatorCount,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.State.getSeparatorCount,9,12,26,16,61.53846153846154,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.getSeparator,24,34,59,52,88.13559322033898,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.findSeparators,10,12,25,13,52.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.endOfQueue,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.State.toString,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.TrainingResult.<init>,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.TrainingResult.<init>,5,5,25,13,52.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CreateTransitionSequence.createTransitionSequences,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CreateTransitionSequence.createTransitionSequenceHelper,31,45,72,63,87.5,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftTransition.isLegal,20,28,42,42,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftTransition.apply,4,4,12,12,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ShiftTransition.equals,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addUnaryStackFeatures,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addUnaryQueueFeatures,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addBinaryFeatures,9,11,30,30,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addPositionFeatures,9,12,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addSeparatorFeature,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addSeparatorFeature,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addSeparatorFeatures,7,9,22,22,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addSeparatorFeatures,12,19,40,38,95.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addEdgeFeatures,12,16,47,47,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BasicFeatureFactory.addEdgeFeatures2,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.IdleTransition.equals,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.CombinationFeatureFactory.featurize,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ReorderingOracle.reorder,49,75,91,91,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ReorderingOracle.reorderIncorrectBinaryTransition,19,27,37,17,45.94594594594595,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ReorderingOracle.reorderIncorrectShiftTransition,35,50,114,59,51.75438596491229,0,0
@@ edu.stanford.nlp.parser.shiftreduce.TrainingExample.trainTransitions,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.shiftreduce.TrainingExample.initialStateFromGoldTagTree,5,5,16,9,56.25,0,0
@@ edu.stanford.nlp.parser.shiftreduce.BaseModel.findEmergencyTransition,49,74,139,137,98.56115107913669,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceUtils.getBinarySide,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceUtils.isEquivalentCategory,6,7,10,7,70.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceUtils.leftIndex,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceUtils.rightIndex,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceUtils.findStateOnAgenda,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceUtils.transitionShortName,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceOptions.setOptionFlag,60,89,211,186,88.15165876777252,0,1
@@ edu.stanford.nlp.parser.shiftreduce.UnaryTransition.isLegal,19,29,42,42,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.UnaryTransition.addUnaryNode,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.UnaryTransition.createNode,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.UnaryTransition.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.UnaryTransition.toString,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.TreeRecorder.evaluate,8,10,23,23,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.defaultCoreNLPFlags,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.parse,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.parse,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.parseTree,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.getParserQueryEvals,12,17,34,34,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.initialStateFromTaggedSentence,12,15,29,16,55.172413793103445,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.buildTrainingOptions,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.checkLeafBranching,14,19,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.checkRootTransition,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.filterTreebank,10,12,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.binarizeTreebank,10,12,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.findKnownStates,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.findKnownStates,10,13,10,10,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.redoTags,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.redoTags,11,13,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.findRootStates,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.findRootOnlyStates,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.findRootOnlyStatesHelper,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.verifyTransitions,10,12,29,14,48.275862068965516,0,1
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.train,15,19,56,53,94.64285714285714,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.loadModel,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser.main,33,48,281,35,12.455516014234876,0,0
@@ edu.stanford.nlp.parser.shiftreduce.DistsimFeatureFactory.addDistsimFeatures,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.shiftreduce.demo.ShiftReduceDemo.main,17,24,31,11,35.483870967741936,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserClient.readResult,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserClient.getParse,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserClient.getTree,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.loadModel,5,5,7,5,71.42857142857143,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.processRequest,30,51,46,26,56.52173913043478,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.handleTokenize,9,11,25,16,64.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.handleLemma,9,11,25,16,64.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.handleDependencies,12,16,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.handleTree,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.handleParse,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.parse,6,7,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.parser.server.LexicalizedParserServer.main,19,26,67,20,29.850746268656714,0,0
@@ edu.stanford.nlp.parser.nndep.ParsingSystem.<init>,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.ParsingSystem.getTransitionID,7,8,20,11,55.00000000000001,0,0
@@ edu.stanford.nlp.parser.nndep.ParsingSystem.getPunctuationTags,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.ParsingSystem.evaluate,27,39,173,68,39.30635838150289,0,0
@@ edu.stanford.nlp.parser.nndep.ParsingSystem.getUAS,6,7,5,5,100.0,0,1
@@ edu.stanford.nlp.parser.nndep.ParsingSystem.getUASnoPunc,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.getHead,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.getLabel,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.getRoot,7,8,18,9,50.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.isSingleRoot,10,12,22,9,40.909090909090914,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.isTree,19,26,73,33,45.20547945205479,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.isProjective,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.visitTree,16,22,55,31,56.36363636363636,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.equal,11,14,34,24,70.58823529411765,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyTree.print,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier$CostFunction.process,65,89,255,157,61.568627450980394,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier$CostFunction.lambda$process$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParserCache.loadFromModelFile,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.<init>,12,15,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.getToPreCompute,10,12,22,17,77.27272727272727,0,1
@@ edu.stanford.nlp.parser.nndep.Classifier.computeCostFunction,13,16,27,16,59.25925925925925,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.takeAdaGradientStep,24,31,118,75,63.559322033898304,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.validateTraining,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.preCompute,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.computeScores,13,17,59,48,81.35593220338984,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.matrixMultiply,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.matrixMultiplySlice,8,9,27,14,51.85185185185185,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.matrixMultiply,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier.matrixMultiplySliceSum,8,9,29,15,51.724137931034484,0,1
@@ edu.stanford.nlp.parser.nndep.Classifier.addCubeInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.parser.nndep.Config.setProperties,14,18,32,32,100.0,0,1
@@ edu.stanford.nlp.parser.nndep.Config.getLanguage,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.CoNLLUTagUpdater.main,11,13,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Util.scaling,14,17,45,23,51.11111111111111,0,0
@@ edu.stanford.nlp.parser.nndep.Util.generateDict,10,12,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Util.getRandom,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Util.getRandomSubList,7,8,21,11,52.38095238095239,0,0
@@ edu.stanford.nlp.parser.nndep.Util.loadConllFile,17,21,18,18,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Util.writeConllFile,8,9,25,16,64.0,0,0
@@ edu.stanford.nlp.parser.nndep.Util.printTreeStats,11,14,20,11,55.00000000000001,0,0
@@ edu.stanford.nlp.parser.nndep.ArcStandard.isTerminal,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.ArcStandard.makeTransitions,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.ArcStandard.initialConfiguration,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.parser.nndep.ArcStandard.canApply,35,51,47,47,100.0,0,1
@@ edu.stanford.nlp.parser.nndep.ArcStandard.apply,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.ArcStandard.getOracle,9,13,26,26,100.0,0,1
@@ edu.stanford.nlp.parser.nndep.ArcStandard.canReach,50,72,243,116,47.73662551440329,0,0
@@ edu.stanford.nlp.parser.nndep.ArcStandard.isOracle,10,14,26,26,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParserCache$DependencyParserSpecification.<init>,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParserCache$DependencyParserSpecification.equals,12,16,25,25,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.getWordID,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.getPosID,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.getFeatures,11,13,34,22,64.70588235294117,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.getFeatureArray,11,13,28,16,57.14285714285714,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.genTrainExamples,26,36,105,66,62.857142857142854,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.generateIDs,11,13,19,11,57.89473684210527,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.genDictionaries,22,28,65,38,58.46153846153847,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.writeModelFile,42,55,129,69,53.48837209302325,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.writeEmbedding,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.loadModelFile,47,62,182,116,63.73626373626373,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.readEmbedFile,19,25,54,42,77.77777777777779,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.train,26,37,137,114,83.21167883211679,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.setupClassifierForTraining,94,135,376,256,68.08510638297872,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.predictInner,13,17,51,34,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.predict,13,16,36,31,86.11111111111111,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.makeGrammaticalRelation,9,14,31,31,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.makeGrammaticalStructure,6,8,20,20,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.predict,11,14,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.testCoNLLReturnScores,18,23,50,39,78.0,0,0
@@ edu.stanford.nlp.parser.nndep.DependencyParser.parseTextFile,14,17,29,26,89.65517241379311,0,1
@@ edu.stanford.nlp.parser.nndep.DependencyParser.initialize,6,7,17,17,100.0,0,1
@@ edu.stanford.nlp.parser.nndep.DependencyParser.main,17,23,34,30,88.23529411764706,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.shift,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.parser.nndep.Configuration.removeSecondTopStack,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.removeTopStack,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getStack,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getBuffer,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getWord,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getPOS,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getLeftChild,11,15,36,25,69.44444444444444,0,1
@@ edu.stanford.nlp.parser.nndep.Configuration.getRightChild,11,15,39,28,71.7948717948718,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.hasOtherChild,8,10,30,18,60.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getLeftValency,10,13,32,21,65.625,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getRightValency,10,13,37,26,70.27027027027027,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getLeftLabelSet,10,13,34,24,70.58823529411765,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getRightLabelSet,10,13,39,29,74.35897435897436,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.makeLabelSetString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.nndep.Configuration.getStr,17,22,54,30,55.55555555555556,0,1
@@ edu.stanford.nlp.parser.nndep.Classifier$Cost.backpropSaved,11,13,36,25,69.44444444444444,0,0
@@ edu.stanford.nlp.parser.nndep.Classifier$Cost.addL2Regularization,23,29,118,62,52.54237288135594,0,1
@@ edu.stanford.nlp.parser.nndep.demo.DependencyParserDemo.main,17,24,31,11,35.483870967741936,0,0
@@ edu.stanford.nlp.parser.nndep.demo.DependencyParserCoreNLPDemo.main,8,9,8,6,75.0,0,0
@@ edu.stanford.nlp.parser.common.ParsingThreadsafeProcessor.process,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.parser.common.ParserGrammar.parse,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.parser.common.ParserGrammar.loadTagger,6,7,24,23,95.83333333333334,0,0
@@ edu.stanford.nlp.parser.common.ParserGrammar.lemmatize,8,9,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.parser.common.ParserGrammar.loadModel,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.common.ParserGrammar.loadModelFromZip,14,19,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.parser.common.ParserUtils.xTree,8,10,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.parser.common.ParserUtils.flattenTallTrees,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.common.ParserUtils.lambda$flattenTallTrees$0,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.parser.common.ArgUtils.numSubArgs,6,7,17,8,47.05882352941176,0,0
@@ edu.stanford.nlp.parser.common.ArgUtils.printArgs,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.parser.common.ArgUtils.getWeightedTreebankDescription,21,30,61,38,62.295081967213115,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats$ObservedCorpusStats.addStatsForTree,14,19,48,48,100.0,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats$ObservedCorpusStats.getPercLensLessThan,7,8,10,7,70.0,0,1
@@ edu.stanford.nlp.parser.eval.TreebankStats$ObservedCorpusStats.display,21,27,34,34,100.0,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats$ObservedCorpusStats.computeFinalValues,14,17,33,24,72.72727272727273,0,1
@@ edu.stanford.nlp.parser.eval.UNKPrinter.main,39,56,94,42,44.680851063829785,0,1
@@ edu.stanford.nlp.parser.eval.TreebankStats.useSplit,10,12,9,9,100.0,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats.gatherStats,11,14,21,21,100.0,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats.dissectTree,20,29,46,36,78.26086956521739,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats.aggregateStats,21,29,94,75,79.7872340425532,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats.run,22,28,39,39,100.0,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats.main,12,16,32,28,87.5,0,0
@@ edu.stanford.nlp.parser.eval.TreebankStats.lambda$run$1,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.parser.eval.TreebankFactoredLexiconStats.main,53,72,134,121,90.29850746268657,0,1
@@ edu.stanford.nlp.parser.eval.TreebankFactoredLexiconStats.setToString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.range,8,10,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.math.ArrayMath.range,8,10,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.math.ArrayMath.doubleArrayToFloatArray,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.floatArrayToDoubleArray,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.floatArrayToDoubleArray,8,9,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.math.ArrayMath.doubleArrayToFloatArray,8,9,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.math.ArrayMath.exp,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.log,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.expInPlace,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.math.ArrayMath.logInPlace,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.math.ArrayMath.softmax,8,9,24,13,54.166666666666664,0,0
@@ edu.stanford.nlp.math.ArrayMath.addInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.addInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.addMultInPlace,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.multiplyInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.multiplyInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.divideInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.powInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.powInPlace,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.add,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.math.ArrayMath.add,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.math.ArrayMath.multiply,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.math.ArrayMath.multiply,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.math.ArrayMath.pow,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.math.ArrayMath.pow,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAddInPlace,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAddInPlace,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAddInPlace,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAddInPlace,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAddInPlace,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.math.ArrayMath.addInPlace,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseSubtractInPlace,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseScaleAddInPlace,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAdd,7,8,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAdd,7,8,17,13,76.47058823529412,0,1
@@ edu.stanford.nlp.math.ArrayMath.pairwiseAdd,7,8,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseScaleAdd,7,8,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseSubtract,7,8,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseSubtract,7,8,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.math.ArrayMath.dotProduct,7,8,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.math.ArrayMath.dotProduct,7,8,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.math.ArrayMath.dotProduct,7,8,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseMultiply,7,8,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseMultiply,7,8,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseMultiply,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseMultiply,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.math.ArrayMath.pairwiseDivideInPlace,7,8,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.math.ArrayMath.hasNaN,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.hasInfinite,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.hasNaN,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.countNaN,7,8,6,3,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.filterNaN,7,8,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.math.ArrayMath.countInfinite,7,8,6,3,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.countNonZero,7,8,6,3,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.countCloseToZero,7,8,8,5,62.5,0,0
@@ edu.stanford.nlp.math.ArrayMath.countPositive,7,8,6,3,50.0,0,1
@@ edu.stanford.nlp.math.ArrayMath.countNegative,7,8,6,3,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.filterInfinite,7,8,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.math.ArrayMath.sum,5,5,13,6,46.15384615384615,0,0
@@ edu.stanford.nlp.math.ArrayMath.sum,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.sum,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.sum,8,9,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.diag,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.iterativeAverage,5,5,6,2,33.33333333333333,0,0
@@ edu.stanford.nlp.math.ArrayMath.norm_inf,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.math.ArrayMath.norm_inf,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.math.ArrayMath.norm_1,8,9,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.math.ArrayMath.norm_1,8,9,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.math.ArrayMath.norm,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.norm,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.argmax,7,8,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.math.ArrayMath.argmax_tieLast,7,8,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.math.ArrayMath.max,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.math.ArrayMath.argmax,7,8,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.math.ArrayMath.argmin,7,8,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.math.ArrayMath.min,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.math.ArrayMath.safeMin,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.argmin,7,8,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.math.ArrayMath.argmin,7,8,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.math.ArrayMath.min,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.math.ArrayMath.argmax,7,8,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.math.ArrayMath.max,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.math.ArrayMath.min,8,9,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.max,8,9,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.safeMax,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.logSum,24,34,73,37,50.68493150684932,0,0
@@ edu.stanford.nlp.math.ArrayMath.logSum,22,31,76,40,52.63157894736842,0,0
@@ edu.stanford.nlp.math.ArrayMath.logSum,22,31,73,37,50.68493150684932,0,0
@@ edu.stanford.nlp.math.ArrayMath.logSum,18,24,64,23,35.9375,0,0
@@ edu.stanford.nlp.math.ArrayMath.innerProduct,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.innerProduct,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.load2DMatrixFromFile,8,9,29,15,51.724137931034484,0,0
@@ edu.stanford.nlp.math.ArrayMath.box,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.unboxToInt,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.box,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.unbox,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.indexOf,7,8,18,9,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.castToInt,8,9,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.math.ArrayMath.normalize,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.L1normalize,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.L2normalize,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.normalize,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.L2normalize,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.standardize,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.L2Norm,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.L2Norm,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.L1Norm,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.logNormalize,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.math.ArrayMath.sampleFromDistribution,9,11,26,15,57.692307692307686,0,0
@@ edu.stanford.nlp.math.ArrayMath.sampleFromDistribution,9,11,26,15,57.692307692307686,0,0
@@ edu.stanford.nlp.math.ArrayMath.klDivergence,8,9,25,12,48.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.median,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.safeMean,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.sumSquaredError,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.sumSquared,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.safeStdev,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.sampleWithoutReplacement,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.math.ArrayMath.shuffle,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.reverse,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.math.ArrayMath.contains,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.containsInSubarray,7,8,16,9,56.25,0,0
@@ edu.stanford.nlp.math.ArrayMath.pearsonCorrelation,8,9,32,17,53.125,0,0
@@ edu.stanford.nlp.math.ArrayMath.sigLevelByApproxRand,13,17,29,22,75.86206896551724,0,0
@@ edu.stanford.nlp.math.ArrayMath.sigLevelByApproxRand,11,14,25,21,84.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.sigLevelByApproxRand,17,22,37,24,64.86486486486487,0,0
@@ edu.stanford.nlp.math.ArrayMath.absDiffOfMeans,9,11,40,14,35.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.toBinaryString,11,13,15,7,46.666666666666664,0,0
@@ edu.stanford.nlp.math.ArrayMath.toString,15,19,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.math.ArrayMath.toString,15,19,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.math.ArrayMath.toString,15,19,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.math.ArrayMath.toString,15,19,32,20,62.5,0,0
@@ edu.stanford.nlp.math.ArrayMath.toString,41,56,130,83,63.84615384615384,0,0
@@ edu.stanford.nlp.math.ArrayMath.toString,35,48,119,80,67.22689075630252,0,0
@@ edu.stanford.nlp.math.ArrayMath.toString,30,40,103,66,64.07766990291263,0,0
@@ edu.stanford.nlp.math.ArrayMath.main,8,9,25,17,68.0,0,0
@@ edu.stanford.nlp.math.ArrayMath.deepCopy,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.addMultInto,5,5,12,8,66.66666666666666,0,1
@@ edu.stanford.nlp.math.ArrayMath.multiplyInto,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.math.ArrayMath.entropy,7,8,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.math.ArrayMath.assertFinite,8,10,24,12,50.0,0,0
@@ edu.stanford.nlp.math.DoubleAD.equals,10,13,19,19,100.0,0,0
@@ edu.stanford.nlp.math.DoubleAD.equals,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.math.DoubleAD.equals,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.math.ADMath.logSum,22,31,90,37,41.11111111111111,0,0
@@ edu.stanford.nlp.math.SloppyMath.max,6,7,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.math.SloppyMath.max,9,11,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.math.SloppyMath.max,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.max,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.min,6,7,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.math.SloppyMath.min,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.min,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.lgamma,5,5,15,7,46.666666666666664,0,0
@@ edu.stanford.nlp.math.SloppyMath.isDangerous,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.isVeryDangerous,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.math.SloppyMath.isCloseTo,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.logAdd,9,11,20,8,40.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.logAdd,9,11,20,8,40.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.nChooseK,7,8,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.math.SloppyMath.intPow,13,17,26,12,46.15384615384615,0,0
@@ edu.stanford.nlp.math.SloppyMath.intPow,7,8,18,4,22.22222222222222,0,0
@@ edu.stanford.nlp.math.SloppyMath.intPow,7,8,18,4,22.22222222222222,0,0
@@ edu.stanford.nlp.math.SloppyMath.hypergeometric,49,73,261,54,20.689655172413794,0,0
@@ edu.stanford.nlp.math.SloppyMath.exactBinomial,8,9,29,12,41.37931034482759,0,0
@@ edu.stanford.nlp.math.SloppyMath.oneTailedFishersExact,42,59,155,79,50.967741935483865,0,0
@@ edu.stanford.nlp.math.SloppyMath.chiSquare2by2,8,9,22,9,40.909090909090914,0,0
@@ edu.stanford.nlp.math.SloppyMath.sigmoid,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.acos,9,12,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.math.SloppyMath.poisson,8,11,15,15,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.factorial,5,5,10,3,30.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.parseDouble,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.math.SloppyMath.segmentDouble,13,17,35,12,34.285714285714285,0,0
@@ edu.stanford.nlp.math.SloppyMath.parseInt,11,13,24,8,33.33333333333333,0,0
@@ edu.stanford.nlp.math.SloppyMath.main,11,14,16,16,100.0,0,0
@@ edu.stanford.nlp.simple.SpanishSentence$2.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence$1.<init>,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.FrenchDocument$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.ArabicDocument$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.ChineseSentence$2.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.GermanSentence$2.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.SpanishSentence$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence$2.<init>,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.simple.GermanSentence$1.<init>,6,7,5,5,100.0,0,1
@@ edu.stanford.nlp.simple.ChineseSentence$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms$1.<init>,5,5,12,12,100.0,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms$1.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms$1.next,4,4,13,13,100.0,0,0
@@ edu.stanford.nlp.simple.ArabicSentence$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.ChineseDocument$2.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.<init>,14,19,37,33,89.1891891891892,0,0
@@ edu.stanford.nlp.simple.Sentence.<init>,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.simple.Sentence.<init>,11,15,36,32,88.88888888888889,0,0
@@ edu.stanford.nlp.simple.Sentence.<init>,8,11,24,24,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.<init>,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.simple.Sentence.<init>,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.serialize,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.tokens,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.simple.Sentence.regexner,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.mentions,18,26,60,39,65.0,0,0
@@ edu.stanford.nlp.simple.Sentence.mentions,20,29,56,35,62.5,0,0
@@ edu.stanford.nlp.simple.Sentence.dependencies,6,8,15,15,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.governor,12,15,11,11,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.governors,11,13,16,12,75.0,0,0
@@ edu.stanford.nlp.simple.Sentence.incomingDependencyLabel,12,15,11,11,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.incomingDependencyLabels,11,13,16,12,75.0,0,0
@@ edu.stanford.nlp.simple.Sentence.sentiment,19,33,7,7,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.coref,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.asCoreMap,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.asCoreLabels,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.updateTokens,7,8,20,13,65.0,0,0
@@ edu.stanford.nlp.simple.Sentence.updateParse,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.equals,18,25,57,50,87.71929824561403,0,0
@@ edu.stanford.nlp.simple.Sentence.hashCode,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.substring,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.sentenceid,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.find,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.semgrex,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.lambda$coref$11,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.simple.Sentence.lambda$kbp$10,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.lambda$kbp$9,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.lambda$openie$7,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.simple.Sentence.lambda$openie$6,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Sentence.lambda$operators$3,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.FrenchSentence$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.Document.useServer,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Document.useServer,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.Document.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.simple.Document.<init>,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.simple.Document.serialize,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.simple.Document.json,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.Document.jsonMinified,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.Document.xml,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.Document.xmlMinified,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.Document.sentences,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Document.sentences,13,17,34,33,97.05882352941177,0,0
@@ edu.stanford.nlp.simple.Document.coref,21,28,45,45,100.0,0,0
@@ edu.stanford.nlp.simple.Document.docid,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.simple.Document.forceSentences,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.Document.runPOS,13,18,39,35,89.74358974358975,0,0
@@ edu.stanford.nlp.simple.Document.runLemma,13,18,40,36,90.0,0,0
@@ edu.stanford.nlp.simple.Document.mockLemma,9,12,29,25,86.20689655172413,0,0
@@ edu.stanford.nlp.simple.Document.runNER,13,18,40,36,90.0,0,0
@@ edu.stanford.nlp.simple.Document.runRegexner,9,11,25,21,84.0,0,0
@@ edu.stanford.nlp.simple.Document.runParse,24,35,68,58,85.29411764705883,0,0
@@ edu.stanford.nlp.simple.Document.runDepparse,13,18,41,37,90.2439024390244,0,0
@@ edu.stanford.nlp.simple.Document.runNatlog,13,18,41,37,90.2439024390244,0,0
@@ edu.stanford.nlp.simple.Document.runOpenie,11,14,33,29,87.87878787878788,0,0
@@ edu.stanford.nlp.simple.Document.runKBP,15,20,45,41,91.11111111111111,0,0
@@ edu.stanford.nlp.simple.Document.runSentiment,17,25,55,51,92.72727272727272,0,0
@@ edu.stanford.nlp.simple.Document.asAnnotation,8,10,15,14,93.33333333333333,0,1
@@ edu.stanford.nlp.simple.Document.fromProto,16,21,50,35,70.0,0,0
@@ edu.stanford.nlp.simple.Document.equals,13,18,35,35,100.0,0,0
@@ edu.stanford.nlp.simple.Document.hashCode,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.simple.ArabicSentence$2.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.Token.pad,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.simple.Token.padOpt,6,7,11,11,100.0,0,1
@@ edu.stanford.nlp.simple.Token.characterOffsetBegin,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.simple.Token.characterOffsetEnd,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.simple.Token.before,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.simple.Token.after,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms.keyphraseSpans,53,83,258,44,17.05426356589147,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms.headOfSpan,19,27,65,47,72.3076923076923,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms.modeInSpan,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms.loopyDependencyPathBetween,39,53,93,77,82.79569892473118,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms.dependencyPathBetween,38,54,135,77,57.03703703703704,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms.unescapeHTML,8,9,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.simple.SentenceAlgorithms.lambda$keyphraseSpans$0,17,23,29,29,100.0,0,0
@@ edu.stanford.nlp.simple.GermanDocument$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.SpanishDocument$1.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.FrenchSentence$2.<init>,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.simple.SentimentClass.isPositive,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.simple.SentimentClass.isNegative,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.simple.SentimentClass.isExtreme,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.simple.SentimentClass.isMild,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.simple.SentimentClass.isNeutral,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.simple.SentimentClass.fromInt,8,12,12,12,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$ApplyActionWrapper.apply,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.time.TimeFormatter.makeRegex,8,9,8,5,62.5,0,0
@@ edu.stanford.nlp.time.TimeFormatter.parsePatternTo,60,99,135,127,94.07407407407408,0,0
@@ edu.stanford.nlp.time.TimeFormatter.isSpecialRegexChar,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter.parseToken,45,70,139,90,64.74820143884892,0,1
@@ edu.stanford.nlp.time.TimeFormatter.isNumericToken,7,10,8,8,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter.lambda$static$0,6,7,10,10,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$TemporalOp$14.apply,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$14.apply,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$14.apply,11,17,19,19,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$6.apply,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.printNode,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.getAttribute,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.removeChildren,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.getMatchingNodes,15,20,36,31,86.11111111111111,0,0
@@ edu.stanford.nlp.time.XMLUtils.getNodeText,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.getNode,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.getMatchingNodes,16,22,38,33,86.8421052631579,0,0
@@ edu.stanford.nlp.time.XMLUtils.getNodeTexts,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.getNodeText,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.getAttributeValue,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.time.XMLUtils.getNode,5,6,5,5,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$TemporalOp$4.apply,9,12,15,15,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$OrdinalTime.toFormattedString,11,15,19,19,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$OrdinalTime.intersect,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$OrdinalTime.resolve,11,15,31,31,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$16.apply,12,18,19,19,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp.apply,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.processTimebankCsvSent,34,46,125,88,70.39999999999999,0,0
@@ edu.stanford.nlp.time.SUTimeMain.processTimebankCsv,24,34,80,41,51.24999999999999,0,0
@@ edu.stanford.nlp.time.SUTimeMain.processTempEval2Doc,57,85,113,96,84.95575221238938,0,0
@@ edu.stanford.nlp.time.SUTimeMain.wordsToSentence,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.sentencesToDocument,11,13,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.time.SUTimeMain.findTimex,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.updateTimexText,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.readTimexAttrExts,47,74,122,91,74.59016393442623,0,0
@@ edu.stanford.nlp.time.SUTimeMain.processTempEval2Tab,15,20,73,35,47.94520547945205,0,1
@@ edu.stanford.nlp.time.SUTimeMain.processTempEval2,13,17,26,26,100.0,0,1
@@ edu.stanford.nlp.time.SUTimeMain.processTempEval3File,13,17,29,29,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.getPipeline,16,25,13,13,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.configLogger,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.time.SUTimeMain.createTimexNodes,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.createTimexNodesPresorted,18,23,40,28,70.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.processTextFile,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.processText,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.annotationToTmlTextElement,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.time.SUTimeMain.main,8,12,33,33,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain.lambda$processTimebankCsvSent$0,7,8,16,16,100.0,0,0
@@ edu.stanford.nlp.time.Options.<init>,14,19,53,32,60.37735849056604,0,0
@@ edu.stanford.nlp.time.TimeFormatter$FormatComponent.appendQuantifier,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$FormatComponent.appendRegex,8,10,20,20,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$12.apply,12,17,20,20,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.toTime,29,43,81,47,58.0246913580247,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.toFormattedString,12,16,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.getPeriod,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.compareTo,17,25,21,21,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.intersect,13,18,23,23,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.intersect,7,9,13,13,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.min,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Duration.max,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$IsoDate.<init>,19,26,31,31,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$IsoDate.<init>,32,48,113,36,31.858407079646017,0,1
@@ edu.stanford.nlp.time.SUTime$IsoDate.initBase,10,13,34,25,73.52941176470588,0,1
@@ edu.stanford.nlp.time.SUTime$IsoDate.toString,15,19,37,37,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$StandardTemporalType.createTemporal,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$StandardTemporalType.create,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithFields.multiplyBy,8,10,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithFields.divideBy,34,48,79,50,63.29113924050633,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithFields.getJodaTimePeriod,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithFields.getJodaTimeDuration,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithFields.resolve,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithFields.add,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$2.apply,14,20,31,31,100.0,0,1
@@ edu.stanford.nlp.time.JollyDayHolidays$JollyHoliday.toFormattedString,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays$JollyHoliday.intersect,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays$JollyHoliday.resolveWithYear,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays$JollyHoliday.resolve,9,12,13,13,100.0,0,0
@@ edu.stanford.nlp.time.SUTime.parseInstant,11,14,19,19,100.0,0,1
@@ edu.stanford.nlp.time.SUTime.parseDateTime,43,68,157,73,46.496815286624205,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TextDateComponent.<init>,10,12,34,23,67.64705882352942,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TextDateComponent.appendRegex0,8,9,8,5,62.5,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.<init>,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.hasTime,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.getTimexType,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.appendDateFormats,74,114,196,167,85.20408163265306,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.appendTimeFormats,23,33,52,52,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.getFormatter,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.getDuration,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.getRange,17,24,60,25,41.66666666666667,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.withStandardFields,10,14,29,23,79.3103448275862,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.reduceGranularityTo,5,6,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.padMoreSpecificFields,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.toFormattedString,9,11,21,16,76.19047619047619,0,1
@@ edu.stanford.nlp.time.SUTime$PartialTime.resolve,38,59,115,84,73.04347826086956,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.getCompatible,24,38,84,84,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.getPeriod,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.toList,11,16,49,37,75.51020408163265,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.intersect,32,46,71,71,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PartialTime.add,29,47,178,51,28.651685393258425,0,0
@@ edu.stanford.nlp.time.ParsedGigawordReader.toAnnotation,13,16,31,22,70.96774193548387,0,0
@@ edu.stanford.nlp.time.ParsedGigawordReader.preTerminals,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.time.ParsedGigawordReader.isPreterminal,9,11,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$10.apply,15,22,26,26,100.0,0,1
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns.<init>,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns.initEnv,13,16,13,13,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns.determineRelFlags,9,13,20,13,65.0,0,0
@@ edu.stanford.nlp.time.HeidelTimeAnnotator.annotate,25,36,97,46,47.42268041237113,0,0
@@ edu.stanford.nlp.time.HeidelTimeAnnotator.toTimexCoreMaps,35,48,97,58,59.79381443298969,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$5.apply,14,20,31,31,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimePatternExtractRuleCreator.create,21,29,59,59,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$17.apply,6,8,9,9,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PeriodicTemporalSet.isGrounded,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PeriodicTemporalSet.getTimexAttributes,8,10,24,24,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PeriodicTemporalSet.resolve,8,9,18,18,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$PeriodicTemporalSet.toFormattedString,10,13,19,19,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$PeriodicTemporalSet.intersect,8,10,29,29,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Range.isGrounded,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Range.getTimexAttributes,12,15,25,25,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Range.toFormattedString,31,45,71,71,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Range.resolve,20,28,70,64,91.42857142857143,0,0
@@ edu.stanford.nlp.time.SUTime$Range.offset,12,15,28,25,89.28571428571429,0,0
@@ edu.stanford.nlp.time.SUTime$Range.add,12,15,24,22,91.66666666666666,0,1
@@ edu.stanford.nlp.time.SUTime$Range.beginTime,6,8,20,20,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Range.mid,15,22,42,42,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Range.intersect,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Range.contains,7,10,16,16,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$15.apply,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$15.apply,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$15.apply,11,17,19,19,100.0,0,0
@@ edu.stanford.nlp.time.TimeAnnotator.annotate,19,26,42,36,85.71428571428571,0,0
@@ edu.stanford.nlp.time.TimeAnnotator.annotateSingleSentence,5,6,10,9,90.0,0,1
@@ edu.stanford.nlp.time.JodaTimeUtils.hasField,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.hasYYYYMMDD,9,12,8,8,100.0,0,1
@@ edu.stanford.nlp.time.JodaTimeUtils.hasYYMMDD,9,12,8,8,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.hasField,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.setField,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getSupportedDurationFields,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getUnsupportedDurationPeriod,12,16,37,14,37.83783783783784,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.combine,47,72,267,30,11.235955056179774,0,1
@@ edu.stanford.nlp.time.JodaTimeUtils.getMostGeneral,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getMostSpecific,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getMostGeneral,7,8,17,8,47.05882352941176,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getMostSpecific,7,8,15,6,40.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getJodaTimePeriod,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.combineMoreGeneralFields,32,50,172,48,27.906976744186046,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.discardMoreSpecificFields,12,17,45,24,53.333333333333336,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.discardMoreSpecificFields,7,8,22,12,54.54545454545454,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.discardMoreSpecificFields,7,8,23,13,56.52173913043478,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.padMoreSpecificFields,35,53,212,55,25.943396226415093,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.isCompatible,12,16,25,20,80.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.resolveDowToDay,9,14,17,17,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.withWeekYear,8,9,29,11,37.93103448275862,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.resolveDowToDay,7,10,11,11,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.resolveWeek,8,12,15,15,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.resolveWeek,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getInstant,35,48,62,52,83.87096774193549,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.fromTimezone,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.getPartial,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.isMoreGeneral,6,8,14,14,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.isMoreSpecific,6,8,14,14,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.zeroPad,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.noFurtherFields,29,40,115,43,37.391304347826086,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.timexDateValue,96,157,221,221,100.0,0,1
@@ edu.stanford.nlp.time.JodaTimeUtils.consistentWithForced,23,31,47,24,51.06382978723404,0,0
@@ edu.stanford.nlp.time.JodaTimeUtils.timexDurationValue,68,97,143,106,74.12587412587412,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$7.apply,8,10,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.time.SUTimeMain$TimebankTimex.<init>,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$3.apply,8,10,17,17,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$IsoTime.<init>,17,21,16,16,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$IsoTime.<init>,10,13,17,17,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$IsoTime.initBase,14,19,56,38,67.85714285714286,0,0
@@ edu.stanford.nlp.time.SUTime$TimeWithRange.getDuration,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TimeWithRange.getRange,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TimeWithRange.add,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TimeWithRange.intersect,11,15,22,22,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TimeWithRange.resolve,6,7,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.time.SUTime$TimeWithRange.toFormattedString,6,7,10,9,90.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$11.apply,15,22,26,26,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$MatchedExpressionValueTypeMatchNodePattern.match,7,8,8,8,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$TemporalOp$13.apply,12,17,20,20,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$1.apply,9,12,15,15,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.init,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.extractTimeExpressionCoreMaps,23,32,77,27,35.064935064935064,0,0
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.toCoreMaps,17,24,35,33,94.28571428571428,0,1
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.extractTimeExpressions,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.extractTimeExpressions,44,65,100,84,84.0,0,0
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.resolveTimeExpression,8,10,20,20,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.resolveTimeExpressions,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpressionExtractorImpl.findReferenceDate,13,18,13,13,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpression.addMod,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpression.extractAnnotation,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpression.extractAnnotation,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpression.getTemporal,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.time.TimeExpression.lambda$static$0,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RefTime.toFormattedString,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RefTime.offset,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$RefTime.resolve,7,9,13,13,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeSimpleParser.parseOrNull,12,16,13,13,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeSimpleParser.parse,10,14,13,13,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeSimpleParser.parseUsingCache,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.time.HeidelTimeKBPAnnotator.annotate,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.time.HeidelTimeKBPAnnotator.getPubDate,9,12,12,12,100.0,0,0
@@ edu.stanford.nlp.time.HeidelTimeKBPAnnotator.prepareHeidelTimeInput,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$CustomDateFormatExtractor.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$CustomDateFormatExtractor.apply,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$CustomDateFormatExtractor.apply,8,10,12,9,75.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$NumericDateComponent.appendRegex0,8,10,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.time.TimeFormatter$NumericDateComponent.parseValue,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$5.checkArgs,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$5.apply,21,29,68,37,54.41176470588235,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.getJodaTimeInstant,14,22,55,36,65.45454545454545,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.getDuration,23,31,48,48,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.getPeriod,25,35,69,39,56.52173913043478,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.getIntersectedRange,16,23,43,43,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.getRange,14,19,56,56,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.intersect,25,39,70,70,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.resolve,27,39,77,64,83.11688311688312,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.getFormatter,17,25,53,41,77.35849056603774,0,0
@@ edu.stanford.nlp.time.SUTime$CompositePartialTime.getTimexType,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.isGrounded,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.getTimexAttributes,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.toFormattedString,16,23,40,40,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.resolve,17,23,63,51,80.95238095238095,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.equals,21,31,59,59,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.hashCode,11,13,18,18,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.add,7,8,26,23,88.46153846153845,0,0
@@ edu.stanford.nlp.time.SUTime$RelativeTime.intersect,7,10,25,25,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$GroundedTime.intersect,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$GroundedTime.intersect,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimeZoneIdComponent.updateTemporal,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$ExplicitTemporalSet.setTimeZone,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$ExplicitTemporalSet.resolve,5,5,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.time.SUTime$ExplicitTemporalSet.toFormattedString,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$ExplicitTemporalSet.intersect,12,16,20,20,100.0,0,0
@@ edu.stanford.nlp.time.Timex.<init>,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.time.Timex.<init>,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.time.Timex.init,28,39,46,45,97.82608695652173,0,0
@@ edu.stanford.nlp.time.Timex.toString,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.time.Timex.equals,21,31,59,59,100.0,0,0
@@ edu.stanford.nlp.time.Timex.hashCode,8,9,14,14,100.0,0,1
@@ edu.stanford.nlp.time.Timex.toXmlElement,16,22,48,48,100.0,0,0
@@ edu.stanford.nlp.time.Timex.fromXml,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.time.Timex.fromMap,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.time.Timex.getDate,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.time.Timex.getRange,54,83,176,176,100.0,0,1
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$1.addEndPoints,14,20,33,27,81.81818181818183,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$1.apply,42,58,69,65,94.20289855072464,0,0
@@ edu.stanford.nlp.time.SUTime$IsoDateTime.hasTime,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$3.checkArgs,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$3.apply,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTimeMain$TimebankSent.add,10,14,36,36,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimeZoneOffsetComponent.appendRegex0,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimeZoneOffsetComponent.parseOffsetMillis,31,46,94,72,76.59574468085107,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.getPeriod,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.getGranularity,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.getUncertaintyGranularity,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.getTimexAttributes,10,14,26,26,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.getTimexType,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.setTimeZone,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.next,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Temporal.prev,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$9.apply,10,14,20,20,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$4.checkArgs,15,23,18,18,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$4.apply,25,37,56,41,73.21428571428571,0,1
@@ edu.stanford.nlp.time.SUTime$DurationWithMillis.multiplyBy,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithMillis.divideBy,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationWithMillis.add,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$FormatterBuilder.toTextRegex,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$FormatterBuilder.appendComponent,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$FormatterBuilder.appendHourOfDay,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$FormatterBuilder.appendQuantifier,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$TimexTypeMatchNodePattern.match,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$SimpleTime.toFormattedString,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.time.GUTimeAnnotator.annotate,22,31,81,39,48.148148148148145,0,0
@@ edu.stanford.nlp.time.GUTimeAnnotator.toInputXML,17,23,47,41,87.2340425531915,0,0
@@ edu.stanford.nlp.time.GUTimeAnnotator.toTimexCoreMaps,40,55,113,68,60.17699115044248,0,1
@@ edu.stanford.nlp.time.SUTime$TimeIndex.getTemporalExpr,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TimeIndex.getTemporal,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TimeIndex.addTemporalExpr,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TimeIndex.toString,11,13,16,13,81.25,0,0
@@ edu.stanford.nlp.time.HeidelTimeKBPAnnotator$HeidelTimeOutputReader.process,28,39,124,29,23.387096774193548,0,0
@@ edu.stanford.nlp.time.HeidelTimeKBPAnnotator$HeidelTimeOutputReader.makeTimexMap,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.time.HeidelTimeKBPAnnotator$HeidelTimeOutputReader.toNodeSequence,16,22,54,36,66.66666666666666,0,0
@@ edu.stanford.nlp.time.SUTime$DurationRange.toFormattedString,8,10,20,20,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationRange.getJodaTimePeriod,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationRange.getJodaTimeDuration,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationRange.add,8,9,15,15,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationRange.multiplyBy,8,9,15,15,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$DurationRange.divideBy,8,9,15,15,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.getGranularity,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.getInterval,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.isComparable,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.getTimexType,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.offset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.closest,8,10,15,5,33.33333333333333,0,0
@@ edu.stanford.nlp.time.SUTime$Time.distance,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.difference,10,14,20,20,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.makeComposite,7,10,20,17,85.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.intersect,13,18,25,25,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.intersect,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.time.SUTime$Time.min,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$Time.max,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$2.checkArgs,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.time.GenericTimeExpressionPatterns$2.apply,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays.init,11,14,23,20,86.95652173913044,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays.bind,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays.getAllHolidaysMap,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays.getAllHolidaysCVMap,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays.getAllHolidays,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.time.JollyDayHolidays.getAllHolidays,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.time.JollyDayHolidays.isGetter,7,9,8,8,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$8.apply,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.time.ParsedGigawordReader$1.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.time.ParsedGigawordReader$1.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.ParsedGigawordReader$1.findReader,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.time.ParsedGigawordReader$1.findAnnotation,15,21,28,28,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$RelaxedNumericDateComponent.<init>,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.time.TimeFormatter$RelaxedNumericDateComponent.appendRegex0,8,10,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.time.TimeFormatter$RelaxedNumericDateComponent.updateTemporal,9,11,12,12,100.0,0,1
@@ edu.stanford.nlp.time.TimeFormatter$DateTimeFieldComponent.updateTemporal,7,9,16,15,93.75,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.compareTo,12,17,34,34,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.getDuration,8,10,18,18,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.getRange,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.add,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.resolve,10,13,38,34,89.47368421052632,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.getJodaTimeInstant,7,9,19,12,63.1578947368421,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.getJodaTimePartial,8,11,23,16,69.56521739130434,0,0
@@ edu.stanford.nlp.time.SUTime$InexactTime.toFormattedString,14,19,32,32,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimeZoneComponent.<init>,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimeZoneComponent.updateTimeZoneNames,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimeZoneComponent.parseDateTimeZone,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.time.TimeFormatter$TimeZoneComponent.updateTemporal,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.SUTime$TemporalOp$18.apply,10,14,20,20,100.0,0,0
@@ edu.stanford.nlp.time.TimexTreeAnnotator.annotate,17,22,27,21,77.77777777777779,0,1
@@ edu.stanford.nlp.time.TimexTreeAnnotator.endOffset,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.time.TimexTreeAnnotator.lambda$annotate$1,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.TimexTreeAnnotator.lambda$annotate$0,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.time.suservlet.SUTimeServlet.parseBoolean,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.time.suservlet.SUTimeServlet.doGet,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.time.suservlet.SUTimeServlet.getRuleFilepaths,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.time.suservlet.SUTimeServlet.getTimeAnnotatorProperties,15,21,29,21,72.41379310344827,0,1
@@ edu.stanford.nlp.time.suservlet.SUTimeServlet.displayAnnotation,34,45,76,54,71.05263157894737,0,1
@@ edu.stanford.nlp.time.suservlet.SUTimeServlet.addResults,13,17,37,32,86.48648648648648,0,1
@@ edu.stanford.nlp.time.suservlet.SUTimePipeline.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.time.suservlet.SUTimePipeline.getTimeAnnotator,13,21,3,3,100.0,0,0
@@ edu.stanford.nlp.time.suservlet.SUTimePipeline.process,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.time.suservlet.SUTimePipeline.main,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank.iterator,8,10,18,18,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank.isEmpty,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank.contains,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank.containsAll,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank.size,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank.toArray,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank.toArray,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.objectbank.ResettableReaderIteratorFactory.iterator,8,9,10,10,100.0,0,0
@@ edu.stanford.nlp.objectbank.ReaderIteratorFactory$ReaderIterator.setNextObject,18,24,40,39,97.5,0,0
@@ edu.stanford.nlp.objectbank.ReaderIteratorFactory$ReaderIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.objectbank.ReaderIteratorFactory$ReaderIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.objectbank.XMLBeginEndIterator.getNext,33,52,113,101,89.38053097345133,0,0
@@ edu.stanford.nlp.objectbank.XMLBeginEndIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.objectbank.XMLBeginEndIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.objectbank.XMLBeginEndIterator.main,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.objectbank.DelimitRegExIterator.<init>,12,15,28,21,75.0,0,0
@@ edu.stanford.nlp.objectbank.DelimitRegExIterator.setNext,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.objectbank.DelimitRegExIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.objectbank.DelimitRegExIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank$OBIterator.setNextObject,6,7,11,11,100.0,0,1
@@ edu.stanford.nlp.objectbank.ObjectBank$OBIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.objectbank.ObjectBank$OBIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.objectbank.LineIterator.setNext,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.objectbank.LineIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.objectbank.LineIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.examples.TokensRegexExample.main,9,11,10,4,40.0,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.init,7,8,21,15,71.42857142857143,0,1
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.getIterator,20,26,42,22,52.38095238095239,0,1
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswers,7,9,21,10,47.61904761904761,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswers,19,28,47,47,100.0,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersTokenizedText,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersAsIsText,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersTokenizedTextTsv,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersAsIsTextTsv,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersAsIsTextTabbed,19,26,53,26,49.056603773584904,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersTokenizedTextTabbed,19,26,49,22,44.89795918367347,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersXML,5,5,3,2,66.66666666666666,0,1
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersTokenizedXML,5,5,3,2,66.66666666666666,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersInlineXML,18,25,66,42,63.63636363636363,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter.printAnswersTokenizedInlineXML,22,31,70,38,54.285714285714285,0,0
@@ edu.stanford.nlp.sequences.LibSVMReaderAndWriter.printAnswers,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter.init,8,9,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter.init,10,12,22,20,90.9090909090909,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter.getIterator,5,5,7,5,71.42857142857143,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter.getDocIterator,5,5,7,5,71.42857142857143,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter.getDocIterator,5,5,8,6,75.0,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter.join,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter.printAnswers,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sequences.ColumnDocumentReaderAndWriter$ColumnDocParser.apply,13,17,23,21,91.30434782608695,0,0
@@ edu.stanford.nlp.sequences.SeqClassifierFlags.setProperties,1319,1987,2662,2622,98.49737039819685,0,23
@@ edu.stanford.nlp.sequences.SeqClassifierFlags.getFeatureFactory,14,19,19,13,68.42105263157895,0,0
@@ edu.stanford.nlp.sequences.SeqClassifierFlags.getNotNullTrueStringRep,36,52,114,114,100.0,0,1
@@ edu.stanford.nlp.sequences.MalletReaderAndWriter.printAnswers,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sequences.Clique$CliqueEqualityWrapper.equals,11,14,33,26,78.78787878787878,0,1
@@ edu.stanford.nlp.sequences.Clique$CliqueEqualityWrapper.hashCode,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceModel.scoresOf,10,12,46,38,82.6086956521739,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceModel.scoreOf,7,8,28,21,75.0,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceModel.length,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceModel.leftWindow,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceModel.rightWindow,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceModel.getPossibleValues,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceModel.<init>,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.sequences.ExactBestSequenceFinder.bestSequence,23,31,110,73,66.36363636363637,0,0
@@ edu.stanford.nlp.sequences.ExactBestSequenceFinder.initProductSizes,10,12,39,24,61.53846153846154,0,0
@@ edu.stanford.nlp.sequences.ExactBestSequenceFinder.computeWindowScore,19,25,84,43,51.19047619047619,0,0
@@ edu.stanford.nlp.sequences.ExactBestSequenceFinder.forwardViterbiInitial,10,12,31,23,74.19354838709677,0,0
@@ edu.stanford.nlp.sequences.ExactBestSequenceFinder.forwardViterbi,20,26,72,41,56.94444444444444,0,0
@@ edu.stanford.nlp.sequences.SequenceSampler.bestSequence,8,9,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.sequences.ViterbiSearchGraphBuilder.getGraph,53,72,297,140,47.13804713804714,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceListener.updateSequenceElement,7,8,15,15,100.0,0,0
@@ edu.stanford.nlp.sequences.FactoredSequenceListener.setInitialSequence,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.sequences.FeatureFactory.eachClique,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.sequences.FeatureFactory.getCliques,8,10,11,11,100.0,0,1
@@ edu.stanford.nlp.sequences.FeatureFactory.addAllInterningAndSuffixing,13,17,16,13,81.25,0,0
@@ edu.stanford.nlp.sequences.FeatureFactory.getWord,4,4,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.sequences.LibSVMReaderAndWriter$ColumnDocParser.apply,13,16,28,24,85.71428571428571,0,0
@@ edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter.main,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter.printAnswers,19,27,40,37,92.5,0,0
@@ edu.stanford.nlp.sequences.TrueCasingForNISTDocumentReaderAndWriter$LineToTrueCasesParser.apply,17,23,30,25,83.33333333333334,0,0
@@ edu.stanford.nlp.sequences.ObjectBankWrapper$WrappedIterator.hasNext,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.sequences.MUCDocumentReaderAndWriter$MUCDocumentParser.apply,33,46,150,41,27.333333333333332,0,1
@@ edu.stanford.nlp.sequences.KBestSequenceFinder.kBestSequences,83,115,448,233,52.00892857142857,0,1
@@ edu.stanford.nlp.sequences.CoNLLDocumentReaderAndWriter.splitIntoDocs,10,13,15,15,100.0,0,1
@@ edu.stanford.nlp.sequences.CoNLLDocumentReaderAndWriter.processDocument,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.sequences.CoNLLDocumentReaderAndWriter.makeCoreLabel,12,17,30,30,100.0,0,0
@@ edu.stanford.nlp.sequences.CoNLLDocumentReaderAndWriter.deEndify,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.sequences.CoNLLDocumentReaderAndWriter.printAnswers,10,12,14,14,100.0,0,1
@@ edu.stanford.nlp.sequences.CoNLLDocumentReaderAndWriter.maybeIncrementCounter,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.sequences.CoNLLDocumentReaderAndWriter.main,23,31,84,19,22.61904761904762,0,1
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler$1.process,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.sequences.BeamBestSequenceFinder.bestSequence,34,46,100,52,52.0,0,0
@@ edu.stanford.nlp.sequences.IOBUtils.entitySubclassify,100,166,272,70,25.735294117647058,0,1
@@ edu.stanford.nlp.sequences.IOBUtils.isEntityBoundary,12,19,18,18,100.0,0,0
@@ edu.stanford.nlp.sequences.IOBUtils.isSameEntityBoundary,12,19,18,18,100.0,0,0
@@ edu.stanford.nlp.sequences.IOBUtils.isDifferentEntityBoundary,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.sequences.IOBUtils.countEntityResults,61,90,222,68,30.630630630630627,0,1
@@ edu.stanford.nlp.sequences.IOBUtils.main,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter$BufferedReaderIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter$BufferedReaderIterator.next,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.sequences.MUCDocumentReaderAndWriter.printAnswers,24,36,64,31,48.4375,0,0
@@ edu.stanford.nlp.sequences.BeamBestSequenceFinder$TagSeq.tmpTags,9,12,22,11,50.0,0,0
@@ edu.stanford.nlp.sequences.BeamBestSequenceFinder$TagSeq.tags,5,5,13,6,46.15384615384615,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter$ColumnDocBufferedGetNext.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter$ColumnDocBufferedGetNext.createDoc,20,27,34,33,97.05882352941177,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter$ColumnDocBufferedGetNext.markBoundary,8,11,17,17,100.0,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter$ColumnDocBufferedGetNext.getNext,46,70,191,109,57.06806282722513,0,0
@@ edu.stanford.nlp.sequences.Clique.intern,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.sequences.Clique.valueOf,5,5,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.sequences.Clique.valueOf,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.sequences.Clique.checkSorted,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.sequences.Clique.indexOfRelativeIndex,7,8,22,13,59.09090909090909,0,0
@@ edu.stanford.nlp.sequences.Clique.toString,7,8,25,16,64.0,0,0
@@ edu.stanford.nlp.sequences.Clique.shift,7,8,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.sequences.Clique.hashCode,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.sequences.ColumnTabDocumentReaderWriter$ColumnDocBufferedGetNextTokens.getNext,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sequences.ObjectBankWrapper.processDocument,6,7,18,18,100.0,0,0
@@ edu.stanford.nlp.sequences.ObjectBankWrapper.intern,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.sequences.ObjectBankWrapper.fix,8,11,25,25,100.0,0,0
@@ edu.stanford.nlp.sequences.ObjectBankWrapper.doBasicStuff,17,24,57,44,77.19298245614034,0,0
@@ edu.stanford.nlp.sequences.ObjectBankWrapper.fixDocLengths,22,32,56,34,60.71428571428571,0,0
@@ edu.stanford.nlp.sequences.ObjectBankWrapper.iobTags,16,21,39,19,48.717948717948715,0,1
@@ edu.stanford.nlp.sequences.ObjectBankWrapper.mergeTags,10,13,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.sequences.ColumnDocumentReaderAndWriter.printAnswers,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sequences.MalletReaderAndWriter$MalletDocParser.apply,12,15,23,23,100.0,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter$OutputStyle.fromShortName,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.sequences.PlainTextDocumentReaderAndWriter$OutputStyle.defaultToPreserveSpacing,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.getRandomSequence,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.findBestUsingSampling,7,8,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.findBestUsingAnnealing,34,48,114,68,59.64912280701754,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.collectSamples,13,17,34,29,85.29411764705883,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.sampleSequenceRepeatedly,5,5,13,7,53.84615384615385,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.sampleSequenceForward,39,52,90,77,85.55555555555556,0,1
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.sampleSequenceBackward,5,5,12,6,50.0,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.samplePositionHelper,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.printSamples,10,12,25,17,68.0,0,0
@@ edu.stanford.nlp.sequences.SequenceGibbsSampler.<init>,9,12,18,18,100.0,0,0
@@ edu.stanford.nlp.dcoref.ScorerMUC.calculateRecall,18,24,64,45,70.3125,0,0
@@ edu.stanford.nlp.dcoref.ScorerMUC.calculatePrecision,16,21,46,33,71.73913043478261,0,1
@@ edu.stanford.nlp.dcoref.SpeakerInfo.<init>,7,9,25,24,96.0,0,0
@@ edu.stanford.nlp.dcoref.SpeakerInfo.hasRealSpeakerName,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.dcoref.SpeakerInfo.addMention,10,14,29,29,100.0,0,0
@@ edu.stanford.nlp.dcoref.SpeakerInfo.getCorefClusterId,7,8,8,7,87.5,0,0
@@ edu.stanford.nlp.dcoref.CoNLLMentionExtractor.nextDoc,20,26,43,37,86.04651162790698,0,0
@@ edu.stanford.nlp.dcoref.CoNLLMentionExtractor.makeCopy,8,9,4,4,100.0,0,1
@@ edu.stanford.nlp.dcoref.CoNLLMentionExtractor.recallErrors,11,13,28,19,67.85714285714286,0,0
@@ edu.stanford.nlp.dcoref.CoNLLMentionExtractor.extractSpans,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLLMentionExtractor.extractGoldMentions,21,27,52,32,61.53846153846154,0,0
@@ edu.stanford.nlp.dcoref.CorefChain.equals,17,25,47,47,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefChain.<init>,12,15,28,23,82.14285714285714,0,0
@@ edu.stanford.nlp.dcoref.CorefChain.<init>,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.dcoref.MUCMentionExtractor.nextDoc,87,126,236,172,72.88135593220339,0,1
@@ edu.stanford.nlp.dcoref.Mention.isPronominal,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.spanToString,9,11,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.dcoref.Mention.lowercaseNormalizedSpanString,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.dcoref.Mention.nerTokens,12,17,53,39,73.58490566037736,0,0
@@ edu.stanford.nlp.dcoref.Mention.nerName,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.process,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.process,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.dcoref.Mention.setSingleton,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getSingletonFeatures,9,12,32,28,87.5,0,0
@@ edu.stanford.nlp.dcoref.Mention.getMentionString,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getGender,22,34,88,67,76.13636363636364,0,1
@@ edu.stanford.nlp.dcoref.Mention.setDiscourse,26,46,17,17,100.0,0,1
@@ edu.stanford.nlp.dcoref.Mention.setPerson,27,40,103,103,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.setSemantics,6,7,16,15,93.75,0,0
@@ edu.stanford.nlp.dcoref.Mention.isListMemberOf,9,12,24,24,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.addListMember,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.dcoref.Mention.addBelongsToList,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.dcoref.Mention.isMemberOfSameList,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.isListLike,33,52,59,30,50.847457627118644,0,0
@@ edu.stanford.nlp.dcoref.Mention.setType,22,33,73,73,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.setGender,27,40,111,107,96.3963963963964,0,1
@@ edu.stanford.nlp.dcoref.Mention.setNumber,33,50,138,120,86.95652173913044,0,0
@@ edu.stanford.nlp.dcoref.Mention.setAnimacy,69,127,114,86,75.43859649122807,0,0
@@ edu.stanford.nlp.dcoref.Mention.knownSuffix,9,11,10,6,60.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.setHeadString,14,20,45,38,84.44444444444444,0,0
@@ edu.stanford.nlp.dcoref.Mention.setNERString,10,13,22,22,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.sameSentence,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.included,10,14,13,13,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.headsAgree,8,12,36,36,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.numbersAgree,12,16,30,30,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.gendersAgree,12,16,30,30,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.animaciesAgree,12,16,30,30,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.entityTypesAgree,57,98,106,106,100.0,0,1
@@ edu.stanford.nlp.dcoref.Mention.includedIn,12,16,28,28,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.attributesAgree,8,11,18,18,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.addApposition,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.dcoref.Mention.isApposition,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.addPredicateNominatives,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.dcoref.Mention.isPredicateNominatives,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.addRelativePronoun,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.dcoref.Mention.appearEarlierThan,27,37,88,88,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.longestNNPEndsWithHead,9,11,29,13,44.827586206896555,0,0
@@ edu.stanford.nlp.dcoref.Mention.lowestNPIncludesHead,18,24,42,19,45.23809523809524,0,1
@@ edu.stanford.nlp.dcoref.Mention.stringWithoutArticle,14,20,20,20,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.preprocessSearchTerm,38,55,359,11,3.064066852367688,0,1
@@ edu.stanford.nlp.dcoref.Mention.buildQueryText,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.removePhraseAfterHead,31,46,121,50,41.32231404958678,0,1
@@ edu.stanford.nlp.dcoref.Mention.removeParenthesis,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.isTheCommonNoun,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.findDependentVerb,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.insideIn,7,9,24,24,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.moreRepresentativeThan,54,85,196,196,100.0,0,1
@@ edu.stanford.nlp.dcoref.Mention.getPremodifiers,16,25,37,37,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getPostmodifiers,17,27,41,41,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getSplitPattern,10,12,22,22,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getPattern,8,9,7,7,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getPattern,20,30,57,47,82.45614035087719,0,0
@@ edu.stanford.nlp.dcoref.Mention.isCoordinated,9,11,9,9,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getContextHelper,13,17,37,16,43.24324324324324,0,0
@@ edu.stanford.nlp.dcoref.Mention.getPremodifierContext,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.isRelativePronoun,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.isRoleAppositive,26,42,74,74,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.isDemonym,12,17,32,21,65.625,0,0
@@ edu.stanford.nlp.dcoref.Mention.getPosition,15,22,44,44,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getRelation,37,62,105,105,100.0,0,1
@@ edu.stanford.nlp.dcoref.Mention.getModifiers,17,26,44,35,79.54545454545455,0,0
@@ edu.stanford.nlp.dcoref.Mention.getQuantification,19,26,36,36,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getNegation,18,25,42,42,100.0,0,0
@@ edu.stanford.nlp.dcoref.Mention.getModal,23,33,56,56,100.0,0,1
@@ edu.stanford.nlp.dcoref.Mention.getReportEmbedding,23,34,65,59,90.76923076923077,0,1
@@ edu.stanford.nlp.dcoref.Mention.getCoordination,14,18,14,14,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$CorpusStats.process,31,45,107,86,80.37383177570094,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$CorpusStats.appendIntCountStats,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.dcoref.SingletonPredictor.setTokenIndices,8,9,2,1,50.0,0,0
@@ edu.stanford.nlp.dcoref.SingletonPredictor.generateFeatureVectors,27,36,38,38,100.0,0,1
@@ edu.stanford.nlp.dcoref.SingletonPredictor.main,9,11,15,5,33.33333333333333,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.<init>,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.getFiles,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.reset,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.getNextDocument,10,13,49,35,71.42857142857143,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.getField,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.concatField,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.getMention,9,12,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.include,10,14,23,23,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.writeTabSep,31,43,84,68,80.95238095238095,0,1
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader.main,27,37,61,50,81.9672131147541,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.setPronouns,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.loadStateAbbreviation,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.loadDemonymLists,10,12,20,20,100.0,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.getDemonyms,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.getWordsFromFile,13,17,15,15,100.0,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.loadCountriesLists,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.loadCorefDict,8,9,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.loadCorefDictPMI,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.loadSignatures,8,9,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.dcoref.Dictionaries.signature,12,16,22,22,100.0,0,1
@@ edu.stanford.nlp.dcoref.Dictionaries.<init>,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefChain$MentionComparator.compare,14,19,48,48,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefChain$CorefMention.equals,28,40,95,95,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefChain$CorefMention.moreRepresentativeThan,31,45,124,124,100.0,0,1
@@ edu.stanford.nlp.dcoref.ScorerBCubed.calculatePrecision,6,8,18,18,100.0,0,0
@@ edu.stanford.nlp.dcoref.ScorerBCubed.calculateRecall,6,8,18,18,100.0,0,1
@@ edu.stanford.nlp.dcoref.ScorerBCubed.calculatePrecisionBall,13,18,47,35,74.46808510638297,0,0
@@ edu.stanford.nlp.dcoref.ScorerBCubed.calculateRecallBall,13,18,47,35,74.46808510638297,0,0
@@ edu.stanford.nlp.dcoref.ScorerBCubed.calculatePrecisionBcai,21,30,76,56,73.68421052631578,0,0
@@ edu.stanford.nlp.dcoref.ScorerBCubed.calculateRecallBcai,13,18,47,35,74.46808510638297,0,0
@@ edu.stanford.nlp.dcoref.ScorerBCubed.calculateRecallBconll,19,27,70,50,71.42857142857143,0,0
@@ edu.stanford.nlp.dcoref.SieveOptions.toString,60,88,146,146,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefCluster.<init>,17,24,51,33,64.70588235294117,0,0
@@ edu.stanford.nlp.dcoref.CorefCluster.mergeClusters,28,43,125,125,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefCluster.printCorefCluster,14,17,31,31,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefCluster.isSinglePronounCluster,10,13,14,14,100.0,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.getHeadIndex,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.dcoref.MentionExtractor.arrange,4,4,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.arrange,38,55,115,94,81.73913043478261,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.mergeLabels,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.inside,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.findTreePattern,9,11,21,15,71.42857142857143,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.markListMemberRelation,12,15,13,13,100.0,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.markMentionRelation,29,45,41,41,100.0,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.findExactMatch,10,13,15,15,100.0,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.loadStanfordProcessor,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.dcoref.MentionExtractor.initializeUtterance,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefScorer.getScore,6,8,12,12,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefScorer.getPrecision,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefScorer.getRecall,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefScorer.getF1,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.CorefScorer.printF1,10,12,32,32,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.filterPredictedMentions,10,12,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.extractPredictedMentions,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.assignMentionIDs,8,9,2,1,50.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.setBarePlural,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.extractPremarkedEntityMentions,12,16,26,17,65.38461538461539,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.extractNamedEntityMentions,16,23,62,31,50.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.extractNPorPRP,10,13,28,25,89.28571428571429,0,1
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.extractEnumerations,11,14,19,19,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.insideNE,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.findHead,11,14,27,27,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.findSyntacticHead,35,53,128,85,66.40625,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.findPartialSpan,10,13,18,18,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.funkyFindLeafWithApproximateSpan,16,22,31,31,100.0,0,1
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.getParser,12,16,27,13,48.148148148148145,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.convertToCoreLabels,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.safeHead,12,17,30,25,83.33333333333334,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.findTreeWithSpan,19,28,33,33,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.removeSpuriousMentions,46,71,138,138,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.inStopList,14,21,16,16,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.partitiveRule,7,9,22,22,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.isPleonastic,9,11,9,9,100.0,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.getPleonasticPatterns,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.checkPleonastic,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityBothHaveProper,16,21,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.dcoref.Rules.entitySameProperHeadLastWord,10,12,5,5,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityAlias,7,9,22,22,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityIWithinI,10,12,7,7,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityPersonDisagree,12,15,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityWordsIncluded,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityHaveIncompatibleModifier,10,12,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityIsRoleAppositive,8,10,16,16,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityIsRelativePronoun,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityIsAcronym,14,18,32,30,93.75,0,1
@@ edu.stanford.nlp.dcoref.Rules.isAcronym,54,77,122,75,61.47540983606557,0,1
@@ edu.stanford.nlp.dcoref.Rules.entityIsPredicateNominatives,13,19,44,44,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityIsApposition,13,18,28,28,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityAttributesAgree,76,120,182,150,82.41758241758241,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityRelaxedHeadsAgreeBetweenMentions,7,9,8,8,100.0,0,1
@@ edu.stanford.nlp.dcoref.Rules.entityHeadsAgree,12,17,28,26,92.85714285714286,0,1
@@ edu.stanford.nlp.dcoref.Rules.entityExactStringMatch,23,32,39,36,92.3076923076923,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityRelaxedExactStringMatch,19,30,50,50,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityIWithinI,11,18,36,36,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityHaveIncompatibleModifier,32,46,73,56,76.71232876712328,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityHaveDifferentLocation,38,55,79,71,89.87341772151899,0,0
@@ edu.stanford.nlp.dcoref.Rules.entitySameProperHeadLastWord,32,46,62,54,87.09677419354838,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityNumberInLaterMention,14,19,17,17,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityHaveExtraProperNoun,27,38,36,28,77.77777777777779,0,1
@@ edu.stanford.nlp.dcoref.Rules.antecedentIsMentionSpeaker,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.antecedentMatchesMentionSpeakerAnnotation,20,27,32,32,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.mentionMatchesSpeaker,19,27,43,43,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityPersonDisagree,53,89,190,190,100.0,0,1
@@ edu.stanford.nlp.dcoref.Rules.entitySameSpeaker,14,19,21,21,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.getSpeakerClusterId,12,18,32,19,59.375,0,0
@@ edu.stanford.nlp.dcoref.Rules.entitySubjectObject,17,28,56,56,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityTokenDistance,5,6,16,16,100.0,0,0
@@ edu.stanford.nlp.dcoref.Rules.entityClusterAllCorefDictionary,15,20,25,23,92.0,0,1
@@ edu.stanford.nlp.dcoref.Rules.entityCorefDictionary,17,24,48,38,79.16666666666666,0,0
@@ edu.stanford.nlp.dcoref.Rules.contextIncompatible,22,34,84,60,71.42857142857143,0,0
@@ edu.stanford.nlp.dcoref.Rules.sentenceContextIncompatible,30,46,92,74,80.43478260869566,0,0
@@ edu.stanford.nlp.dcoref.ScorerPairwise.calculateRecall,19,25,36,30,83.33333333333334,0,1
@@ edu.stanford.nlp.dcoref.ScorerPairwise.calculatePrecision,19,25,36,30,83.33333333333334,0,1
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.wordsToParse,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.getLabelledSpans,41,61,132,73,55.3030303030303,0,2
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.wordsToSentence,50,72,139,102,73.38129496402878,0,1
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.sentencesToDocument,11,13,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.getTreeNonTerminal,7,9,16,7,43.75,0,0
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.annotateDocument,22,31,60,55,91.66666666666666,0,1
@@ edu.stanford.nlp.dcoref.CoNLL2011DocumentReader$DocumentIterator.readNextDocument,30,45,84,47,55.952380952380956,0,0
@@ edu.stanford.nlp.dcoref.Document.<init>,9,11,8,8,100.0,0,0
@@ edu.stanford.nlp.dcoref.Document.processDiscourse,28,42,67,67,100.0,0,1
@@ edu.stanford.nlp.dcoref.Document.initialize,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.dcoref.Document.initializeCorefCluster,16,22,82,63,76.82926829268293,0,0
@@ edu.stanford.nlp.dcoref.Document.mergeIncompatibles,15,20,46,31,67.3913043478261,0,0
@@ edu.stanford.nlp.dcoref.Document.mergeAcronymCache,22,30,51,36,70.58823529411765,0,0
@@ edu.stanford.nlp.dcoref.Document.findTwinMentions,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.dcoref.Document.findTwinMentionsStrict,25,33,51,46,90.19607843137256,0,0
@@ edu.stanford.nlp.dcoref.Document.findTwinMentionsRelaxed,24,32,67,62,92.53731343283582,0,0
@@ edu.stanford.nlp.dcoref.Document.setParagraphAnnotation,19,24,19,10,52.63157894736842,0,0
@@ edu.stanford.nlp.dcoref.Document.findDocType,20,28,39,28,71.7948717948718,0,0
@@ edu.stanford.nlp.dcoref.Document.assignOriginalID,19,25,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.dcoref.Document.extractGoldCorefClusters,12,15,15,13,86.66666666666667,0,0
@@ edu.stanford.nlp.dcoref.Document.getGoldLinks,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.dcoref.Document.extractGoldLinks,51,75,178,98,55.0561797752809,0,1
@@ edu.stanford.nlp.dcoref.Document.markQuotations,30,46,56,31,55.35714285714286,0,1
@@ edu.stanford.nlp.dcoref.Document.findSpeakers,25,33,37,37,100.0,0,0
@@ edu.stanford.nlp.dcoref.Document.findSpeakersInArticle,14,19,55,23,41.81818181818181,0,1
@@ edu.stanford.nlp.dcoref.Document.findQuotationSpeaker,14,21,52,52,100.0,0,0
@@ edu.stanford.nlp.dcoref.Document.findSpeaker,19,25,51,39,76.47058823529412,0,1
@@ edu.stanford.nlp.dcoref.Document.findSpeakersInConversation,20,26,45,28,62.22222222222222,0,0
@@ edu.stanford.nlp.dcoref.Document.findParagraphSpeaker,16,23,58,41,70.6896551724138,0,0
@@ edu.stanford.nlp.dcoref.Document.findNextParagraphSpeaker,14,20,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.dcoref.Document.isSpeaker,22,32,69,59,85.5072463768116,0,0
@@ edu.stanford.nlp.dcoref.Document.printMentionDetection,7,8,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.<init>,43,62,102,84,82.35294117647058,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.initScorers,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.sieveClassName,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.initializeAndRunCoref,27,38,90,63,70.0,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.runAndScoreCoref,29,43,107,80,74.76635514018692,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.runAndScoreCorefDist,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.waitForFiles,8,10,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.fromSieveNameToIndex,9,11,21,12,57.14285714285714,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.fromSieveOrderConstraintString,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.toSieveOrderConstraintString,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.optimizeSieveOrdering,57,81,173,136,78.61271676300578,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.coref,11,14,28,24,85.71428571428571,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.corefReturnHybridOutput,16,21,43,34,79.06976744186046,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.coreference,63,94,277,192,69.31407942238266,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.postProcessing,23,33,42,42,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.getSingletonPredictorFromSerializedFile,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.filterMentionsWithSingletonClusters,11,14,11,11,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.getConllEvalSummary,7,8,16,9,56.25,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printTopK,71,104,255,149,58.43137254901961,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printLink,5,5,20,20,100.0,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printList,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printLinkWithContext,40,53,180,98,54.44444444444444,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printLogs,25,36,94,55,58.51063829787234,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printDiscourseStructure,10,12,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printScoreSummary,18,24,20,20,100.0,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printFinalConllScore,5,5,8,7,87.5,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.getFinalConllScore,15,20,48,25,52.083333333333336,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.getFinalScore,19,32,27,21,77.77777777777779,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printConllOutput,7,8,17,12,70.58823529411765,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printConllOutput,46,61,105,83,79.04761904761905,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printRawDoc,47,65,113,85,75.22123893805309,0,1
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.getLinks,13,16,13,13,100.0,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.debugPrintMentions,8,9,29,15,51.724137931034484,0,0
@@ edu.stanford.nlp.dcoref.SieveCoreferenceSystem.checkClusters,12,15,17,14,82.35294117647058,0,0
@@ edu.stanford.nlp.dcoref.CorefChain$CorefMentionComparator.compare,14,19,48,48,100.0,0,0
@@ edu.stanford.nlp.dcoref.ACEMentionExtractor$EntityComparator.compare,10,13,16,16,100.0,0,1
@@ edu.stanford.nlp.dcoref.ACEMentionExtractor.<init>,8,10,35,20,57.14285714285714,0,0
@@ edu.stanford.nlp.dcoref.ACEMentionExtractor.nextDoc,18,24,69,41,59.42028985507246,0,0
@@ edu.stanford.nlp.dcoref.ACEMentionExtractor.extractGoldMentions,23,31,72,55,76.38888888888889,0,0
@@ edu.stanford.nlp.dcoref.ACEMentionExtractor.printRawDoc,40,54,140,61,43.57142857142857,0,0
@@ edu.stanford.nlp.dcoref.sievepasses.DeterministicCorefSieve.skipThisMention,25,40,89,77,86.51685393258427,0,1
@@ edu.stanford.nlp.dcoref.sievepasses.DeterministicCorefSieve.coreferent,255,418,1158,1081,93.35060449050087,0,2
@@ edu.stanford.nlp.dcoref.sievepasses.DeterministicCorefSieve.getOrderedAntecedents,9,12,36,32,88.88888888888889,0,0
@@ edu.stanford.nlp.dcoref.sievepasses.DeterministicCorefSieve.sortMentionsForPronoun,22,31,66,49,74.24242424242425,0,0
@@ edu.stanford.nlp.dcoref.sievepasses.NameMatch.isNamedMention,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.dcoref.sievepasses.NameMatch.checkEntityMatch,13,21,66,65,98.48484848484848,0,1
@@ edu.stanford.nlp.dcoref.util.ConvertGenderFile.main,27,39,97,47,48.45360824742268,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils$PositionedTree.equals,9,12,27,27,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.parse,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.readDep,16,22,42,42,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.makeVertex,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.readWordAndIndex,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.getNextFreeIndex,5,5,12,6,50.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.readLeftBracket,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.readRightBracket,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.readRelnSeparator,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.isLeftBracket,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.isRightBracket,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.isRelnSeparator,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph$SemanticGraphParsingTask.isPunct,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.makeGraphFromNodes,17,22,16,16,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.findMatchingNode,9,12,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.getSubTreeEdgesHelper,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.getEdgesSpannedByVertices,11,14,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.getChildrenWithRelnPrefix,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.getChildrenWithRelnPrefix,14,18,18,18,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.getChildrenWithPrepC,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.edgesWithReln,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.findAllRelnsWithPrefix,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.tabuDescendants,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.tabuDescendants,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.descendantsTabuRelns,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.descendantsTabuTestAndRelns,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.descendantsTabuTestAndRelns,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.descendantsTabuTestAndRelns,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.tabuDescendantsHelper,18,25,31,31,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.tabuDescendantsHelper,18,25,33,33,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.leftMostChildVertice,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.leftRightMostChildVertices,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.getDependencyBlanket,13,18,24,24,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.resetVerticeOrdering,14,17,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.enRepairEdges,10,13,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.killNonRooted,10,12,9,9,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.replaceNode,13,16,15,15,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.anonymyizeNodes,5,5,5,4,80.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.makeReplacedEdges,14,19,24,19,79.16666666666666,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.allEdgesInSet,11,13,6,6,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.diffEdges,18,23,37,37,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.printEdges,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.printVertices,15,20,35,34,97.14285714285714,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.semgrexFromGraphHelper,31,45,78,76,97.43589743589743,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.setSentIndex,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.removeDuplicates,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.removeDuplicates,10,12,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.mapTreeToSg,38,52,69,53,76.81159420289855,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.isTree,17,22,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils.lambda$semgrexFromGraph$0,10,13,25,6,24.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphEdge.toString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphEdge.compareTo,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphEdge.equals,13,18,23,23,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphEdge.hashCode,11,13,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphEdge$SemanticGraphEdgeTargetComparator.compare,6,7,10,10,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.getEdge,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.edgeListSorted,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.isAncestor,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.commonAncestor,33,46,50,50,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getCommonAncestor,28,38,51,51,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.matchPatternToVertex,43,60,61,41,67.21311475409836,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.matchPatternToVertex,31,43,40,28,70.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getChildList,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getChildren,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.getParentList,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getParents,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getSiblings,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getPathToRoot,12,16,24,24,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getPathToRoot,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getParent,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getNodeByIndex,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getNodeByIndexSafe,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getNodeByIndexAndCopyCount,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getNodeByIndexAndCopyCountSafe,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getNodeByWordPattern,10,14,11,11,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getAllNodesByWordPattern,10,14,13,13,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.getAllNodesByPartOfSpeechPattern,10,14,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.descendants,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.descendantsHelper,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.childPairs,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.parentPairs,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.relns,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.reln,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.childRelns,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getVerticesWithoutParents,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getFirstRoot,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.resetRoots,18,23,22,22,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.hasChild,10,13,16,16,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.hasChildWithReln,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.hasParentWithReln,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getChildWithReln,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getParentsWithReln,11,14,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getParentsWithReln,11,14,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getChildrenWithReln,11,14,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getChildrenWithRelns,11,14,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getEdge,10,13,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.isNegatedVertex,10,13,22,22,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.isNegatedVerb,8,10,12,12,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.isInConditionalContext,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.attachedNegatedVerb,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.isAuxiliaryVerb,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getLeafVertices,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.getSubgraphVertices,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.isDag,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.isDag,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.isDagHelper,11,14,19,19,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toString,10,12,21,21,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.recToString,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.space,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toRecoveredSentenceString,7,8,8,4,50.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.toRecoveredSentenceStringWithIndexMarking,7,8,10,5,50.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toEnUncollapsedSentenceString,16,21,19,13,68.42105263157895,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.insertSpecificIntoList,6,7,18,9,50.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toString,7,10,15,15,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.toList,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toPOSList,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toReadableString,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toXMLString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toCompactString,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toCompactStringHelper,18,24,34,34,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.toDotFormat,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.<init>,13,16,18,12,66.66666666666666,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.<init>,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.makeSoftCopy,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.equals,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.findAllRelns,8,10,9,9,100.0,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraph.findAllRelns,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.typedDependencies,12,15,17,12,70.58823529411765,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.yieldSpan,10,12,16,10,62.5,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraph.yield,10,12,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFormatter.formatSemanticGraph,11,14,20,18,90.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFormatter.formatSGNode,9,11,21,21,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFormatter.formatSGNodeOnelineHelper,18,24,39,39,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFormatter.formatSGNodeMultiline,13,17,40,36,90.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFormatter.formatLabel,10,14,31,22,70.96774193548387,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils$TreeNodeProxy.create,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphPrinter.main,22,30,40,36,90.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphUtils$IndexedWordProxy.create,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromTree,11,13,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromTree,17,25,46,33,71.73913043478261,0,1
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromTree,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromTree,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromTree,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromEdges,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.getVerticesFromEdgeSet,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromVertices,25,35,33,33,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.duplicateKeepNodes,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.makeFromGraphs,11,13,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.SemanticGraphFactory.deepCopyFromGraphs,17,22,37,25,67.56756756756756,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$RIGHT_SIBLING.satisfiesOrder,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.toString,8,9,10,10,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.getPattern,7,9,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.getName,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.isKnownRelation,15,25,22,22,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.getRelation,42,77,29,29,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.getRelation,11,15,19,19,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.getRelation,11,15,21,21,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation.equals,9,12,23,23,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexPattern.negate,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexPattern.makeOptional,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexPattern.prettyPrint,8,9,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexPattern.equals,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexPattern.main,50,73,82,73,89.02439024390245,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$EQUALS$1.advance,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDPARENT$1.initialize,15,19,54,42,77.77777777777779,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDPARENT$1.advance,23,33,104,69,66.34615384615384,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern.<init>,33,48,106,62,58.490566037735846,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern.nodeAttrMatch,37,51,76,58,76.31578947368422,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern.toString,20,30,51,51,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern.getChildren,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern.matcher,8,9,22,22,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.fullExpression,7,8,26,6,23.076923076923077,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.Root,23,31,49,45,91.83673469387756,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.SubNode,27,37,57,45,78.94736842105263,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.RelationDisj,13,17,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.RelationConj,19,25,30,28,93.33333333333333,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.ModRelation,12,16,22,19,86.36363636363636,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.RelChild,11,14,17,15,88.23529411764706,0,1
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.Relation,79,108,166,92,55.42168674698795,0,1
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.NodeDisj,13,17,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.NodeConj,19,25,31,29,93.54838709677419,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.ModNode,11,14,20,18,90.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.Child,11,14,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.AddAttribute,19,27,48,40,83.33333333333334,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.Description,30,40,71,59,83.09859154929578,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.<init>,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.ReInit,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.<init>,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.ReInit,10,12,29,20,68.96551724137932,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.<init>,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.ReInit,5,5,8,4,50.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.jj_consume_token,7,8,30,24,80.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.getNextToken,5,5,16,14,87.5,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.getToken,8,9,34,6,17.647058823529413,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.jj_ntk_f,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParser.generateParseException,21,28,77,41,53.246753246753244,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$DEPENDENT.satisfies,11,15,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$SIBLING_RELATION.satisfies,6,8,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexMatcher.setupFindIterator,13,18,42,40,95.23809523809523,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexMatcher.find,12,17,23,23,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexMatcher.findNextMatchingNode,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.TokenMgrError.addEscapes,18,28,59,31,52.54237288135594,0,0
@@ edu.stanford.nlp.semgraph.semgrex.TokenMgrError.LexicalErr,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.resetChildIter,9,11,24,24,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.resetChild,12,15,34,34,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.goToNextNodeMatch,50,74,149,134,89.93288590604027,0,1
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.commitVariableGroups,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.decommitVariableGroups,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.decommitNamedNodes,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.decommitNamedRelations,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.matchChild,12,16,23,23,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodePattern$NodeMatcher.matches,14,19,27,27,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.Alignment.toString,18,23,32,32,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.Alignment.iwToString,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.Alignment.equals,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.Alignment.patchedAlignment,9,11,25,25,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.Alignment.makeFromIndexArray,17,24,47,35,74.46808510638297,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$ADJACENT_NODE$1.advance,10,13,31,25,80.64516129032258,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDPARENT.satisfies,12,16,33,29,87.87878787878788,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDPARENT.satisfyHelper,18,26,49,49,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$ADJACENT_NODE.satisfies,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.jjMoveStringLiteralDfa0_0,21,38,57,57,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.jjMoveNfa_0,123,206,1123,234,20.837043633125557,0,2
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.jjFillToken,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.jjCanMove_0,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.getNextToken,17,23,62,49,79.03225806451613,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.jjCheckNAdd,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.ReInitRounds,5,5,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexParserTokenManager.SwitchTo,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.Env.bind,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.Env.lookupAnnotationKey,8,11,14,14,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$GRANDSOMETHING.satisfies,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$GRANDSOMETHING.satisfyHelper,14,19,27,27,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$DEPENDENT$1.advance,11,14,46,33,71.73913043478261,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$SIBLING_RELATION$1.advance,13,17,39,33,84.61538461538461,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$SearchNodeIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$SearchNodeIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexBatchParser.parse,10,13,15,15,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexBatchParser.replaceMacros,14,19,47,32,68.08510638297872,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexBatchParser.preprocess,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SemgrexBatchParser.extractMacro,11,15,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDKID.satisfies,12,16,33,29,87.87878787878788,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDKID.satisfyHelper,18,26,49,49,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$ALIGNMENT$1.advance,18,24,45,41,91.11111111111111,0,0
@@ edu.stanford.nlp.semgraph.semgrex.NodeAttributes.setAttribute,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$GRANDSOMETHING$1.initialize,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$GRANDSOMETHING$1.advance,15,22,66,52,78.78787878787878,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$EQUALS.satisfies,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern.<init>,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern.setChild,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern.localString,12,15,16,16,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern.toString,13,16,23,23,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$GOVERNER$1.advance,10,13,34,28,82.35294117647058,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.ExpandBuff,5,5,24,24,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.FillBuff,16,22,78,56,71.7948717948718,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.UpdateLineColumn,12,17,38,28,73.68421052631578,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.readChar,8,10,30,29,96.66666666666667,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.backup,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.ReInit,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.ReInit,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.GetImage,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.GetSuffix,5,5,18,18,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.SimpleCharStream.adjustBeginLineColumn,15,20,101,63,62.37623762376238,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$RIGHT_IMMEDIATE_SIBLING.satisfiesOrder,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$GOVERNER.satisfies,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LEFT_IMMEDIATE_SIBLING.satisfiesOrder,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.VariableStrings.isSet,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.VariableStrings.setVar,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.VariableStrings.unsetVar,6,7,18,18,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$ALIGNMENT.satisfies,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ParseException.initialise,25,33,109,46,42.201834862385326,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ParseException.add_escapes,18,28,59,31,52.54237288135594,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LEFT_SIBLING.satisfiesOrder,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$1.satisfies,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.ProcessSemgrexRequest.matchSentence,11,13,11,11,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ProcessSemgrexRequest.processRequest,8,9,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$3.satisfies,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDKID$1.initialize,15,19,54,42,77.77777777777779,0,1
@@ edu.stanford.nlp.semgraph.semgrex.GraphRelation$LIMITED_GRANDKID$1.advance,23,33,104,69,66.34615384615384,0,1
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern$CoordinationMatcher.<init>,5,5,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern$CoordinationMatcher.resetChildIter,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern$CoordinationMatcher.resetChildIter,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern$CoordinationMatcher.matches,26,38,111,85,76.57657657657657,0,1
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern$CoordinationMatcher.getMatch,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.CoordinationPattern$CoordinationMatcher.toString,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.demo.SemgrexDemo.main,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SetRoots.evaluate,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SetRoots.toEditString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon$ArgsBox.init,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon$ArgsBox.toString,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.DeleteGraphFromNode.crawl,12,15,16,16,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.DeleteGraphFromNode.evaluate,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SsurgeonPattern.toString,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SsurgeonPattern.execute,16,21,28,28,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SsurgeonPattern.execute,11,14,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SsurgeonPattern.main,14,18,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SsurgeonEdit.getNamedNode,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.AddEdge.evaluate,8,10,20,20,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SsurgeonWordlist.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.SsurgeonWordlist.<init>,7,8,16,11,68.75,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.CollapseSubtree.evaluate,19,25,29,29,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.CollapseSubtree.lambda$evaluate$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.RemoveEdge.evaluate,24,36,49,49,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.AddDep.fromCheapString,7,8,8,7,87.5,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.AddDep.nullShield,5,5,3,3,100.0,0,1
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.KillNonRootedNodes.evaluate,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.RemoveNamedEdge.evaluate,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.KillAllIncomingEdges.evaluate,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.inst,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.expandFromPatterns,17,23,29,28,96.55172413793103,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.exhaustFromPatterns,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.exhaustFromPatterns,21,29,33,32,96.96969696969697,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.parseArgs,11,14,15,15,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.parseEditLine,53,87,123,52,42.27642276422765,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.writeToFile,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.writeToString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.createPatternXMLDoc,10,12,19,16,84.21052631578947,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.readFromFile,12,15,32,22,68.75,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.readFromDirectory,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.ssurgeonPatternFromXML,9,11,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.assemblePredFromXML,21,33,16,16,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.testRead,16,20,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.getTagText,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.getEltText,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.getFirstTag,9,11,16,11,68.75,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.getFirstChildElement,7,8,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.getChildElements,7,8,16,11,68.75,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.Ssurgeon.main,15,20,59,25,42.3728813559322,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.pred.WordlistTest.evaluate,18,25,51,51,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.pred.SsurgAndPred.test,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.pred.SsurgAndPred.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.pred.SsurgTestManager.inst,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.pred.SsurgOrPred.test,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.semgraph.semgrex.ssurgeon.pred.SsurgOrPred.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.ClassifierCombiner.<init>,14,19,45,36,80.0,0,0
@@ edu.stanford.nlp.ie.ClassifierCombiner.<init>,8,9,21,15,71.42857142857143,0,1
@@ edu.stanford.nlp.ie.ClassifierCombiner.extractCombinationMode,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.ClassifierCombiner.loadClassifiers,11,14,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.ClassifierCombiner.labels,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.ClassifierCombiner.mergeDocuments,36,50,90,69,76.66666666666667,0,1
@@ edu.stanford.nlp.ie.ClassifierCombiner.mergeTwoDocuments,36,51,112,22,19.642857142857142,0,0
@@ edu.stanford.nlp.ie.ClassifierCombiner.classify,13,17,44,36,81.81818181818183,0,1
@@ edu.stanford.nlp.ie.ClassifierCombiner.serializeClassifier,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.ie.ClassifierCombiner.examineCRF,28,41,103,71,68.93203883495146,0,0
@@ edu.stanford.nlp.ie.ClassifierCombiner.showCCInfo,10,12,33,25,75.75757575757575,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.getOneSubstitutionMatch,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.isOneSubstitutionMatch,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.singleEntityToString,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.collapseNERLabels,21,29,59,20,33.89830508474576,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizedDateString,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizedDurationString,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.isYear,11,16,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.detectDateRangeModifier,33,49,67,62,92.53731343283582,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.detectDateRangeModifier,7,9,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.detectTwoSidedRangeModifier,34,50,72,62,86.11111111111111,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.concatenateNumericString,16,22,30,17,56.666666666666664,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizedTimeString,50,73,61,61,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.convertToAmerican,9,12,30,10,33.33333333333333,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizedMoneyString,13,18,28,17,60.71428571428571,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizedNumberStringQuiet,55,82,172,79,45.93023255813954,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizedOrdinalStringQuiet,11,15,24,23,95.83333333333334,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizedPercentString,7,9,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.fetchNumberFromSUTime,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.fetchTimexFromSUTime,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.processEntity,58,95,116,57,49.137931034482754,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.timeEntityToString,11,15,15,15,100.0,0,1
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.normalizeClassifierOutput,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.detectQuantityModifier,48,67,65,65,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.detectTimeOfDayModifier,56,84,86,86,100.0,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.isCompatible,22,34,35,35,100.0,0,1
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.addNormalizedQuantitiesToEntities,54,83,191,53,27.748691099476442,0,1
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.fixupNerBeforeNormalization,49,81,130,82,63.07692307692307,0,0
@@ edu.stanford.nlp.ie.QuantifiableEntityNormalizer.applySpecializedNER,13,18,39,30,76.92307692307693,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.predict,16,23,37,37,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.precision,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.precisionMicro,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.precisionMacro,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.recall,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.recallMicro,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.recallMacro,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy.dumpPerRelationStats,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.EmpiricalNERPriorBIO.scoreOf,47,70,188,123,65.42553191489363,0,0
@@ edu.stanford.nlp.ie.NERGUI.getFile,9,12,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.ie.NERGUI.saveUntaggedContents,5,5,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.ie.NERGUI.checkFile,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI.loadClassifier,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI.loadDefaultClassifier,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI.openFile,5,5,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI.redraw,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI.removeTags,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI.extract,27,36,83,50,60.24096385542169,0,0
@@ edu.stanford.nlp.ie.NERGUI.colorToHTML,20,28,35,27,77.14285714285715,0,0
@@ edu.stanford.nlp.ie.NERGUI.buildExtractButton,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI.buildTagPanel,11,14,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.ie.NERGUI.makeTagToColorMap,9,11,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.ie.NERGUI.getNColors,15,19,43,25,58.139534883720934,0,1
@@ edu.stanford.nlp.ie.NERClassifierCombiner.<init>,5,5,10,10,100.0,0,1
@@ edu.stanford.nlp.ie.NERClassifierCombiner.<init>,8,9,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.ie.NERClassifierCombiner.createNERClassifierCombiner,16,21,36,32,88.88888888888889,0,0
@@ edu.stanford.nlp.ie.NERClassifierCombiner.usesSUTime,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.NERClassifierCombiner.copyAnswerFieldsToNERField,8,9,4,4,100.0,0,1
@@ edu.stanford.nlp.ie.NERClassifierCombiner.classifyWithGlobalInformation,8,9,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.NERClassifierCombiner.recognizeNumberSequences,10,14,40,35,87.5,0,0
@@ edu.stanford.nlp.ie.NERClassifierCombiner.readRegexnerGazette,9,11,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.NERClassifierCombiner.main,25,35,61,43,70.49180327868852,0,0
@@ edu.stanford.nlp.ie.EmpiricalNERPrior.scoreOf,122,188,1386,148,10.678210678210679,0,1
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.spanBetweenMentions,13,17,46,20,43.47826086956522,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.withMentionsPositioned,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.denseFeatures,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.surfaceFeatures,73,106,188,129,68.61702127659575,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.dependencyFeatures,46,66,123,77,62.601626016260155,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.relationSpecificFeatures,60,87,150,117,78.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.features,6,8,17,17,100.0,0,1
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.initFactory,8,11,20,16,80.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.trainMultinomialClassifier,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.classify,8,11,28,14,50.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.main,7,8,16,14,87.5,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.$deserializeLambda$,40,75,51,51,100.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.lambda$main$2,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.lambda$main$1,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.KBPStatisticalExtractor.lambda$surfaceFeatures$0,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.NERServer$NERClient.communicateWithNERServer,14,19,25,23,92.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.<init>,8,9,16,12,75.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.scoresOf,7,8,31,18,58.06451612903226,0,1
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.setInitialSequence,8,10,31,17,54.83870967741935,0,1
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.addEntityToEntitiesArray,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.extractEntity,7,9,25,20,80.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.otherOccurrences,9,11,30,16,53.333333333333336,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.toArray,5,5,11,7,63.63636363636363,0,1
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.matches,11,14,41,30,73.17073170731707,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.updateSequenceElement,72,104,303,267,88.11881188118812,0,1
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.toString,7,8,33,22,66.66666666666666,0,1
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.toString,7,8,35,24,68.57142857142857,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory$FeatureCollector.setSuffix,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory$FeatureCollector.build,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory$FeatureCollector.add,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$NERTag.fromString,14,18,17,17,100.0,0,0
@@ edu.stanford.nlp.ie.KBPTokensregexExtractor.<init>,11,14,20,20,100.0,0,0
@@ edu.stanford.nlp.ie.KBPTokensregexExtractor.classify,27,38,59,59,100.0,0,0
@@ edu.stanford.nlp.ie.KBPTokensregexExtractor.lambda$main$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.KBPEnsembleExtractor.classify,9,12,28,10,35.714285714285715,0,0
@@ edu.stanford.nlp.ie.KBPEnsembleExtractor.main,13,16,30,19,63.33333333333333,0,0
@@ edu.stanford.nlp.ie.KBPEnsembleExtractor.lambda$main$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.addNormalizedQuantitiesToEntities,34,52,109,23,21.100917431192663,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.detectQuantityModifier,36,50,45,45,100.0,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.processEntity,45,75,93,59,63.44086021505376,0,1
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizedMoneyString,35,55,79,21,26.582278481012654,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizedPercentString,15,22,39,34,87.17948717948718,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizedOrdinalString,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizedNumberString,10,13,23,20,86.95652173913044,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.recurNormalizeLiteralIntegerString,23,34,52,32,61.53846153846154,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.compositeAtUnitIfExists,13,19,29,23,79.3103448275862,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizeLiteralDecimalString,11,14,31,22,70.96774193548387,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizeMonthOrDay,15,20,30,15,50.0,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizeYear,25,35,76,41,53.94736842105263,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.normalizeDateString,27,42,89,55,61.79775280898876,0,0
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.singleEntityToString,7,8,9,9,100.0,0,1
@@ edu.stanford.nlp.ie.ChineseQuantifiableEntityNormalizer.prettyNumber,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.NERServer$Session.run,13,17,33,33,100.0,0,0
@@ edu.stanford.nlp.ie.NERServer$Session.close,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy$PerRelationStat.f1,5,6,11,11,100.0,0,1
@@ edu.stanford.nlp.ie.KBPRelationExtractor$Accuracy$PerRelationStat.compareTo,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier$1.drawSample,5,5,8,7,87.5,0,0
@@ edu.stanford.nlp.ie.ChineseMorphFeatureSets.<init>,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.ChineseMorphFeatureSets.getFeatures,47,70,179,87,48.60335195530726,0,0
@@ edu.stanford.nlp.ie.ChineseMorphFeatureSets.addTypedFeature,9,12,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier$2.process,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.NERClassifierCombiner$Language.fromString,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.NERGUI$ActionPerformer.actionPerformed,45,84,45,45,100.0,0,0
@@ edu.stanford.nlp.ie.KBPSemgrexExtractor.<init>,11,14,20,20,100.0,0,1
@@ edu.stanford.nlp.ie.KBPSemgrexExtractor.classify,14,20,47,47,100.0,0,0
@@ edu.stanford.nlp.ie.KBPSemgrexExtractor.matches,36,51,70,70,100.0,0,0
@@ edu.stanford.nlp.ie.KBPSemgrexExtractor.lambda$main$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.init,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.getCliqueFeatures,21,29,74,74,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.initLexicon,22,30,62,50,80.64516129032258,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.describeDistsimLexicon,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.distSimAnnotate,13,17,32,26,81.25,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.dehyphenate,8,10,20,10,50.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.isNameCase,12,16,20,13,65.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.noUpperCase,9,11,16,9,56.25,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.hasLetter,9,11,16,9,56.25,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.isOrdinal,19,30,47,47,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.readGazette,17,23,61,52,85.24590163934425,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.makeGenericKeyCache,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.generateSlashHyphenFeatures,10,12,26,26,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresC,477,732,2051,1793,87.42077035592393,0,6
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCpC,110,181,495,467,94.34343434343434,0,1
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCp2C,31,54,79,79,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCp3C,25,44,62,62,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCp4C,29,52,70,70,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCp5C,33,60,78,78,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCpCp2C,43,72,216,216,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCpCp2Cp3C,19,31,100,100,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCpCp2Cp3Cp4C,8,11,27,27,100.0,0,1
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCnC,6,8,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.featuresCpCnC,8,12,34,34,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.reverse,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.occurrencePatterns,49,75,223,147,65.91928251121077,0,1
@@ edu.stanford.nlp.ie.NERFeatureFactory.intern,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.NERFeatureFactory.initGazette,11,14,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.defaultReaderAndWriter,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.plainTextReaderAndWriter,7,9,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.<init>,11,14,42,36,85.71428571428571,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.reinit,9,11,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.makePlainTextReaderAndWriter,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.preprocessTokens,8,9,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyKBest,10,12,22,21,95.45454545454545,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.getViterbiSearchGraph,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyObjectBank,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyToString,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyToCharacterOffsets,21,29,63,23,36.507936507936506,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.segmentString,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.train,7,8,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.makeObjectBankFromString,6,7,26,26,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.makeObjectBankFromFiles,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.makeObjectBankFromFiles,11,14,25,25,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.makeObjectBankFromFiles,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.makeObjectBankFromReader,4,4,13,13,100.0,0,1
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.printProbsDocuments,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.outputCalibrationInfo,14,17,31,13,41.935483870967744,0,1
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyStdin,8,10,18,17,94.44444444444444,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyAndWriteAnswers,32,45,123,73,59.34959349593496,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyAndWriteAnswersKBest,8,9,21,12,57.14285714285714,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyAndWriteViterbiSearchGraph,7,8,24,17,70.83333333333334,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.writeAnswers,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.countResults,7,8,24,24,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.countResultsSegmenter,17,25,30,25,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.printResults,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.printPRLine,14,19,23,23,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.loadClassifier,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.loadClassifier,5,5,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.printFeatures,16,21,48,33,68.75,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.printFeatureLists,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.ie.AbstractSequenceClassifier.printFeatureListsHelper,16,20,37,20,54.054054054054056,0,1
@@ edu.stanford.nlp.ie.UniformPrior.<init>,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.UniformPrior.scoresOf,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.ie.PresetSequenceClassifier.<init>,4,4,10,9,90.0,0,1
@@ edu.stanford.nlp.ie.PresetSequenceClassifier.classify,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.NumberNormalizer.setVerbose,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.NumberNormalizer.parseNumberPart,33,57,37,21,56.75675675675676,0,0
@@ edu.stanford.nlp.ie.NumberNormalizer.wordToNumber,46,67,130,78,60.0,0,1
@@ edu.stanford.nlp.ie.NumberNormalizer.wordToNumberRecurse,17,24,58,34,58.620689655172406,0,0
@@ edu.stanford.nlp.ie.NumberNormalizer.findNumbers,113,173,872,139,15.940366972477063,0,1
@@ edu.stanford.nlp.ie.NumberNormalizer.findNumberRanges,18,25,35,35,100.0,0,0
@@ edu.stanford.nlp.ie.NumberNormalizer.findAndMergeNumbers,22,34,51,34,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.NumberNormalizer.findAndAnnotateNumericExpressionsWithRanges,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.<init>,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.scoresOf,5,5,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.setInitialSequence,7,8,23,11,47.82608695652174,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.addEntityToEntitiesArray,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.extractEntity,9,11,35,23,65.71428571428571,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.otherOccurrences,9,11,30,16,53.333333333333336,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.toArray,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.matches,11,14,41,30,73.17073170731707,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.joiningTwoEntities,11,15,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.splittingTwoEntities,9,12,18,18,100.0,0,1
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.appendingEntity,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.prependingEntity,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.addingSingletonEntity,10,14,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.removingEndOfEntity,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.removingBeginningOfEntity,10,13,23,23,100.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.noChange,14,19,26,26,100.0,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.updateSequenceElement,80,116,296,286,96.62162162162163,0,1
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.toString,7,8,33,22,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.toString,7,8,35,24,68.57142857142857,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.stripCorporateTitles,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.noSpecialChars,22,33,39,24,61.53846153846154,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.moreCanonicalMention,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.firstNameMatch,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.sameEntityWithoutLinking,37,63,75,75,100.0,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.nearExactEntityMatch,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.approximateEntityMatchScore,28,43,98,67,68.36734693877551,0,1
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.clusterEntityMentions,20,26,22,14,63.63636363636363,0,1
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.bestEntityMention,12,16,45,9,20.0,0,0
@@ edu.stanford.nlp.ie.KBPBasicSpanishCorefSystem.createCanonicalMentionMap,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$RelationType.fromString,19,26,38,38,100.0,0,0
@@ edu.stanford.nlp.ie.KBPRelationExtractor$RelationType.plausiblyHasRelation,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.demo.NERDemo.main,55,72,60,57,95.0,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.<init>,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.<init>,8,9,28,16,57.14285714285714,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.stemAcronym,12,16,47,36,76.59574468085107,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.setValue,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.setValue,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.getValue,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.equals,18,25,51,31,60.78431372549019,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.hashCode,8,9,28,13,46.42857142857143,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.writeToFieldValueCounter,8,10,30,16,53.333333333333336,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.unpackToCliqueTemplates,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.PascalTemplate.toString,8,10,35,18,51.42857142857142,0,0
@@ edu.stanford.nlp.ie.pascal.TeXHyphenator.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.TeXHyphenator.insertHyphPattern,10,13,26,9,34.61538461538461,0,1
@@ edu.stanford.nlp.ie.pascal.TeXHyphenator.getMatchingPatterns,11,15,37,27,72.97297297297297,0,0
@@ edu.stanford.nlp.ie.pascal.TeXHyphenator.labelWordBreakPoints,19,24,57,28,49.122807017543856,0,0
@@ edu.stanford.nlp.ie.pascal.TeXHyphenator.findBreakPoints,13,18,55,15,27.27272727272727,0,1
@@ edu.stanford.nlp.ie.pascal.TeXHyphenator.main,11,13,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.Alignment.serialize,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.Alignment.<init>,13,17,34,30,88.23529411764706,0,0
@@ edu.stanford.nlp.ie.pascal.Alignment.toString,12,16,65,27,41.53846153846154,0,0
@@ edu.stanford.nlp.ie.pascal.Alignment.equals,10,14,29,29,100.0,0,1
@@ edu.stanford.nlp.ie.pascal.Alignment.hashCode,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.<init>,8,11,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.<init>,10,13,17,14,82.35294117647058,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.<init>,7,10,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.incrementYear,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.incrementMonth,17,23,47,46,97.87234042553192,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.incrementDay,32,46,95,60,63.1578947368421,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.makeStringDayChange,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.makeStringMonthChange,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.makeStringYearChange,5,5,9,3,33.33333333333333,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.extractFields,36,55,71,71,100.0,0,1
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.getRangeDates,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.addExtraRanges,17,24,44,38,86.36363636363636,0,1
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isRange,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.getStartDate,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.getEndDate,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isAfter,58,89,113,84,74.33628318584071,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.checkWildcardAfterCompatibility,11,15,24,19,79.16666666666666,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isCompatible,14,19,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isYearCompatible,14,20,23,22,95.65217391304348,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isMonthCompatible,14,20,23,22,95.65217391304348,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isDayCompatible,14,20,23,22,95.65217391304348,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.checkWildcardCompatibility,11,15,24,19,79.16666666666666,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.contains,15,22,28,28,100.0,0,1
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isAfter,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isCompatibleDate,9,12,17,17,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isYearCompatible,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isMonthCompatible,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.isDayCompatible,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.tokenizeDate,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.extractYYYYMMDD,8,10,16,13,81.25,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.extractMMDDYY,14,18,26,19,73.07692307692307,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.extractYear,20,28,56,20,35.714285714285715,0,1
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.foundMiscYearPattern,21,30,81,13,16.049382716049383,0,1
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.extractMonth,15,20,39,16,41.02564102564102,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.extractDay,20,28,41,36,87.8048780487805,0,0
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.extractWeekday,7,8,5,5,100.0,0,1
@@ edu.stanford.nlp.ie.pascal.ISODateInstance.main,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.InfoTemplate.<init>,14,19,26,26,100.0,0,1
@@ edu.stanford.nlp.ie.pascal.InfoTemplate.equals,14,21,53,53,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.DateTemplate.<init>,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.DateTemplate.equals,12,17,37,37,100.0,0,0
@@ edu.stanford.nlp.ie.pascal.Prior.<init>,18,25,60,45,75.0,0,0
@@ edu.stanford.nlp.ie.pascal.Prior.get,7,8,13,8,61.53846153846154,0,0
@@ edu.stanford.nlp.ie.regexp.ChineseNumberSequenceClassifier.<init>,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.ChineseNumberSequenceClassifier.classify,38,61,101,92,91.0891089108911,0,0
@@ edu.stanford.nlp.ie.regexp.ChineseNumberSequenceClassifier.rightScanFindsMoneyWord,14,20,33,20,60.60606060606061,0,0
@@ edu.stanford.nlp.ie.regexp.ChineseNumberSequenceClassifier.classifyWithGlobalInformation,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.<init>,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.classifyWithGlobalInformation,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.finalizeClassification,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.classifyWithSUTime,44,65,105,91,86.66666666666667,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.alignSentence,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.buildSentenceFromTokens,10,14,25,21,84.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.buildText,12,16,39,19,48.717948717948715,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.moneyAndPercentRecognizer,29,46,90,63,70.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.ordinalRecognizer,9,12,15,15,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.copyTokens,18,24,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.transferAnnotations,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.copyTokens,7,10,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.copyCoreLabel,10,12,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.classifyOld,109,188,260,243,93.46153846153847,0,1
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.leftScanFindsWeightWord,8,10,17,9,52.94117647058824,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.rightScanFindsMoneyWord,13,18,31,18,58.06451612903226,0,0
@@ edu.stanford.nlp.ie.regexp.NumberSequenceClassifier.main,12,16,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier$Entry.<init>,8,9,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier$Entry.compareTo,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier.<init>,14,19,24,24,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier.<init>,10,13,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier.containsValidPos,11,14,26,18,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier.classify,12,15,37,32,86.48648648648648,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier.readEntries,20,27,36,33,91.66666666666666,0,0
@@ edu.stanford.nlp.ie.regexp.RegexNERSequenceClassifier.findStartIndex,21,32,64,47,73.4375,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier$Scorer.buildTagArray,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier$Scorer.getPossibleValues,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier$Scorer.scoreOf,25,33,79,41,51.89873417721519,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier$Scorer.scoresOf,23,32,88,65,73.86363636363636,0,1
@@ edu.stanford.nlp.ie.ner.CMMClassifier$Scorer.recenter,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.classify,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.classifyNoSeq,26,37,101,87,86.13861386138613,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.loglikelihood,15,19,42,27,64.28571428571429,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.getSequenceModel,12,15,31,31,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.classifySeq,70,101,306,210,68.62745098039215,0,1
@@ edu.stanford.nlp.ie.ner.CMMClassifier.retrain,8,9,29,19,65.51724137931035,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.retrain,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.train,11,14,53,45,84.90566037735849,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.getFeaturesAboveThreshold,16,21,42,28,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.getDataset,23,31,71,54,76.05633802816901,0,1
@@ edu.stanford.nlp.ie.ner.CMMClassifier.getBiasedDataset,24,32,69,61,88.40579710144928,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.getDataset,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.getDataset,24,32,84,61,72.61904761904762,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.adapt,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.adaptMaxEnt,8,10,27,27,100.0,0,1
@@ edu.stanford.nlp.ie.ner.CMMClassifier.train,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.trainMaxEnt,22,30,114,109,95.6140350877193,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.trainSemiSup,9,11,37,35,94.5945945945946,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.loadClassifier,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.makeAnswerArraysAndTagIndex,26,35,86,51,59.30232558139535,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.makeDatum,8,9,9,9,100.0,0,1
@@ edu.stanford.nlp.ie.ner.CMMClassifier.addOtherClasses,29,41,106,70,66.0377358490566,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.getThresholds,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.trainSemiSup,23,29,61,34,55.73770491803278,0,0
@@ edu.stanford.nlp.ie.ner.CMMClassifier.main,19,26,52,52,100.0,0,0
@@ edu.stanford.nlp.ie.ner.webapp.NERServlet.init,22,30,35,33,94.28571428571428,0,0
@@ edu.stanford.nlp.ie.ner.webapp.NERServlet.doGet,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.ner.webapp.NERServlet.addResults,23,33,61,44,72.1311475409836,0,1
@@ edu.stanford.nlp.ie.ner.webapp.NERServlet.outputHighlighting,19,25,43,31,72.09302325581395,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple$WithTree.subjectHead,13,17,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple$WithTree.objectHead,13,17,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple$WithTree.relationHead,15,20,36,19,52.77777777777778,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple$WithTree.lambda$relationHead$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.util.FixLocation.main,8,9,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.util.FixLocation.readFile,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.util.FixLocation.fix,15,21,38,18,47.368421052631575,0,0
@@ edu.stanford.nlp.ie.util.FixLocation.query,33,47,113,61,53.98230088495575,0,0
@@ edu.stanford.nlp.ie.util.FixLocation.print,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.relationGloss,16,20,21,21,100.0,0,1
@@ edu.stanford.nlp.ie.util.RelationTriple.relationLemmaGloss,16,20,21,21,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.getSpan,5,5,10,4,40.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.relationTokenSpan,18,24,87,31,35.63218390804598,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.asSentence,20,25,26,18,69.23076923076923,0,1
@@ edu.stanford.nlp.ie.util.RelationTriple.equals,11,15,31,31,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.toReverbString,15,20,53,27,50.943396226415096,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.lambda$relationLemmaGloss$5,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.lambda$relationLemmaGloss$4,8,11,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.lambda$objectLemmaGloss$3,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.lambda$objectLemmaGloss$2,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.lambda$subjectLemmaGloss$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.util.RelationTriple.lambda$subjectLemmaGloss$0,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.ResultsPrinter.align,11,14,28,14,50.0,0,0
@@ edu.stanford.nlp.ie.machinereading.RelationExtractorResultsPrinter.printResults,14,18,32,25,78.125,0,0
@@ edu.stanford.nlp.ie.machinereading.RelationExtractorResultsPrinter.printResultsInternal,29,39,87,50,57.47126436781609,0,0
@@ edu.stanford.nlp.ie.machinereading.RelationExtractorResultsPrinter.printResultsUsingLabels,8,10,20,16,80.0,0,0
@@ edu.stanford.nlp.ie.machinereading.ExtractorMerger.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.ExtractorMerger.annotate,14,17,23,17,73.91304347826086,0,0
@@ edu.stanford.nlp.ie.machinereading.ExtractorMerger.buildRelationExtractorMerger,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.save,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.trainMulticlass,9,11,23,21,91.30434782608695,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.reportWeights,10,12,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.classOf,11,14,22,22,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.compatibleLabel,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.extractAllRelations,14,18,43,41,95.34883720930233,0,1
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.annotateMulticlass,10,12,26,26,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.annotateSentence,10,12,8,8,100.0,0,1
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.annotate,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.createDataset,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.createDatum,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.createDatum,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.annotate,8,9,12,9,75.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.extractEntities,26,41,103,22,21.35922330097087,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.makeAnnotationFromGivenNERTag,18,25,54,30,55.55555555555556,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.makeAnnotationFromAllNERTags,19,27,66,28,42.42424242424242,0,1
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.notBIO,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.makeEntityMention,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.makeEntityMentionIdentifier,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.makeEntityMention,6,7,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.runTestSet,18,24,35,33,94.28571428571428,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.train,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.saveCoNLLFiles,26,38,67,30,44.776119402985074,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.saveCoNLL,16,22,32,19,59.375,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.createClassifier,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.load,6,7,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.labeledSentenceToString,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.createDatum,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.createDatum,6,7,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.addFeatures,243,377,687,546,79.47598253275109,0,3
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.sentToString,8,10,11,7,63.63636363636363,0,1
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.addDependencyPathFeatures,167,247,515,341,66.2135922330097,0,1
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.usingFeature,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.generalizeRelation,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.dependencyPathAsList,13,16,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.ie.machinereading.BasicRelationFeatureFactory.getFeature,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.setConsoleLevel,9,11,12,5,41.66666666666667,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeMachineReadingForAnnotation,20,26,37,37,100.0,0,1
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeMachineReading,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.run,72,112,209,155,74.16267942583733,0,1
@@ edu.stanford.nlp.ie.machinereading.MachineReading.printTask,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.train,64,95,196,145,73.9795918367347,0,1
@@ edu.stanford.nlp.ie.machinereading.MachineReading.removeSkippableRelations,15,20,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.changeGoldRelationArgsToPredicted,11,13,13,13,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.annotate,49,68,108,96,88.88888888888889,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.assignSyntacticHeadToEntities,23,34,28,28,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeExtractor,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeDataSets,30,41,104,69,66.34615384615384,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.keepPercentage,7,8,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.serializedModelExists,9,11,16,11,68.75,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeResultsPrinters,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeReader,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeAuxReader,5,6,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeEntityExtractor,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeRelationExtractor,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.makeRelationFeatureFactory,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.MachineReading.loadOrMakeSerializedSentences,10,14,25,24,96.0,0,1
@@ edu.stanford.nlp.ie.machinereading.EntityExtractorResultsPrinter.printResults,68,99,199,157,78.89447236180904,0,0
@@ edu.stanford.nlp.ie.machinereading.EntityExtractorResultsPrinter.makeLabel,5,6,10,9,90.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.<init>,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.getParser,6,8,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.parse,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.modifyUsingCoreNLPNER,12,15,16,12,75.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.sentenceToString,8,10,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.assignSyntacticHead,9,11,27,21,77.77777777777779,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.preProcessSentences,30,45,61,61,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.convertToCoreLabels,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.safeHead,6,7,8,8,100.0,0,1
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.findSyntacticHead,17,23,57,47,82.45614035087719,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.findPartialSpan,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.funkyFindLeafWithApproximateSpan,9,12,21,21,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.originalFindSyntacticHead,13,18,32,28,87.5,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.parseStrings,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.GenericDataSetReader.findTreeWithSpan,19,28,33,33,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.ResultsPrinter$1CompareSentences.compare,6,8,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothResultsByRelation$1RelComp.compare,12,16,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothResultsByRelation.printResults,34,51,76,69,90.78947368421053,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothEntityExtractor.getEntityTypeForTag,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothCONLL04Reader.read,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothCONLL04Reader.getNormalizedNERTag,14,19,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothCONLL04Reader.readSentence,20,29,54,42,77.77777777777779,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothCONLL04Reader.getIndexByObjectEquality,7,8,18,9,50.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.roth.RothCONLL04Reader.setHeadWord,17,25,60,46,76.66666666666667,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.read,16,21,21,21,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.countMentionTypes,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.countNameRelations,10,14,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.countAdjacentMentions,14,19,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.printCounter,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.readDocument,36,49,118,75,63.559322033898304,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.convertAceEventMention,14,18,34,24,70.58823529411765,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.convertAceRelationMention,15,21,40,30,75.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.AceReader.convertAceEntityMention,17,24,84,42,50.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceCharSeq.getTokenStart,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceCharSeq.getTokenEnd,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceCharSeq.match,18,26,95,42,44.21052631578947,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.loadDictionary,9,11,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.exists,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.loadProximityClasses,11,14,28,21,75.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.removeSpaces,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.detectCase,50,71,122,45,36.885245901639344,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.extractSuffixes,9,11,27,16,59.25925925925925,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.<init>,20,26,39,39,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.adjustPhrasePositions,5,5,10,8,80.0,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.display,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceRelation.toXml,8,9,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.hasApostropheBlock,10,13,26,9,34.61538461538461,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.concatenate,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.countNewLines,5,5,13,6,46.15384615384615,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.countNewLines,7,8,18,7,38.88888888888889,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.tokenizeToWords,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.tokenizeToWordTokens,25,34,120,57,47.5,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.tokenizeText,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.getNext,6,7,20,8,40.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.main,10,12,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer$AbbreviationMap.normalizeCase,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEventMention.getMinTokenStart,10,12,22,4,18.181818181818183,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEventMention.getMaxTokenEnd,10,12,22,4,18.181818181818183,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceElement.appendOffset,5,5,9,5,55.55555555555556,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceSentenceSegmenter.tokenizeAndSegmentSentences,23,33,108,27,25.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceSentenceSegmenter.main,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntity.toXml,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention.toXml,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention.contains,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention.detectHeadToken,8,10,31,17,54.83870967741935,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention.before,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention.after,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.setSource,15,20,21,21,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.toXml,10,12,15,15,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.tokensWithByteSpan,14,20,33,15,45.45454545454545,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.matchCharSeqs,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.parseDocument,60,86,212,94,44.339622641509436,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.parseDocument,33,46,101,47,46.53465346534654,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.constructSentenceRelationMentions,14,19,37,26,70.27027027027027,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.sameChunk,13,18,29,23,79.3103448275862,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.isChunkHead,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.findChunkEnd,9,11,20,13,65.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.findChunkStart,10,13,20,13,65.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.isApposition,9,13,17,17,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.countVerbs,7,8,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.countCommas,7,8,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.readRawBytes,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.readPredictedEntityBoundaries,30,45,86,56,65.11627906976744,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument.makeCharSeq,11,14,40,20,50.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceRelationMention.getFirstArg,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceRelationMention.getLastArg,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceRelationMention.toXml,7,8,23,23,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDomReader.parseRelationMention,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDomReader.parseEventMention,7,8,7,7,100.0,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDomReader.parseDocument,20,25,47,31,65.95744680851064,0,1
@@ edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDomReader.main,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.common.StringDictionary.getIndexAndCount,6,7,16,13,81.25,0,0
@@ edu.stanford.nlp.ie.machinereading.common.StringDictionary.get,10,13,27,17,62.96296296296296,0,0
@@ edu.stanford.nlp.ie.machinereading.common.StringDictionary.get,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.common.StringDictionary.getCount,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.common.StringDictionary.save,7,8,19,16,84.21052631578947,0,1
@@ edu.stanford.nlp.ie.machinereading.common.StringDictionary.load,14,19,27,27,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.common.DomReader.getChildByName,9,11,20,15,75.0,0,1
@@ edu.stanford.nlp.ie.machinereading.common.DomReader.getChildrenByName,7,8,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.ie.machinereading.common.DomReader.getChildByAttribute,11,15,29,24,82.75862068965517,0,1
@@ edu.stanford.nlp.ie.machinereading.common.DomReader.getChildByNameAndAttribute,12,17,33,28,84.84848484848484,0,0
@@ edu.stanford.nlp.ie.machinereading.common.SimpleTokenize.tokenize,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.common.SimpleTokenize.tokenize,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.common.SimpleTokenize.normalizeQuotes,10,13,31,13,41.935483870967744,0,0
@@ edu.stanford.nlp.ie.machinereading.common.SimpleTokenize.tokenizeWithQuotes,18,24,56,44,78.57142857142857,0,0
@@ edu.stanford.nlp.ie.machinereading.common.SimpleTokenize.quotify,7,8,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.ie.machinereading.common.NoPunctuationHeadFinder.isPunctuationLabel,7,9,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.common.NoPunctuationHeadFinder.postOperationFix,6,7,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Relation.addRelation,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Relation.getRelationMentions,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.<init>,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.removeFromParents,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.getSingleParent,17,23,20,18,90.0,0,1
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.toString,11,13,15,15,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.contains,10,13,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.addArg,12,16,34,29,85.29411764705883,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.setArgs,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.addArgs,10,13,20,16,80.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.mergeEvent,13,17,39,34,87.17948717948718,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.equals,23,34,59,59,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EventMention.hashCode,8,9,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Event.addEntity,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Event.getEventMentions,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Entity.addEntity,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Entity.getEntityMentions,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.<init>,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.fromValues,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.fromValues,19,25,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.equals,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.expandToInclude,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.contains,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.contains,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.isBefore,8,10,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.isAfter,8,10,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.toInclusive,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.overlaps,11,17,44,44,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.overlap,11,16,55,55,100.0,0,1
@@ edu.stanford.nlp.ie.machinereading.structure.Span.overlaps,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span.distance,11,15,28,28,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span$1.hasNext,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.Span$1.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionDataSet.<init>,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionDataSet.addSentences,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionSentence.getRelation,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionSentence.getAllUnrelatedRelations,17,22,44,20,45.45454545454545,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionSentence.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionSentence.tokensToString,7,8,16,8,50.0,0,1
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention$CompByHead.compare,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.argsMatch,9,11,25,20,80.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.getEntityMentionArgs,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.getFirstSyntacticHeadPosition,10,13,16,7,43.75,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.getLastSyntacticHeadPosition,10,13,16,7,43.75,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.toString,13,17,41,35,85.36585365853658,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.replaceGoldArgsWithPredicted,15,19,24,18,75.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.removeArguments,10,13,32,27,84.375,0,1
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.filterUnrelatedRelations,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.equals,23,34,59,59,100.0,0,1
@@ edu.stanford.nlp.ie.machinereading.structure.RelationMention.hashCode,11,13,16,16,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.equals,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.headIncludes,17,29,58,58,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.equals,6,8,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.labelEquals,14,24,50,50,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.textEquals,19,28,52,52,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.getValue,7,8,25,16,64.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.toString,29,37,39,39,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.EntityMention.hashCode,14,17,21,21,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.getExtentString,7,8,25,16,64.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.equals,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.getSpan,15,21,30,12,40.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.getFullValue,9,12,30,22,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.concatenateTypes,13,16,20,12,60.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.attributeMap,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.probsToString,7,8,10,6,60.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.printableObject,12,18,24,24,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.entityMentionsToCoreLabels,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.sentenceEntityMentionsToCoreLabels,29,43,59,43,72.88135593220339,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.sentenceCount,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addSentence,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addSentences,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.deepMentionCopy,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.sentenceDeepMentionCopy,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getRelations,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getAllRelations,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getAllUnrelatedRelations,21,28,48,24,50.0,0,1
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addEntityMention,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addEntityMentions,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getEntityMentions,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addRelationMention,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addRelationMentions,4,4,6,5,83.33333333333334,0,1
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getRelationMentions,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addEventMention,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.addEventMentions,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getEventMentions,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.prettify,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getTextContent,10,13,23,15,65.21739130434783,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.sentenceToString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.tokensAndNELabelsToString,11,15,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.datasetToString,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.tokensToString,7,8,8,4,50.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.updateOffsets,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.updateOffsetsInCoreLabels,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.machinereading.structure.ExtractionObject$CompByExtent.compare,6,7,10,10,100.0,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifierNoisyLabel.readErrorMatrix,5,5,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierNoisyLabel.getObjectiveFunction,7,9,33,32,96.96969696969697,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction$ExpectationThreadsafeProcessorWithEmpirical.process,11,13,46,39,84.78260869565217,0,1
@@ edu.stanford.nlp.ie.crf.TestSequenceModel.<init>,14,17,39,30,76.92307692307693,0,1
@@ edu.stanford.nlp.ie.crf.TestSequenceModel.getPossibleValues,7,8,17,17,100.0,0,0
@@ edu.stanford.nlp.ie.crf.TestSequenceModel.scoreOf,5,5,19,15,78.94736842105263,0,1
@@ edu.stanford.nlp.ie.crf.TestSequenceModel.scoresOf,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.domainDimension,10,13,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.initial,17,21,53,35,66.0377358490566,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.empty2D,8,9,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.initialize2DWeights,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.to2D,5,5,15,10,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.computeEHat,21,27,79,57,72.15189873417721,0,1
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.logPotential,23,30,106,76,71.69811320754717,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.combineAndScaleLopWeights,8,9,26,13,50.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.combineAndScaleLopWeights2D,11,13,41,21,51.21951219512195,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.separateLopExpertWeights2D,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.separateLopExpertWeights,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.getCliquePotentialFunction,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.calculate,62,86,309,199,64.40129449838187,0,6
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction$ExpectationThreadsafeProcessor.process,8,9,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.addMenuBar,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.getFile,9,12,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.saveUntaggedContents,5,5,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.checkFile,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.loadClassifier,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.loadClassifier,5,5,8,8,100.0,0,1
@@ edu.stanford.nlp.ie.crf.NERGUI.openURL,5,5,13,13,100.0,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.removeTags,7,8,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.extract,35,47,93,75,80.64516129032258,0,1
@@ edu.stanford.nlp.ie.crf.NERGUI.colorToHTML,20,28,35,27,77.14285714285715,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.buildExtractButton,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.buildTagPanel,11,14,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI.makeTagToColorMap,9,11,14,13,92.85714285714286,0,1
@@ edu.stanford.nlp.ie.crf.NERGUI.getNColors,15,19,43,25,58.139534883720934,0,0
@@ edu.stanford.nlp.ie.crf.NonLinearSecondOrderCliquePotentialFunction.hiddenLayerOutput,36,51,133,91,68.42105263157895,0,0
@@ edu.stanford.nlp.ie.crf.NonLinearSecondOrderCliquePotentialFunction.computeCliquePotential,21,28,97,55,56.70103092783505,0,0
@@ edu.stanford.nlp.ie.crf.NonLinearCliquePotentialFunction.hiddenLayerOutput,24,33,98,60,61.224489795918366,0,0
@@ edu.stanford.nlp.ie.crf.NonLinearCliquePotentialFunction.computeCliquePotential,23,31,95,63,66.3157894736842,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierEvaluator.setEvalCmd,5,6,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierEvaluator.interpretCmdOutput,9,11,24,15,62.5,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierEvaluator.evaluate,5,5,10,8,80.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionNoisyLabel.expectedAndEmpiricalCountsAndValueForADoc,4,4,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierWithLOP.createPartialDataForLOP,19,24,85,39,45.88235294117647,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierWithLOP.getFeatureBoundaryIndices,21,27,75,44,58.666666666666664,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifierWithLOP.trainWeights,46,63,191,153,80.10471204188482,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.transformDocData,16,21,74,39,52.702702702702695,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.getCliquePotentialFunctionForTest,6,7,25,23,92.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.trainWeights,7,8,38,38,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.trainWeightsUsingNonLinearCRF,17,23,49,41,83.6734693877551,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.serializeTextClassifier,40,52,70,62,88.57142857142857,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.loadTextClassifier,67,93,226,157,69.46902654867256,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.serializeClassifier,5,5,17,17,100.0,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifierNonlinear.loadClassifier,5,5,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLabel.equals,11,14,33,26,78.78787878787878,0,0
@@ edu.stanford.nlp.ie.crf.CRFLabel.toString,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLabel.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLabel.hashCode,6,7,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.<init>,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.scoresOf,23,31,118,75,63.559322033898304,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.scoreOf,5,5,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.logProbTable,8,9,28,17,60.71428571428571,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.probsToDoubleArr,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.logProbsToDoubleArr,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.probs,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.logProbs,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.logProb,9,11,46,38,82.6086956521739,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.logProbs,10,12,33,22,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.probs,10,12,33,22,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.objectArrayToIntArray,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.intArrayToListE,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.condLogProbGivenPrevious,9,11,38,32,84.21052631578947,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.condLogProbsGivenPrevious,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.condLogProbsGivenPrevious,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.condLogProbGivenNext,9,11,38,32,84.21052631578947,0,2
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.condLogProbsGivenNext,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.condLogProbsGivenNext,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.getCalibratedCliqueTree,12,15,42,24,57.14285714285714,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.getCalibratedCliqueTree,10,12,37,22,59.45945945945946,0,0
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.getFactorTable,13,16,59,26,44.06779661016949,0,1
@@ edu.stanford.nlp.ie.crf.CRFCliqueTree.getFactorTable,12,15,45,22,48.888888888888886,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.initial,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.initial,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.getPriorType,21,32,25,25,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.<init>,7,8,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.empiricalCounts,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.empiricalCountsForADoc,23,30,69,46,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.expectedCountsAndValueForADoc,10,12,27,27,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.documentExpectedCounts,21,27,65,35,53.84615384615385,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.documentLogProbability,13,18,44,34,77.27272727272727,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.multiThreadGradient,27,37,87,68,78.16091954022988,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.calculate,14,18,57,39,68.42105263157895,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.calculateStochastic,12,15,51,36,70.58823529411765,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.calculateStochasticUpdate,10,12,35,25,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.calculateStochasticGradient,10,12,39,27,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.valueAt,7,8,10,3,30.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.getFeatureGrouping,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.applyPrior,25,33,88,63,71.5909090909091,0,1
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.getCondProbs,21,27,81,39,48.148148148148145,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.combine2DArr,8,9,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.combine2DArr,8,9,22,13,59.09090909090909,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.combine2DArr,8,9,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.combine2DArr,8,9,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.to2D,5,5,15,10,66.66666666666666,0,1
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.to2D,5,5,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.clear2D,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.to1D,5,5,3,2,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.to1D,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.getWeightIndices,9,11,36,26,72.22222222222221,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.empty2D,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierFloat.trainWeights,15,19,46,38,82.6086956521739,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.toProbString,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.toString,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.toString,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.toString,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.toArray,5,5,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.indexOf,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.indexOf,5,5,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.indicesEnd,8,9,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.indicesFront,13,16,46,25,54.347826086956516,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.conditionalLogProb,7,8,26,22,84.61538461538461,0,1
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.unnormalizedLogProbFront,5,5,13,9,69.23076923076923,0,1
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.unnormalizedLogProbEnd,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.unnormalizedLogProbEnd,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.multiplyInFront,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.multiplyInEnd,5,5,14,10,71.42857142857143,0,1
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.sumOutEnd,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.sumOutFront,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.divideBy,8,10,32,18,56.25,0,0
@@ edu.stanford.nlp.ie.crf.FloatFactorTable.main,26,33,74,26,35.13513513513514,0,0
@@ edu.stanford.nlp.ie.crf.LinearCliquePotentialFunction.computeCliquePotential,10,12,31,20,64.51612903225806,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.<init>,20,25,62,52,83.87096774193549,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.getNumWeights,7,8,10,7,70.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.getFeatureTypeIndex,14,19,13,13,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.scaleWeights,8,9,29,16,55.172413793103445,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.combineWeights,30,40,173,111,64.16184971098265,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.combine,14,19,64,60,93.75,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.dropFeaturesBelowThreshold,17,22,104,47,45.19230769230769,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.documentToDataAndLabels,23,32,95,58,61.05263157894737,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printLabelInformation,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printLabelValue,32,42,110,69,62.727272727272734,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.documentsToDataAndLabels,15,20,50,46,92.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.documentsToDataAndLabelsList,5,5,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printFeatures,9,11,24,23,95.83333333333334,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.makeAnswerArraysAndTagIndex,125,176,455,293,64.3956043956044,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.allLabels,10,12,33,20,60.60606060606061,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.makeDatum,15,19,65,51,78.46153846153847,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.makeDatumUsingEmbedding,36,51,139,72,51.798561151079134,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.dumpFeatures,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.classify,6,7,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.classify,6,7,21,21,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.classifyAndWriteAnswers,14,19,54,37,68.51851851851852,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.getSequenceModel,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.getCliquePotentialFunctionForTest,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.classifyMaxEnt,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.classifyMaxEnt,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.classifyMaxEnt,18,24,67,51,76.11940298507463,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.classifyGibbs,26,36,107,97,90.65420560747664,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printProbsDocument,20,28,66,50,75.75757575757575,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.zeroOrderProbabilities,8,9,19,13,68.42105263157895,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printFirstOrderProbsDocuments,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printFactorTableDocuments,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.getCliqueTrees,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printFactorTableDocument,8,9,31,20,64.51612903225806,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.printFirstOrderProbsDocument,20,26,52,39,75.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.train,52,75,246,209,84.95934959349594,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.to2D,8,9,28,16,57.14285714285714,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.pruneNodeFeatureIndices,11,13,38,30,78.94736842105263,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.trainWeights,53,72,202,137,67.82178217821783,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.getMinimizer,36,51,246,169,68.69918699186992,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.extractDatumSequence,19,24,79,47,59.49367088607595,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.addProcessedData,26,35,95,62,65.26315789473685,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.loadTextClassifier,74,105,216,157,72.68518518518519,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.loadTextClassifier,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.serializeTextClassifier,33,43,109,82,75.22935779816514,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.serializeClassifier,9,11,25,25,100.0,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.loadClassifier,33,45,103,85,82.52427184466019,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.loadTagIndex,10,13,27,25,92.5925925925926,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.parseMatrix,23,30,58,33,56.896551724137936,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.readEntityMatrices,18,23,55,33,60.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.writeWeights,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.topWeights,10,12,24,24,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.readEmbeddingsData,21,29,52,35,67.3076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.chooseCRFClassifier,13,17,32,26,81.25,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.toString,8,10,25,11,44.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.main,50,74,184,184,100.0,0,1
@@ edu.stanford.nlp.ie.crf.CRFClassifier.lambda$makeDatumUsingEmbedding$1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifier.lambda$makeDatum$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.crf.LabelDictionary.increment,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.ie.crf.LabelDictionary.isConstrained,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.crf.LabelDictionary.getConstrainedSet,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.crf.LabelDictionary.lock,13,17,34,33,97.05882352941177,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierWithDropout.loadAuxiliaryData,13,17,36,30,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.crf.CRFClassifierWithDropout.getObjectiveFunction,7,8,37,32,86.48648648648648,0,1
@@ edu.stanford.nlp.ie.crf.NoisyLabelLinearCliquePotentialFunction.g,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.crf.NoisyLabelLinearCliquePotentialFunction.computeCliquePotential,7,8,15,9,60.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.<init>,11,13,31,23,74.19354838709677,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.initEdgeLabels,11,14,49,44,89.79591836734694,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.sparseE,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.sparseE,8,9,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.expectedCountsAndValueForADoc,55,77,207,149,71.98067632850241,0,1
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.increScoreAllowNull,7,8,18,18,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.initializeDataFeatureHash,39,52,122,87,71.31147540983606,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.getDropoutPrior,132,190,615,277,45.040650406504064,0,1
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.setWeights,12,15,42,25,59.523809523809526,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.calculate,52,72,180,118,65.55555555555556,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.getPriorType,19,29,23,23,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.<init>,11,15,39,39,100.0,0,1
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.domainDimension,13,17,60,50,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.initial,52,72,289,155,53.63321799307958,0,1
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.empiricalCounts,13,16,45,33,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.emptyU,10,13,40,27,67.5,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.emptyW,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.separateWeights,22,29,91,45,49.45054945054945,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.calculate,234,341,1206,665,55.140961857379764,0,3
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.getRegularizerParamRange,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.to2D,5,5,16,11,68.75,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.empty2D,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.emptyFull2D,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.getFeatureGrouping,41,54,161,105,65.21739130434783,0,1
@@ edu.stanford.nlp.ie.crf.FactorTable.toProbString,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.toNonLogString,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.toString,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.toString,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.toString,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.toArray,5,5,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.indexOf,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.indexOf,5,5,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.indexOf,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.indexOf,5,5,15,8,53.333333333333336,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.indicesEnd,8,9,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.indicesEnd,5,5,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.indicesFront,5,5,10,7,70.0,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbGivenPrevious,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbsGivenPrevious,7,8,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbGivenFirst,4,4,13,13,100.0,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.unnormalizedConditionalLogProbGivenFirst,4,4,13,13,100.0,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbGivenNext,7,8,28,24,85.71428571428571,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.unnormalizedLogProbEnd,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.unnormalizedLogProbEnd,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.multiplyInFront,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.multiplyInEnd,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.sumOutEnd,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.sumOutFront,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.divideBy,8,10,32,18,56.25,0,0
@@ edu.stanford.nlp.ie.crf.FactorTable.main,53,69,212,101,47.64150943396226,0,0
@@ edu.stanford.nlp.ie.crf.NERGUI$ActionPerformer.actionPerformed,52,98,52,52,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.getPriorType,12,16,11,11,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.<init>,8,11,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.domainDimension,13,17,60,50,83.33333333333334,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.initial,66,92,377,191,50.663129973474796,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.emptyU4Edge,10,13,40,27,67.5,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.emptyW4Edge,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.emptyU,10,13,40,27,67.5,0,1
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.emptyW,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.separateWeights,35,46,153,66,43.13725490196079,0,0
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.calculate,230,327,1121,513,45.76271186440678,0,3
@@ edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.emptyFull2D,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFBiasedClassifier.makeDatum,11,14,46,33,71.73913043478261,0,0
@@ edu.stanford.nlp.ie.crf.CRFBiasedClassifier.addBiasFeature,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFBiasedClassifier.main,19,26,65,65,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFBiasedClassifier.lambda$makeDatum$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFDatum.toString,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.ie.crf.CRFDatum.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFFeatureExporter.ubPrefixFeatureString,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFFeatureExporter.getFeatureString,15,19,40,35,87.5,0,0
@@ edu.stanford.nlp.ie.crf.CRFFeatureExporter.printFeatures,14,17,80,34,42.5,0,0
@@ edu.stanford.nlp.ie.crf.CRFFeatureExporter.printFeatures,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFFeatureExporter.main,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.domainDimension,6,7,14,11,78.57142857142857,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.to2D,5,5,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.to1D,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.empty2D,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.empiricalCounts,14,17,72,39,54.166666666666664,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.getFloatFactorTable,13,16,57,24,42.10526315789473,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.getCalibratedCliqueTree,22,31,92,54,58.69565217391305,0,0
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.calculate,52,70,282,160,56.73758865248227,0,1
@@ edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFloatFunction.calculateWeird1,65,87,318,175,55.0314465408805,0,1
@@ edu.stanford.nlp.ie.qe.Units.registerDerivedUnit,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.ie.qe.Units.registerUnit,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.qe.Units.registerUnits,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.ie.qe.Units.loadUnits,20,26,56,51,91.07142857142857,0,0
@@ edu.stanford.nlp.ie.qe.QuantifiableEntityExtractor.extract,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.ie.qe.QuantifiableEntityExtractor.generatePrefixDefs,12,15,19,19,100.0,0,0
@@ edu.stanford.nlp.ie.qe.QuantifiableEntityExtractor.generateUnitsStage0Rules,18,23,32,32,100.0,0,0
@@ edu.stanford.nlp.ie.qe.Unit.formatInDefaultUnit,5,6,14,14,100.0,0,0
@@ edu.stanford.nlp.ie.qe.UnitPrefix.registerPrefixes,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.ie.qe.UnitPrefix.loadPrefixes,8,9,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.scenegraph.EntityClassifier.getDatum,15,19,30,24,80.0,0,1
@@ edu.stanford.nlp.scenegraph.EntityClassifier.train,13,16,13,13,100.0,0,0
@@ edu.stanford.nlp.scenegraph.EntityClassifier.main,8,9,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphUtils.getCommonAncestor,14,19,32,23,71.875,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphUtils.inSameSubTree,18,26,25,21,84.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphUtils.getClosestIndices,16,22,32,20,62.5,0,1
@@ edu.stanford.nlp.scenegraph.Sandbox.printMostDiscriminativeSyntacticPatterns,13,16,16,16,100.0,0,0
@@ edu.stanford.nlp.scenegraph.RuleBasedParser.getPredicate,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.scenegraph.RuleBasedParser.parse,48,68,114,110,96.49122807017544,0,1
@@ edu.stanford.nlp.scenegraph.RuleBasedParser.countDoubleNumMods,13,16,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.scenegraph.RuleBasedParser.main,25,33,59,45,76.27118644067797,0,0
@@ edu.stanford.nlp.scenegraph.DcorefPronounResolver.resolvePronouns,14,19,19,10,52.63157894736842,0,0
@@ edu.stanford.nlp.scenegraph.KNNSceneGraphParser.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.scenegraph.KNNSceneGraphParser.parse,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.scenegraph.KNNSceneGraphParser.loadImages,8,9,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.scenegraph.KNNSceneGraphParser.train,13,16,25,20,80.0,0,0
@@ edu.stanford.nlp.scenegraph.KNNSceneGraphParser.main,27,35,68,58,85.29411764705883,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageCleaner.getPipeline,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageCleaner.getTokenizerPipeline,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageCleaner.extractAllAttributes,8,9,1,1,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageCleaner.splitAttributeConjunctions,33,48,81,55,67.90123456790124,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageCleaner.lemmatize,18,23,23,23,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageCleaner.trimFunctionWords,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageCleaner.lambda$lemmaGloss$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.BoWExample.findWordsInBetween,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.scenegraph.BoWExample.extractFeatures,17,23,23,23,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageDependencyParser.main,13,16,20,16,80.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageFilter.countAll,11,13,6,6,100.0,0,1
@@ edu.stanford.nlp.scenegraph.SceneGraphImageFilter.filterRegions,32,45,75,50,66.66666666666666,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImageFilter.main,13,16,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraph.toReadableString,11,13,6,6,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraph.getOrAddNode,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraph.toJSON,14,17,14,14,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphEvaluation$SceneGraphRelationTriplet.<init>,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphEvaluation$SceneGraphRelationTriplet.equals,14,20,45,45,100.0,0,0
@@ edu.stanford.nlp.scenegraph.GroundTruthConverter.main,25,32,47,43,91.48936170212765,0,1
@@ edu.stanford.nlp.scenegraph.SceneGraphAttribute.equals,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.scenegraph.AbstractPronounResolver.score,15,21,39,23,58.97435897435898,0,0
@@ edu.stanford.nlp.scenegraph.AbstractPronounResolver.run,5,5,18,12,66.66666666666666,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.processQuanftificationModifiers,41,55,102,102,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.createMultiWordExpression,15,20,22,17,77.27272727272727,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.resolvePlurals,70,103,184,170,92.3913043478261,0,1
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.copyNode,13,16,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.collapseCompounds,17,23,44,27,61.36363636363637,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.collapseParticles,16,21,33,22,66.66666666666666,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.resolvePronouns,18,24,25,25,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.main,29,41,63,43,68.25396825396825,0,1
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.lambda$collapseParticles$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SemanticGraphEnhancer.lambda$collapseCompounds$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphEvaluation.evaluate,29,37,36,31,86.11111111111111,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphEvaluation.evaluate,26,33,36,31,86.11111111111111,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphEvaluation.toSmatchString,40,53,99,66,66.66666666666666,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphEvaluation.toSmatchString,50,67,130,94,72.3076923076923,0,1
@@ edu.stanford.nlp.scenegraph.AbstractPronounResolver$TestExample.<init>,16,21,18,18,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphImagePCFGParser.main,16,20,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.scenegraph.SimplePronounResolution.bfsNPSearch,15,20,21,21,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SimplePronounResolution.resolvePronouns,14,20,28,28,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SimplePronounResolution.resolvePronouns,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.BoWSceneGraphParser.<init>,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.scenegraph.BoWSceneGraphParser.parse,39,55,69,69,100.0,0,0
@@ edu.stanford.nlp.scenegraph.BoWSceneGraphParser.loadImages,8,9,12,8,66.66666666666666,0,1
@@ edu.stanford.nlp.scenegraph.BoWSceneGraphParser.getTrainingExamples,47,68,99,98,98.98989898989899,0,0
@@ edu.stanford.nlp.scenegraph.BoWSceneGraphParser.main,32,44,86,72,83.72093023255815,0,0
@@ edu.stanford.nlp.scenegraph.AbstractSceneGraphParser.parse,4,4,1,1,100.0,0,0
@@ edu.stanford.nlp.scenegraph.AbstractSceneGraphParser.parse,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.EntityExtractor.extractEntities,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.scenegraph.EntityExtractor.extractAttributes,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.scenegraph.ObjectSceneGraphParser.parse,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.scenegraph.ObjectSceneGraphParser.main,14,18,29,21,72.41379310344827,0,0
@@ edu.stanford.nlp.scenegraph.GenerateAlignmentData.main,16,20,20,16,80.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphNode.compareTo,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphNode.equals,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphNode.toJSONString,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.scenegraph.OpenIEParser.main,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphSentenceMatcher.containsNull,7,8,2,2,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphSentenceMatcher.findClosestPair,20,26,23,18,78.26086956521739,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphSentenceMatcher.getRelationTriples,28,39,47,47,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphSentenceMatcher.getMatch,42,59,153,68,44.44444444444444,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphSentenceMatcher.tagsCompatible,13,20,16,16,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphSentenceMatcher.main,8,9,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphRelation.compareTo,8,10,20,20,100.0,0,0
@@ edu.stanford.nlp.scenegraph.SceneGraphRelation.equals,11,15,29,29,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRegion.fromJSONObject,9,12,19,13,68.42105263157895,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRegion.toJSONObject,11,15,25,25,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRegion.toReadableString,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageObject.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageObject.fromJSONObject,9,11,10,10,100.0,0,1
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageObject.toJSONObject,14,18,22,22,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageObject.lambda$toJSONObject$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.labelFromString,15,20,21,21,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.labelToString,20,28,53,25,47.16981132075472,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.containsLemma,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.containsWord,8,10,6,6,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.findWord,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.findLemma,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.getSemanticGraph,15,19,28,24,85.71428571428571,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageUtils.grammaticalStructureToJSON,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.fromJSONObject,12,16,23,23,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.toJSONObject,17,22,39,39,100.0,0,1
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.clone,10,13,21,21,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.subjectGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.subjectLemmaGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.attributeGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.attributeLemmaGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.equals,12,16,21,21,100.0,0,1
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.lambda$attributeLemmaGloss$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageAttribute.lambda$subjectLemmaGloss$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.fromJSONObject,19,27,38,38,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.toJSONObject,22,29,50,50,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.subjectGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.subjectLemmaGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.objectGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.objectLemmaGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.predicateGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.predicateLemmaGloss,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.equals,14,19,25,25,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.lambda$predicateLemmaGloss$2,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.lambda$objectLemmaGloss$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImageRelationship.lambda$subjectLemmaGloss$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImage.readFromJSON,18,23,20,20,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImage.toJSON,14,17,22,22,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImage.main,11,13,15,11,73.33333333333333,0,1
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImage.addAttribute,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImage.addRelationship,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.scenegraph.image.SceneGraphImage.removeRegion,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.sentiment.RNNOptions.readObject,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.sentiment.RNNOptions.toString,15,20,55,34,61.81818181818181,0,0
@@ edu.stanford.nlp.sentiment.RNNOptions.setOption,53,76,179,167,93.29608938547486,0,1
@@ edu.stanford.nlp.sentiment.CollapseUnaryTransformer.transformTree,12,16,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.sentiment.ExternalEvaluate.populatePredictedLabels,16,22,33,28,84.84848484848484,0,0
@@ edu.stanford.nlp.sentiment.ExternalEvaluate.main,15,20,77,18,23.376623376623375,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.printConfusionMatrix,8,9,26,13,50.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.approxAccuracy,14,17,68,30,44.11764705882353,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.approxCombinedAccuracy,14,17,46,21,45.65217391304348,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.reset,5,5,15,15,100.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.eval,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.eval,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.countLengthAccuracy,13,17,28,18,64.28571428571429,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.countTree,12,15,19,19,100.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.countRoot,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.lengthAccuracies,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.printLengthAccuracies,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.sentiment.AbstractEvaluate.printSummary,15,20,72,64,88.88888888888889,0,0
@@ edu.stanford.nlp.sentiment.ConvertMatlabModel.copyWordVector,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.sentiment.ConvertMatlabModel.replaceWordVector,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.sentiment.ConvertMatlabModel.loadMatrix,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.sentiment.ConvertMatlabModel.main,34,48,140,56,40.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.sumError,9,11,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.getPredictedClass,7,8,22,7,31.818181818181817,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.scoreDerivatives,8,9,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.calculate,10,12,55,48,87.27272727272727,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.scaleAndRegularize,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.scaleAndRegularize,10,13,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.scaleAndRegularizeTensor,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.backpropDerivativesAndError,21,27,108,106,98.14814814814815,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.computeTensorDeltaDown,5,5,16,9,56.25,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.getTensorGradient,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient.forwardPropagateTree,19,25,50,42,84.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentTraining.executeOneTrainingBatch,5,5,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.sentiment.SentimentTraining.train,35,52,170,122,71.76470588235294,0,0
@@ edu.stanford.nlp.sentiment.SentimentTraining.main,30,43,270,44,16.296296296296298,0,0
@@ edu.stanford.nlp.sentiment.RNNTrainOptions.getClassWeight,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.sentiment.RNNTrainOptions.toString,8,9,33,29,87.87878787878788,0,0
@@ edu.stanford.nlp.sentiment.RNNTrainOptions.setOption,40,58,134,130,97.01492537313433,0,0
@@ edu.stanford.nlp.sentiment.ReadSentimentDataset.convertTree,51,70,150,76,50.66666666666667,0,0
@@ edu.stanford.nlp.sentiment.ReadSentimentDataset.connect,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.sentiment.ReadSentimentDataset.writeTrees,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.sentiment.ReadSentimentDataset.main,64,92,645,78,12.093023255813954,0,1
@@ edu.stanford.nlp.sentiment.ReadSentimentDataset.lambda$static$1,6,7,5,5,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.modelFromMatrices,5,6,13,13,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.<init>,14,17,34,26,76.47058823529412,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.<init>,34,46,100,89,89.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.toString,44,63,83,83,100.0,0,1
@@ edu.stanford.nlp.sentiment.SentimentModel.initRandomWordVectors,15,19,21,20,95.23809523809523,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.readWordVectors,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.getWForNode,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.getTensorForNode,8,10,14,14,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.getClassWForNode,8,10,19,19,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.getVocabWord,6,7,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.basicCategory,7,9,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.getBinaryClassification,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentModel.printParamInformation,32,46,181,62,34.25414364640884,0,0
@@ edu.stanford.nlp.sentiment.SentimentUtils.attachLabels,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentUtils.readTreesWithLabels,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentUtils.sentimentString,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentUtils.lambda$static$0,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.sentiment.SimpleSentiment$SentimentDatum.asCoreMap,11,16,30,24,80.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient$ModelDerivatives.<init>,8,9,16,16,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient$ModelDerivatives.addMatrices,12,15,14,14,100.0,0,1
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient$ModelDerivatives.addTensors,12,15,14,14,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient$ModelDerivatives.addMatrices,12,15,14,14,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient$ModelDerivatives.initDerivatives,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient$ModelDerivatives.initTensorDerivatives,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentCostAndGradient$ModelDerivatives.initDerivatives,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sentiment.SimpleSentiment.featurize,10,12,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.sentiment.SimpleSentiment.train,16,20,40,32,80.0,0,0
@@ edu.stanford.nlp.sentiment.SimpleSentiment.$deserializeLambda$,13,21,13,13,100.0,0,0
@@ edu.stanford.nlp.sentiment.SimpleSentiment.lambda$twitter$6,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.sentiment.SimpleSentiment.lambda$stanford$5,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.sentiment.SimpleSentiment.lambda$train$946015b$1,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.sentiment.SimpleSentiment.lambda$train$1,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentPipeline.setSentimentLabels,9,11,8,8,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentPipeline.setIndexLabels,7,8,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.sentiment.SentimentPipeline.outputTreeVectors,10,12,25,18,72.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentPipeline.outputTreeScores,10,12,25,18,72.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentPipeline.outputTree,11,15,19,19,100.0,0,0
@@ edu.stanford.nlp.sentiment.SentimentPipeline.getAnnotations,14,18,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.sentiment.SentimentPipeline.main,78,110,485,63,12.989690721649486,0,0
@@ edu.stanford.nlp.sentiment.Evaluate.countUnks,10,13,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.sentiment.Evaluate.printSummary,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.sentiment.Evaluate.populatePredictedLabels,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.sentiment.Evaluate.main,18,24,107,30,28.037383177570092,0,0
@@ edu.stanford.nlp.sentiment.BuildBinarizedDataset.setUnknownLabels,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.sentiment.BuildBinarizedDataset.setPredictedLabels,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.sentiment.BuildBinarizedDataset.extractLabels,16,21,43,22,51.162790697674424,0,0
@@ edu.stanford.nlp.sentiment.BuildBinarizedDataset.setSpanLabel,15,21,36,36,100.0,0,0
@@ edu.stanford.nlp.sentiment.BuildBinarizedDataset.main,30,40,107,36,33.64485981308411,0,0
@@ edu.stanford.nlp.sentiment.RNNTestOptions.setOption,10,13,27,27,100.0,0,1
@@ edu.stanford.nlp.neural.Embedding.loadWordVectors,26,38,83,39,46.98795180722892,0,0
@@ edu.stanford.nlp.neural.Embedding.loadWordVectors,26,38,84,40,47.61904761904761,0,0
@@ edu.stanford.nlp.neural.Embedding.get,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.neural.Embedding.getEmbeddingSize,16,22,32,14,43.75,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.<init>,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.<init>,8,10,39,27,69.23076923076923,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.random,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.set,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.scale,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.plus,9,12,53,49,92.45283018867924,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.elementMult,9,12,53,49,92.45283018867924,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.elementSum,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.setSlice,9,12,33,33,100.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.getSlice,5,6,14,14,100.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.bilinearProducts,11,14,33,29,87.87878787878788,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.isZero,7,8,18,11,61.111111111111114,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.toString,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.neural.SimpleTensor.toString,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.neural.VectorMap$itype.getType,6,7,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.neural.VectorMap$itype.read,6,8,12,12,100.0,0,0
@@ edu.stanford.nlp.neural.VectorMap$itype.write,7,9,15,15,100.0,0,0
@@ edu.stanford.nlp.neural.VectorMap.serialize,13,17,14,14,100.0,0,0
@@ edu.stanford.nlp.neural.VectorMap.serialize,11,13,11,6,54.54545454545454,0,0
@@ edu.stanford.nlp.neural.VectorMap.deserialize,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.neural.VectorMap.deserialize,10,12,32,24,75.0,0,1
@@ edu.stanford.nlp.neural.VectorMap.readWord2Vec,15,20,30,19,63.33333333333333,0,0
@@ edu.stanford.nlp.neural.VectorMap.equals,24,35,41,34,82.92682926829268,0,0
@@ edu.stanford.nlp.neural.VectorMap.sameFloat,8,11,12,12,100.0,0,0
@@ edu.stanford.nlp.neural.VectorMap.fromFloat,12,16,19,19,100.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor$SimpleMatrixIteratorWrapper.hasNext,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor$SimpleMatrixIteratorWrapper.next,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.neural.SimpleTensor$SimpleMatrixIteratorWrapper.advanceIterator,8,11,19,19,100.0,0,0
@@ edu.stanford.nlp.neural.ConvertModels.fromMatrix,8,9,22,12,54.54545454545454,0,0
@@ edu.stanford.nlp.neural.ConvertModels.fromTensor,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.neural.ConvertModels.toMatrix,17,22,43,25,58.139534883720934,0,0
@@ edu.stanford.nlp.neural.ConvertModels.toTensor,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.neural.ConvertModels.transformMap,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.neural.ConvertModels.writeFastCoref,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.neural.ConvertModels.readFastCoref,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.neural.ConvertModels.main,30,42,74,74,100.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.loadTextMatrices,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.convertTextMatrix,10,12,30,17,56.666666666666664,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.dot,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.vectorToParams,13,16,21,12,57.14285714285714,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.paramsToVector,13,16,25,14,56.00000000000001,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.paramsToVector,13,16,26,15,57.692307692307686,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.softmax,8,9,20,10,50.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.elementwiseApplyReLU,8,9,20,10,50.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.elementwiseApplyLog,8,9,20,10,50.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.elementwiseApplyTanh,8,9,20,10,50.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.concatenateWithBias,8,9,11,5,45.45454545454545,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.concatenate,8,9,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.randomGaussian,8,9,21,11,52.38095238095239,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.isZero,7,8,14,7,50.0,0,0
@@ edu.stanford.nlp.neural.NeuralUtils.lambda$convertTextMatrix$0,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.getNodeVector,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.getPredictions,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.getPredictionsAsStringList,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.getPredictedClass,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.getPredictedClassProb,6,7,7,7,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.getGoldClass,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.setGoldClass,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.getPredictionError,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.RNNCoreAnnotations.setPredictionError,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.neural.rnn.TopNGramRecord.<init>,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.neural.rnn.TopNGramRecord.countTree,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.neural.rnn.TopNGramRecord.simplifyTree,7,8,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.neural.rnn.TopNGramRecord.countTreeHelper,14,19,42,31,73.80952380952381,0,0
@@ edu.stanford.nlp.neural.rnn.TopNGramRecord.getPriorityQueue,4,4,8,8,100.0,0,1
@@ edu.stanford.nlp.neural.rnn.TopNGramRecord.toString,11,13,30,17,56.666666666666664,0,0
@@ edu.stanford.nlp.neural.rnn.TopNGramRecord.lambda$scoreComparator$0,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.paragraphs.ParagraphAnnotator.annotate,21,28,52,36,69.23076923076923,0,0
@@ edu.stanford.nlp.paragraphs.RunParagraphAnnotator.runTest,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.tagger.util.CountClosedTags.<init>,8,9,12,12,100.0,0,1
@@ edu.stanford.nlp.tagger.util.CountClosedTags.countSentences,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.tagger.util.CountClosedTags.addTaggedWords,10,13,19,19,100.0,0,1
@@ edu.stanford.nlp.tagger.util.CountClosedTags.countTrainingTags,8,10,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.tagger.util.CountClosedTags.countTestTags,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.util.CountClosedTags.report,29,40,74,65,87.83783783783784,0,0
@@ edu.stanford.nlp.tagger.util.CountClosedTags.help,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.util.CountClosedTags.checkArgs,9,11,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.util.CountClosedTags.main,9,11,7,7,100.0,0,0
@@ edu.stanford.nlp.tagger.util.MakePrefixFile.main,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.util.ConvertTreesToTags.main,52,81,218,69,31.65137614678899,0,1
@@ edu.stanford.nlp.tagger.io.TSVTaggedFileReader.<init>,8,9,15,15,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TSVTaggedFileReader.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TSVTaggedFileReader.next,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.tagger.io.TSVTaggedFileReader.primeNext,18,27,72,36,50.0,0,0
@@ edu.stanford.nlp.tagger.io.TaggedFileRecord.toString,18,25,55,55,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TaggedFileRecord.reader,6,8,17,17,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TaggedFileRecord.createRecords,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TaggedFileRecord.createRecord,32,45,68,46,67.64705882352942,0,0
@@ edu.stanford.nlp.tagger.io.TaggedFileRecord.getEncoding,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TaggedFileRecord.getTagSeparator,4,4,3,3,100.0,0,1
@@ edu.stanford.nlp.tagger.io.TreeTaggedFileReader.<init>,8,9,25,25,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TreeTaggedFileReader.hasNext,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.tagger.io.TreeTaggedFileReader.next,8,10,25,20,80.0,0,0
@@ edu.stanford.nlp.tagger.io.TextTaggedFileReader.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TextTaggedFileReader.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.io.TextTaggedFileReader.primeNext,9,11,22,22,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorUpperDigitDash.extract,6,8,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.AmbiguityClasses.add,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.AmbiguityClasses.getClass,9,11,16,16,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TemplateHash.add,10,12,42,34,80.95238095238095,0,0
@@ edu.stanford.nlp.tagger.maxent.TemplateHash.addPrev,8,9,31,23,74.19354838709677,0,0
@@ edu.stanford.nlp.tagger.maxent.TemplateHash.getXValues,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ReadDataTagged.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ReadDataTagged.loadFile,26,35,117,65,55.55555555555556,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerFeature.getVal,9,11,20,13,65.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerFeature.ftilde,5,5,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorSpanishAuxiliaryTag.extract,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TemplateHash$ListInstances.getInstances,5,5,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.tagger.maxent.TestThreadedTagger.compareResults,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestThreadedTagger.runThreadedTest,33,44,81,54,66.66666666666666,0,1
@@ edu.stanford.nlp.tagger.maxent.LambdaSolveTagger.initCondsZlambdaEtc,16,20,86,61,70.93023255813954,0,0
@@ edu.stanford.nlp.tagger.maxent.LambdaSolveTagger.g,5,5,27,20,74.07407407407408,0,0
@@ edu.stanford.nlp.tagger.maxent.LambdaSolveTagger.fExpected,5,5,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.tagger.maxent.LambdaSolveTagger.checkCorrectness,23,30,118,74,62.71186440677966,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorDistsimConjunction.extract,7,8,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger$TaggerWrapper.<init>,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger$TaggerWrapper.apply,19,24,55,46,83.63636363636363,0,1
@@ edu.stanford.nlp.tagger.maxent.Extractor.leftContext,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractor.rightContext,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractor.isLocal,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractor.extract,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractor.extractLV,9,11,20,12,60.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractor.extractLV,10,13,28,17,60.71428571428571,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractor.toString,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractor.getParenthesizedArg,8,11,19,19,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.ExtractorWordSuff.extract,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorWordSuff.isLocal,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestClassifier.<init>,7,9,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.tagger.maxent.TestClassifier.processResults,10,13,42,42,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestClassifier.test,28,38,75,45,60.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestClassifier.resultsString,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTaggerServer$Session.run,10,13,29,29,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.<init>,11,15,22,22,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.setCorrectTags,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.tagSentence,22,29,58,54,93.10344827586206,0,1
@@ edu.stanford.nlp.tagger.maxent.TestSentence.init,7,8,25,16,64.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getTaggedNice,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getTaggedSentence,12,16,37,30,81.08108108108108,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.toNice,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.calculateProbs,17,21,68,46,67.64705882352942,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.writeTagsAndErrors,25,35,100,74,74.0,0,1
@@ edu.stanford.nlp.tagger.maxent.TestSentence.updateConfusionMatrix,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.runTagInference,9,11,17,13,76.47058823529412,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.setHistory,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.initializeScorer,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getScores,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getExactScores,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getHistories,40,54,107,98,91.58878504672897,0,1
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getHistories,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getExactHistories,11,14,24,24,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.runExactExtractor,9,12,35,26,74.28571428571429,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getApproximateHistories,11,14,26,26,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.TestSentence.runApproximateExtractor,10,13,36,27,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.printUnknown,22,30,79,42,53.16455696202531,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.printTop,20,27,66,35,53.03030303030303,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getTop3,14,18,58,32,55.172413793103445,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.getPossibleValues,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.scoreOf,7,8,21,9,42.857142857142854,0,0
@@ edu.stanford.nlp.tagger.maxent.TestSentence.stringTagsAt,12,17,44,42,95.45454545454545,0,1
@@ edu.stanford.nlp.tagger.maxent.ExtractorDash.extract,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorLetterDashDigit.extract,17,24,32,15,46.875,0,0
@@ edu.stanford.nlp.tagger.maxent.CTBunkDict.getInstance,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CTBunkDict.readCTBunkDict,7,8,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.CTBunkDict.getTag,5,6,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.<init>,11,15,20,14,70.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.setProperties,32,49,69,69,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.getOutputOptionsContains,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.wsvStringToStringArray,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.getTagInside,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.getTokenizerInvertible,9,12,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.getDefaultScore,11,14,9,9,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.dump,9,12,24,24,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.getSentenceDelimiter,5,6,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerConfig.getMode,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerExperiments.<init>,8,10,30,26,86.66666666666667,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerExperiments.add,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerExperiments.getFeaturesNew,62,88,321,236,73.5202492211838,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerExperiments.hashHistories,20,25,76,56,73.68421052631578,0,1
@@ edu.stanford.nlp.tagger.maxent.TaggerExperiments.isPopulated,15,19,26,26,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TaggerExperiments.addTemplatesNew,10,12,38,27,71.05263157894737,0,1
@@ edu.stanford.nlp.tagger.maxent.TaggerExperiments.addRareTemplatesNew,12,15,51,40,78.43137254901961,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorWordShapeConjunction.extract,7,8,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTaggerGUI$1.run,5,5,8,6,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorWordTwoTags.<init>,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorWordTwoTags.leftContext,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorWordTwoTags.rightContext,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.getNaaclExtractors,8,9,14,6,42.857142857142854,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.getCaselessNaaclExtractors,8,9,14,6,42.857142857142854,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.getExtractorFramesRare,77,109,164,128,78.04878048780488,0,1
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.lcTagFeatures,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.ctbPreFeatures,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.ctbSufFeatures,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.asbcUnkFeatures,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFramesRare.ctbUnkDictFeatures,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorUCase.extract,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CtbDict.getInstance,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CtbDict.readCtbDict,9,11,23,21,91.30434782608695,0,0
@@ edu.stanford.nlp.tagger.maxent.CtbDict.getTagPre,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CtbDict.getTagSuf,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorNonAlphanumeric.extract,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorMidSentenceCap.extract,7,9,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CtbSufDetector.extract,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorSpanishSemiauxiliaryTag.extract,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorCapC.extract,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames.getExtractorFrames,97,149,209,154,73.68421052631578,0,1
@@ edu.stanford.nlp.tagger.maxent.ExtractorVerbalVBNZero.precondition,12,17,14,14,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorVerbalVBNZero.extract,20,29,47,36,76.59574468085107,0,0
@@ edu.stanford.nlp.tagger.maxent.CWordBooleanExtractor.extract,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ASBCunkDetector.extract,4,4,10,10,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.TTags.<init>,23,32,40,40,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.TTags.getOpenTags,9,11,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.tagger.maxent.TTags.getOpenTagsArray,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.tagger.maxent.TTags.save,8,10,18,18,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TTags.read,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TTags.isClosed,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.TTags.markClosed,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TTags.setOpenClassTags,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TTags.setClosedClassTags,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TTags.deterministicallyExpandTags,40,65,84,19,22.61904761904762,0,1
@@ edu.stanford.nlp.tagger.maxent.TTags.toString,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CTBunkDictDetector.extract,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorCapDistLC.extract,19,26,49,34,69.38775510204081,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorsConjunction.<init>,10,13,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorsConjunction.extract,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorTwoWords.<init>,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorStartSentenceCap.extract,9,12,18,18,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractors.initTypes,13,17,37,26,70.27027027027027,0,1
@@ edu.stanford.nlp.tagger.maxent.Extractors.equals,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractors.leftContext,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractors.rightContext,7,8,9,4,44.44444444444444,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractors.setGlobalHolder,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Extractors.toString,7,8,25,16,64.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CountWrapper.<init>,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CountWrapper.equals,6,7,9,9,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.CountWrapper.read,7,9,17,17,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ASBCunkDict.getInstance,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ASBCunkDict.readASBCunkDict,7,8,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.ASBCunkDict.getTag,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorWordPref.extract,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorWordPref.isLocal,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorCWordCapCase.extract,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorSpanishGender.extract,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTaggerServer$TaggerClient.communicateWithMaxentTaggerServer,11,14,22,20,90.9090909090909,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorSymbols.extract,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorLetterDigitDash.extract,6,8,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.fillWordTagCounts,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.addVThatTaking,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getCountPart,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getCountThat,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getCountIn,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getCountRB,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getCount,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getTags,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getFirstTag,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.sum,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.isUnknown,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.save,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.readTags,7,8,21,14,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.readVerbs,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.tagger.maxent.Dictionary.setAmbClasses,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.Dictionary.getAmbClass,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CaselessCompanyNameDetector.<init>,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CaselessCompanyNameDetector.extract,7,8,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.tagger.maxent.AmbiguityClass.<init>,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.AmbiguityClass.add,9,11,38,26,68.42105263157895,0,0
@@ edu.stanford.nlp.tagger.maxent.AmbiguityClass.toString,7,8,10,10,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.AmbiguityClass.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorContinuousTagConjunction.extract,14,18,45,29,64.44444444444444,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorContinuousTagConjunction.toString,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorWordShapeClassifier.isLocal,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorThreeTags.<init>,8,10,40,10,25.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorThreeTags.rightContext,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorFrames$ExtractorThreeTags.leftContext,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.ExtractorCapLCSeen.extract,6,7,18,18,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.History.getX,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.tagger.maxent.History.toString,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.History.hashCode,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.tagger.maxent.History.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.FeatureKey.hashCode,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.tagger.maxent.FeatureKey.equals,10,14,29,29,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TagCount.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TagCount.save,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TagCount.readTagCount,8,9,20,14,70.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TagCount.get,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TagCount.calculateSumCache,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.tagger.maxent.TagCount.getFirstTag,7,8,12,7,58.333333333333336,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.startsUpperCase,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.startsLowerCase,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.containsDash,6,7,4,4,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.containsNumber,9,11,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.allNumeric,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.allSymbols,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.containsLetter,9,11,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.containsAlphanumeric,10,13,23,13,56.52173913043478,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.containsUpperCase,9,11,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.allUpperCase,9,11,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.tagger.maxent.RareExtractor.noneLowerCase,9,11,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorMidSentenceCapC.extract,9,12,18,18,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorCNumber.extract,4,4,2,2,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.ExtractorAllCapitalized.extract,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorDistsim.isLocal,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.PairsHolder.getWord,6,7,15,15,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.PairsHolder.getTag,6,7,15,15,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.PluralAcronymDetector.pluralAcronym,9,11,18,11,61.111111111111114,0,1
@@ edu.stanford.nlp.tagger.maxent.PluralAcronymDetector.extract,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.init,33,51,83,57,68.67469879518072,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.initDefaultScores,6,7,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.getInactiveTagDefaultScore,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.hasApproximateScoring,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.chooseTokenizerFactory,13,18,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.readExtractors,6,7,18,16,88.88888888888889,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.removeDeadRules,19,25,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.simplifyLambda,24,31,67,32,47.76119402985074,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.saveModel,24,31,47,30,63.829787234042556,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.readModelAndInit,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.readModelAndInit,46,65,170,134,78.82352941176471,0,1
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.dumpModel,16,20,53,39,73.58490566037736,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.isRare,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.process,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.tagCoreLabels,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.lemmatize,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.castCoreLabels,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.tokenizeText,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.runTest,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.trainAndSaveModel,14,18,27,27,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.getXMLWords,19,27,32,30,93.75,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.getTsvWords,18,25,27,27,100.0,0,1
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.tagFromXML,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.tagFromXML,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.tagFromXML,5,5,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.runTagger,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.runTagger,15,20,49,38,77.55102040816327,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.runTaggerStdin,21,30,58,49,84.48275862068965,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.runTaggerSGML,14,19,36,32,88.88888888888889,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.runTagger,25,34,75,61,81.33333333333333,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.runTagger,10,13,25,19,76.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.tagCoreLabelsOrHasWords,9,12,16,15,93.75,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.outputTaggedSentence,7,9,22,22,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.MaxentTagger.main,11,14,21,21,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.Distsim.<init>,15,19,42,23,54.761904761904766,0,0
@@ edu.stanford.nlp.tagger.maxent.Distsim.initLexicon,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.tagger.maxent.Distsim.getMapping,10,14,32,22,68.75,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorNumeric.extract,5,6,4,4,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CtbPreDetector.extract,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.CompanyNameDetector.extract,9,11,16,11,68.75,0,0
@@ edu.stanford.nlp.tagger.maxent.ExtractorAllCap.extract,4,4,2,2,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.documentation.TaggerDemo2.main,12,15,13,13,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.documentation.MulticoreWrapperDemo.main,12,15,19,19,100.0,0,0
@@ edu.stanford.nlp.tagger.maxent.documentation.TaggerDemo.main,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.logNormalizeInPlace,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.max,7,8,8,5,62.5,0,0
@@ edu.stanford.nlp.stats.Counters.asCounter,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.min,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.stats.Counters.argmin,8,10,15,5,33.33333333333333,0,0
@@ edu.stanford.nlp.stats.Counters.argmax,14,20,33,15,45.45454545454545,0,1
@@ edu.stanford.nlp.stats.Counters.argmin,10,14,29,11,37.93103448275862,0,0
@@ edu.stanford.nlp.stats.Counters.standardDeviation,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,7,8,5,5,100.0,0,1
@@ edu.stanford.nlp.stats.Counters.addInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.addInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.subtractInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.subtractInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.divideInPlace,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.stats.Counters.dotProductInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.divideInPlace,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.multiplyInPlace,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.multiplyInPlace,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.logInPlace,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.deleteOutofRange,10,12,30,22,73.33333333333333,0,0
@@ edu.stanford.nlp.stats.Counters.retainTop,7,8,13,9,69.23076923076923,0,1
@@ edu.stanford.nlp.stats.Counters.retainTopKeyComparable,7,8,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.stats.Counters.retainBottom,7,8,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.stats.Counters.retainNonZeros,10,12,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.retainAbove,10,12,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.retainAbove,13,16,14,14,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.retainBelow,10,12,13,13,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.retainMatchingKeys,15,19,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.stats.Counters.retainKeys,10,12,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.removeKeys,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.removeKeys,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.keysAbove,7,8,9,9,100.0,0,1
@@ edu.stanford.nlp.stats.Counters.keysBelow,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.keysAt,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.transform,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.transformWithValuesAdd,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toSortedList,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toRankCounter,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.stats.Counters.toTiedRankCounter,21,28,63,38,60.317460317460316,0,0
@@ edu.stanford.nlp.stats.Counters.toDescendingMagnitudeSortedListWithCounts,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toSortedListWithCounts,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toSortedListWithCounts,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toPriorityQueue,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.intersection,10,12,14,14,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.jaccardCoefficient,11,13,20,14,70.0,0,0
@@ edu.stanford.nlp.stats.Counters.product,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.dotProduct,16,23,41,25,60.97560975609756,0,0
@@ edu.stanford.nlp.stats.Counters.dotProduct,7,8,10,7,70.0,0,0
@@ edu.stanford.nlp.stats.Counters.sumEntries,5,5,5,2,40.0,0,1
@@ edu.stanford.nlp.stats.Counters.add,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.add,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.add,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.optimizedDotProduct,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.getDotProd,8,10,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.stats.Counters.absoluteDifference,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.division,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.divisionNonNaN,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.entropy,7,8,10,7,70.0,0,0
@@ edu.stanford.nlp.stats.Counters.crossEntropy,9,11,15,12,80.0,0,0
@@ edu.stanford.nlp.stats.Counters.klDivergence,9,11,17,14,82.35294117647058,0,0
@@ edu.stanford.nlp.stats.Counters.sumSquares,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.stats.Counters.L1Norm,7,8,8,5,62.5,0,0
@@ edu.stanford.nlp.stats.Counters.saferL2Norm,10,12,18,8,44.44444444444444,0,0
@@ edu.stanford.nlp.stats.Counters.cosine,16,22,35,18,51.42857142857142,0,0
@@ edu.stanford.nlp.stats.Counters.average,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.linearCombination,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.hIndex,13,16,16,12,75.0,0,1
@@ edu.stanford.nlp.stats.Counters.perturbCounts,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.printCounterComparison,14,18,28,28,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.getCountCounts,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.scale,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.tfLogScale,7,8,10,9,90.0,0,0
@@ edu.stanford.nlp.stats.Counters.printCounterSortedByKeys,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.loadIntoCounter,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.saveCounter,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.loadInto2DCounter,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.loadIncInto2DCounter,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.save2DCounter,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.save2DCounterSorted,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.serializeStringCounter,10,12,15,15,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.deserializeStringCounter,9,11,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toSortedString,6,7,17,13,76.47058823529412,0,1
@@ edu.stanford.nlp.stats.Counters.toSortedByKeysString,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toString,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toString,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toBiggestValuesFirstString,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toBiggestValuesFirstString,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.toVerticalString,11,14,26,22,84.61538461538461,0,0
@@ edu.stanford.nlp.stats.Counters.restrictedArgMax,7,8,11,6,54.54545454545454,0,0
@@ edu.stanford.nlp.stats.Counters.toCounter,9,11,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.stats.Counters.toCounter,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.asArray,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.asArray,5,5,5,4,80.0,0,0
@@ edu.stanford.nlp.stats.Counters.scale,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.sample,9,11,15,13,86.66666666666667,0,0
@@ edu.stanford.nlp.stats.Counters.powNormalized,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.pow,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.powInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.exp,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.expInPlace,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.diff,5,5,4,4,100.0,0,1
@@ edu.stanford.nlp.stats.Counters.equals,13,17,23,23,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.asCounter,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.fromMap,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.fromMap,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.stats.Counters.isUniformDistribution,12,15,22,10,45.45454545454545,0,0
@@ edu.stanford.nlp.stats.Counters.maxInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.minInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.retainTopMass,6,7,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.stats.Counters.divideInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.ensureKeys,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.topKeys,6,7,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.stats.Counters.topKeysWithCounts,6,7,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.stats.Counters.getFCounter,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.transformValuesInPlace,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.getCounts,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.retainKeys,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.flatten,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.isFinite,8,10,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.lambda$toComparator$4,8,10,18,18,100.0,0,0
@@ edu.stanford.nlp.stats.Counters.lambda$toComparatorWithKeys$2,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution$DynamicDistribution.sampleFrom,7,8,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.stats.MultiClassChunkEvalStats.getTypeLabel,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassChunkEvalStats.markBoundary,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassChunkEvalStats.addGuess,27,42,91,90,98.9010989010989,0,0
@@ edu.stanford.nlp.stats.MultiClassChunkEvalStats.main,11,13,26,18,69.23076923076923,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.score,5,5,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.clearCounts,17,22,40,40,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.finalizeCounts,14,20,55,45,81.81818181818183,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.addGuess,14,19,44,43,97.72727272727273,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.addGuesses,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.score,11,14,24,24,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.getConllEvalString,5,6,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallExtendedStats.getConllEvalString,8,10,12,12,100.0,0,1
@@ edu.stanford.nlp.stats.Dirichlet.checkParameters,9,11,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.Dirichlet.drawSample,8,9,10,7,70.0,0,0
@@ edu.stanford.nlp.stats.Dirichlet.drawSample,8,9,25,14,56.00000000000001,0,0
@@ edu.stanford.nlp.stats.Dirichlet.unnormalizedLogProbabilityOf,7,8,22,9,40.909090909090914,0,0
@@ edu.stanford.nlp.stats.Counters$NaturalComparator.compare,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$FunctionDataSeries.get,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.AccuracyStats.score,8,9,24,19,79.16666666666666,0,0
@@ edu.stanford.nlp.stats.AccuracyStats.getDescription,4,4,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.AccuracyStats.toStringArr,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.stats.DataSeries$ArrayDataSeries.setData,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$ArrayDataSeries.get,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$ArrayDataSeries.set,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter$NaturalComparator.compare,4,4,4,4,100.0,0,1
@@ edu.stanford.nlp.stats.EquivalenceClassEval.eval,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval.evalPrecision,12,15,42,32,76.19047619047619,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval.removeItem,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval.lastF1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval.f1,6,7,6,6,100.0,0,1
@@ edu.stanford.nlp.stats.EquivalenceClassEval.f1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval.percentage,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval.displayHelper,11,13,23,23,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval.getPads,19,24,31,19,61.29032258064516,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval$Eval.eval,8,9,20,20,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval$Eval.evalPrecision,10,12,37,21,56.75675675675676,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval$Eval.evalRecall,7,8,12,6,50.0,0,0
@@ edu.stanford.nlp.stats.Gamma.drawSample,16,22,35,35,100.0,0,0
@@ edu.stanford.nlp.stats.Gamma.equals,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$AverageDataSeries.<init>,10,13,24,17,70.83333333333334,0,0
@@ edu.stanford.nlp.stats.DataSeries$AverageDataSeries.name,8,9,8,5,62.5,0,1
@@ edu.stanford.nlp.stats.DataSeries$AverageDataSeries.get,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.stats.DataSeries$AverageDataSeries.size,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$AverageDataSeries.domain,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Distributions.getSetOfAllKeys,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.Distributions.overlap,5,5,14,5,35.714285714285715,0,0
@@ edu.stanford.nlp.stats.Distributions.weightedAverage,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.stats.Distributions.klDivergence,14,19,56,33,58.92857142857143,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$CounterView.getCount,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$CounterView.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$CounterView.hashCode,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$CounterView.toString,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallStats.score,18,24,76,63,82.89473684210526,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallStats.getPrecisionInfo,5,6,20,20,100.0,0,1
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallStats.getPrecisionInfo,8,9,31,15,48.38709677419355,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallStats.getRecallInfo,5,6,20,20,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallStats.getRecallInfo,8,9,31,15,48.38709677419355,0,0
@@ edu.stanford.nlp.stats.MultiClassPrecisionRecallStats.getDescription,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.stats.Counters$2$1$1$1.setValue,13,17,77,72,93.5064935064935,0,0
@@ edu.stanford.nlp.stats.PrecisionRecallStats.<init>,14,20,34,26,76.47058823529412,0,0
@@ edu.stanford.nlp.stats.PrecisionRecallStats.getPrecision,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.PrecisionRecallStats.getRecall,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.PrecisionRecallStats.getFMeasure,5,6,7,7,100.0,0,1
@@ edu.stanford.nlp.stats.Counters$2.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Counters$2.getCount,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Counters$2.remove,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.stats.Counters$2.setCount,28,37,73,58,79.45205479452055,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.entrySet,17,22,37,37,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.lowestLevelCounterEntrySet,17,22,34,34,100.0,0,1
@@ edu.stanford.nlp.stats.GeneralizedCounter.totalCount,7,8,10,7,70.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.keySet,17,22,33,33,100.0,0,1
@@ edu.stanford.nlp.stats.GeneralizedCounter.getCount,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.getCount,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.getCount,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.getCounts,7,8,27,20,74.07407407407408,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.conditionalizeHelper,6,7,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.conditionalize,7,8,12,9,75.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.conditionalizeOnce,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.incrementCount,7,8,16,13,81.25,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.incrementCount,7,8,22,16,72.72727272727273,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.incrementCount2D,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.incrementCount3D,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.incrementCount1D,8,10,27,24,88.88888888888889,0,1
@@ edu.stanford.nlp.stats.GeneralizedCounter.containsKey,7,8,20,10,50.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.reverseKeys,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.oneDimensionalCounterView,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.toString,16,23,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.printKeySet,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.arrayPrintDouble,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter.prettyPrint,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.getCounter,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.size,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.containsKey,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.remove,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.getCount,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.setCounter,5,5,14,14,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.reverseIndexOrder,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.toString,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.toMatrix,8,9,23,13,56.52173913043478,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.toCSVString,11,13,30,22,73.33333333333333,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.secondKeySet,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.flatten,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.addAll,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.subtractAll,7,8,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.sumInnerCounter,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.removeZeroCounts,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.remove,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.clean,12,15,13,13,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalCounter.recomputeTotal,5,5,3,2,66.66666666666666,0,0
@@ edu.stanford.nlp.stats.IntCounter.totalIntCount,7,8,10,7,70.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.getIntCount,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.setCount,6,7,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.stats.IntCounter.setCounts,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.incrementCount,6,7,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.stats.IntCounter.incrementCounts,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.addAll,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.subtractAll,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.remove,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.removeAll,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.isEmpty,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.toString,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.toString,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.max,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.min,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.argmax,10,14,29,11,37.93103448275862,0,0
@@ edu.stanford.nlp.stats.IntCounter.argmin,10,14,29,11,37.93103448275862,0,0
@@ edu.stanford.nlp.stats.IntCounter.keysAbove,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.keysBelow,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.keysAt,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.IntCounter.lambda$removeZeroCounts$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$Entry.equals,12,17,28,28,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$Entry.hashCode,5,6,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.getDistributionFromPartiallySpecifiedCounter,5,5,9,7,77.77777777777779,0,0
@@ edu.stanford.nlp.stats.Distribution.getUniformDistribution,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.getPerturbedUniformDistribution,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.getPerturbedDistribution,7,8,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.stats.Distribution.getDistributionWithReservedMass,7,8,9,7,77.77777777777779,0,1
@@ edu.stanford.nlp.stats.Distribution.getDistributionFromLogValues,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.absolutelyDiscountedDistribution,8,9,24,15,62.5,0,0
@@ edu.stanford.nlp.stats.Distribution.laplaceSmoothedDistribution,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.laplaceWithExplicitUnknown,8,9,16,16,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.goodTuringSmoothedCounter,16,20,47,33,70.2127659574468,0,0
@@ edu.stanford.nlp.stats.Distribution.goodTuringWithExplicitUnknown,16,20,44,28,63.63636363636363,0,0
@@ edu.stanford.nlp.stats.Distribution.getCountCounts,10,12,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.stats.Distribution.simpleGoodTuring,10,12,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.stats.Distribution.validateCounter,9,11,7,7,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.collectCountCounts,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.countCounts2IntArrays,5,5,8,7,87.5,0,0
@@ edu.stanford.nlp.stats.Distribution.distributionWithDirichletPrior,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.dynamicCounterWithDirichletPrior,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.distributionFromLogisticCounter,8,9,14,8,57.14285714285714,0,0
@@ edu.stanford.nlp.stats.Distribution.probabilityOf,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.addToKeySet,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.equals,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.equals,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.stats.Distribution.toString,7,8,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.stats.Distribution.main,11,13,39,27,69.23076923076923,0,0
@@ edu.stanford.nlp.stats.Distribution.lambda$toString$0,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.equals,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.getCounter,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.size,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.containsKey,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.remove,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.getCount,5,6,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.totalCounts,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.reverseIndexOrder,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.toString,8,9,5,5,100.0,0,1
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.toMatrix,8,9,23,13,56.52173913043478,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.toCSVString,11,13,30,22,73.33333333333333,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.toCSVString,11,13,30,22,73.33333333333333,0,1
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.secondKeySet,8,9,3,3,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.flatten,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.addAll,5,5,4,3,75.0,0,1
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.subtractAll,7,8,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.removeZeroCounts,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.remove,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.TwoDimensionalIntCounter.clean,12,15,13,13,100.0,0,0
@@ edu.stanford.nlp.stats.EquivalenceClassEval$Eval$CollectionContainsChecker.contained,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassAccuracyStats.score,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassAccuracyStats.confidenceWeightedAccuracy,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.stats.MultiClassAccuracyStats.initMC,13,16,50,34,68.0,0,0
@@ edu.stanford.nlp.stats.MultiClassAccuracyStats.numCorrect,7,8,24,13,54.166666666666664,0,0
@@ edu.stanford.nlp.stats.MultiClassAccuracyStats.getAccCoverage,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.stats.MultiClassAccuracyStats.getDescription,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.stats.MultiClassAccuracyStats.toString,7,8,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.stats.DataSeries$ListDataSeries.setData,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$ListDataSeries.get,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$ListDataSeries.set,5,6,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$ListDataSeries.readDataSeries,26,35,71,44,61.97183098591549,0,0
@@ edu.stanford.nlp.stats.DataSeries$ListDataSeries.main,8,9,8,6,75.0,0,0
@@ edu.stanford.nlp.stats.DataSeries$ListDataSeries.demo1,5,5,10,6,60.0,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.<init>,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.getCount,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.setCount,6,7,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.incrementCount,6,7,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.logIncrementCount,7,8,25,20,80.0,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.remove,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.mutableRemove,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.removeAll,5,5,1,1,100.0,0,1
@@ edu.stanford.nlp.stats.ClassicCounter.isEmpty,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.stats.ClassicCounter.equals,12,16,27,27,100.0,0,1
@@ edu.stanford.nlp.stats.ClassicCounter.valueOfIgnoreComments,10,12,8,8,100.0,0,1
@@ edu.stanford.nlp.stats.ClassicCounter.fromString,10,13,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.DirichletProcess.drawSample,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.stats.DirichletProcess.numOccurances,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.DirichletProcess.probabilityOf,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.stats.SimpleGoodTuring.<init>,10,13,13,13,100.0,0,0
@@ edu.stanford.nlp.stats.SimpleGoodTuring.compute,34,45,165,97,58.78787878787879,0,0
@@ edu.stanford.nlp.stats.SimpleGoodTuring.row,10,13,40,23,57.49999999999999,0,0
@@ edu.stanford.nlp.stats.SimpleGoodTuring.findBestFit,8,9,49,29,59.183673469387756,0,1
@@ edu.stanford.nlp.stats.SimpleGoodTuring.print,5,5,16,12,75.0,0,0
@@ edu.stanford.nlp.stats.SimpleGoodTuring.validate,7,8,23,14,60.86956521739131,0,0
@@ edu.stanford.nlp.stats.SimpleGoodTuring.readInput,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.stats.SimpleGoodTuring.integerList2IntArray,5,5,4,3,75.0,0,0
@@ edu.stanford.nlp.stats.Multinomial.<init>,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.stats.Multinomial.probabilityOf,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Multinomial.logProbabilityOf,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.Multinomial.drawSample,7,8,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.stats.Multinomial.equals,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.stats.Multinomial.hashCode,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.stats.DataSeries$AbstractDataSeries.toListPairDouble,8,9,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.stats.ClassicCounter$1.contains,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$OneDimensionalCounterView.equals,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$OneDimensionalCounterView.hashCode,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.stats.GeneralizedCounter$OneDimensionalCounterView.toString,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.international.Language.compatibleWith,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.international.german.scripts.GermanTreebankTokenReport.main,18,23,22,17,77.27272727272727,0,0
@@ edu.stanford.nlp.international.german.scripts.GermanTreebankUDUpdater.splitHyphenatedToken,11,14,43,23,53.48837209302325,0,0
@@ edu.stanford.nlp.international.german.scripts.GermanTreebankUDUpdater.main,17,22,46,28,60.86956521739131,0,0
@@ edu.stanford.nlp.international.german.process.GermanTokenizerPostProcessor.condenseUmlauts,6,7,9,9,100.0,0,0
@@ edu.stanford.nlp.international.german.process.GermanTokenizerPostProcessor.condenseUmlauts,29,40,66,24,36.36363636363637,0,0
@@ edu.stanford.nlp.international.german.process.GermanTokenizerPostProcessor.process,37,56,82,61,74.39024390243902,0,0
@@ edu.stanford.nlp.international.german.process.GermanTokenizerPostProcessor.lambda$new$0,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.international.morph.AddMorphoAnnotations.main,30,44,70,61,87.14285714285714,0,0
@@ edu.stanford.nlp.international.morph.AddMorphoAnnotations$YieldIterator.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.international.morph.AddMorphoAnnotations$YieldIterator.primeNext,12,15,20,20,100.0,0,0
@@ edu.stanford.nlp.international.morph.AddMorphoAnnotations$YieldIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.morph.AddMorphoAnnotations$YieldIterator.next,8,10,18,18,100.0,0,0
@@ edu.stanford.nlp.international.morph.MorphoFeatureSpecification.splitMorphString,7,9,10,10,100.0,0,0
@@ edu.stanford.nlp.international.morph.MorphoFeatures.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.international.morph.MorphoFeatures.getValue,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.international.morph.MorphoFeatures.numFeatureMatches,8,10,12,9,75.0,0,0
@@ edu.stanford.nlp.international.morph.MorphoFeatures.fromTagString,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.international.morph.MorphoFeatures.toString,7,8,11,11,100.0,0,1
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.nounSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.adjSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.hasDigit,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.isDigit,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.verbSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.possiblePlural,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.advSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.hasPunc,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.isPunc,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.isAllCaps,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchUnknownWordSignatures.isCapitalized,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.international.french.FrenchMorphoFeatureSpecification.getValues,8,10,16,16,100.0,0,1
@@ edu.stanford.nlp.international.french.FrenchMorphoFeatureSpecification.strToFeatures,93,141,180,180,100.0,0,1
@@ edu.stanford.nlp.international.french.FrenchMorphoFeatureSpecification.addPhiFeatures,24,36,57,55,96.49122807017544,0,0
@@ edu.stanford.nlp.international.french.FrenchMorphoFeatureSpecification.main,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.MWEPreprocessor$ManualUWModel.getTag,10,13,17,17,100.0,0,1
@@ edu.stanford.nlp.international.french.pipeline.MWEPreprocessor.printCounter,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.MWEPreprocessor.updateTagger,7,8,4,4,100.0,0,1
@@ edu.stanford.nlp.international.french.pipeline.MWEPreprocessor.traverseAndFix,19,25,31,31,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.MWEPreprocessor.resolveDummyTags,5,5,14,11,78.57142857142857,0,0
@@ edu.stanford.nlp.international.french.pipeline.MWEPreprocessor.countMWEStatistics,7,8,11,11,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.MWEPreprocessor.main,7,8,23,23,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.FTBDataset.getCanditoTreeID,7,9,11,11,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.FTBDataset.build,34,47,71,67,94.36619718309859,0,1
@@ edu.stanford.nlp.international.french.pipeline.FTBDataset.preprocessMWEs,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.FTBDataset.setOptions,12,16,27,25,92.5925925925926,0,0
@@ edu.stanford.nlp.international.french.pipeline.FTBDataset.makeSplitSet,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.FTBCorrector.loadOps,10,12,16,16,100.0,0,1
@@ edu.stanford.nlp.international.french.pipeline.FTBCorrector.continuing,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.pipeline.FTBCorrector.main,11,14,25,22,88.0,0,0
@@ edu.stanford.nlp.international.french.scripts.MWEFrequencyDist.main,21,27,48,39,81.25,0,1
@@ edu.stanford.nlp.international.french.scripts.FrenchTreebankUDUpdater.fixNPWithHyphen,13,19,58,28,48.275862068965516,0,0
@@ edu.stanford.nlp.international.french.scripts.FrenchTreebankUDUpdater.fixMWNWithHyphen,14,19,52,30,57.692307692307686,0,1
@@ edu.stanford.nlp.international.french.scripts.FrenchTreebankUDUpdater.fixPREFEndingWithHyphen,18,26,71,31,43.66197183098591,0,1
@@ edu.stanford.nlp.international.french.scripts.FrenchTreebankUDUpdater.main,54,80,187,110,58.82352941176471,0,0
@@ edu.stanford.nlp.international.french.scripts.FrenchTreebankTokenReport.main,17,21,20,15,75.0,0,1
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.readIds,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.readTrees,8,9,15,12,80.0,0,0
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.preprocessMWEs,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.mungeLeaves,23,32,40,23,57.49999999999999,0,0
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.replacePOSTags,17,25,44,33,75.0,0,1
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.outputSplits,14,19,43,33,76.74418604651163,0,0
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.treeToMorfette,14,20,37,29,78.37837837837837,0,0
@@ edu.stanford.nlp.international.french.scripts.SplitCanditoTrees.main,9,11,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.international.french.scripts.MungeTreesWithMorfetteAnalyses$MorfetteFileIterator.primeNext,11,14,31,26,83.87096774193549,0,0
@@ edu.stanford.nlp.international.french.scripts.MungeTreesWithMorfetteAnalyses$MorfetteFileIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.scripts.MungeTreesWithMorfetteAnalyses$MorfetteFileIterator.next,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.international.french.scripts.MungeTreesWithMorfetteAnalyses.main,17,24,36,32,88.88888888888889,0,0
@@ edu.stanford.nlp.international.french.scripts.MungeTreesWithMorfetteAnalyses.getLemma,14,21,22,21,95.45454545454545,0,0
@@ edu.stanford.nlp.international.french.scripts.TreeToMorfette.main,14,19,35,27,77.14285714285715,0,0
@@ edu.stanford.nlp.international.french.process.FrenchTokenizer$FrenchTokenizerFactory.setOptions,18,24,27,27,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchTokenizer.<init>,5,6,5,5,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchTokenizer.getNext,20,32,51,42,82.35294117647058,0,0
@@ edu.stanford.nlp.international.french.process.FrenchTokenizer.processCompound,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchTokenizer.processContraction,14,22,15,3,20.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchTokenizer.main,21,27,40,28,70.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.<init>,67,104,98,94,95.91836734693877,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.getNext,8,11,21,21,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.getNormalizedAmpNext,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.international.french.process.FrenchLexer.next,231,380,1029,515,50.0485908649174,0,3
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.setupDictionary,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.getInstance,4,4,6,5,83.33333333333334,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.isStrippable,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.removeAccents,7,8,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.getCase,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.normalizeStrippedVerb,16,23,38,27,71.05263157894737,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.stripSuffix,7,8,16,12,75.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.separatePronouns,8,11,17,17,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishVerbStripper.stripVerb,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishUnknownWordSignatures.conditionalSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishUnknownWordSignatures.imperfectSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishUnknownWordSignatures.infinitiveSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.spanish.SpanishUnknownWordSignatures.adverbSuffix,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor$POSTieBreaker.compare,8,11,8,8,100.0,0,1
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor$MultiWordProcessor.process,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.loadTrees,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.updateTagger,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.split,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.findSplitPoint,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.fixMultiWordTokens,11,13,11,11,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.convertTreeTagsToUD,65,95,98,98,100.0,0,1
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor.main,19,26,22,22,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor$ManualUWModel.getOverrideTag,105,175,162,162,100.0,0,1
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor$ManualUWModel.getTag,17,24,26,26,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraPOSStats.process,13,16,10,10,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraPOSStats.main,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor$RightOfExclusiveFilter.test,7,8,16,16,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor$RightOfExclusiveFilter.getFollowingTerminal,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor$RightOfExclusiveFilter.getRightSiblingOrRightAncestor,6,7,13,13,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor$RightOfExclusiveFilter.getLeftmostDescendant,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor.updateTagger,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor.traverseAndFix,13,18,27,27,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor.getContainingPhrase,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor.inferPOS,10,14,25,25,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor.inferPhrasalCategory,17,25,23,23,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor.resolveDummyTags,7,8,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.MultiWordPreprocessor.main,11,14,23,23,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor$LeftOfFilter.test,9,12,28,28,100.0,0,0
@@ edu.stanford.nlp.international.spanish.pipeline.AnCoraProcessor$LeftOfFilter.getRightmostDescendant,4,4,5,5,100.0,0,1
@@ edu.stanford.nlp.international.spanish.scripts.TreeToTSV.main,22,31,52,37,71.15384615384616,0,0
@@ edu.stanford.nlp.international.spanish.scripts.ConfusionMatrixTSV.main,10,12,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishTokenizer$SpanishTokenizerFactory.setOptions,42,69,30,30,100.0,0,1
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.<init>,70,108,102,98,96.07843137254902,0,1
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.convertToEl,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.getNext,8,11,21,21,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.getNormalizedAmpNext,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishLexer.next,218,365,978,493,50.40899795501023,0,2
@@ edu.stanford.nlp.international.spanish.process.SpanishTokenizer.<init>,11,15,15,15,100.0,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishTokenizer.processContraction,21,34,23,10,43.47826086956522,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishTokenizer.processVerb,7,8,14,13,92.85714285714286,0,0
@@ edu.stanford.nlp.international.spanish.process.SpanishTokenizer.processCompound,5,5,7,6,85.71428571428571,0,1
@@ edu.stanford.nlp.international.spanish.process.SpanishTokenizer.main,31,42,62,41,66.12903225806451,0,0
@@ edu.stanford.nlp.international.spanish.process.AnCoraPronounDisambiguator.disambiguatePersonalPronoun,13,18,33,33,100.0,0,1
@@ edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification.getValues,20,28,46,46,100.0,0,0
@@ edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification.strToFeatures,65,107,163,163,100.0,0,1
@@ edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification.processInflectionalFeatures,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification.processInflectionalFeaturesHelper,21,31,52,52,100.0,0,0
@@ edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification.main,10,12,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.international.arabic.ArabicVerbStemBank.getInstance,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.international.arabic.ArabicVerbStemBank.getStem,4,4,10,10,100.0,0,0
@@ edu.stanford.nlp.international.arabic.ArabicVerbStemBank.load,13,18,29,29,100.0,0,0
@@ edu.stanford.nlp.international.arabic.ArabicVerbStemBank.debugPrint,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.arabic.Buckwalter.<init>,9,11,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.international.arabic.Buckwalter.convert,28,39,66,52,78.78787878787878,0,0
@@ edu.stanford.nlp.international.arabic.Buckwalter.main,39,57,61,36,59.01639344262295,0,0
@@ edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification$ArabicMorphoFeatures.fromTagString,8,9,16,11,68.75,0,0
@@ edu.stanford.nlp.international.arabic.ArabicMorphoFeatureSpecification$ArabicMorphoFeatures.getTag,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.international.arabic.IBMArabicEscaper.escapeString,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.international.arabic.IBMArabicEscaper.stripAnnotationsAndClassing,17,24,48,36,75.0,0,1
@@ edu.stanford.nlp.international.arabic.IBMArabicEscaper.apply,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.arabic.IBMArabicEscaper.apply,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.international.arabic.IBMArabicEscaper.main,18,23,40,19,47.5,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBCorrector.loadOps,10,12,16,16,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBCorrector.continuing,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBCorrector.main,7,8,16,13,81.25,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.MWETreeVisitorExternal.loadMWEs,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.MWETreeVisitorExternal.visitTree,11,14,16,16,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.MWETreeVisitorExternal.getPreterminalSubtrees,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.MWETreeVisitorExternal.main,9,11,20,16,80.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBArabicDataset$ArabicRawTreeNormalizer.<init>,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBArabicDataset$ArabicRawTreeNormalizer.processPreterminal,20,27,66,39,59.09090909090909,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBArabicDataset$ArabicRawTreeNormalizer.arabicAoverAFilter,14,21,23,23,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBArabicDataset$ArabicRawTreeNormalizer.visitTree,26,38,62,59,95.16129032258065,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBArabicDataset.build,17,22,39,39,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.ATBArabicDataset.setOptions,10,13,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.UnvocLexicalMapper.map,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DefaultLexicalMapper.mapUtf8,13,19,43,37,86.04651162790698,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DefaultLexicalMapper.mapBuckwalter,19,28,59,55,93.22033898305084,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DefaultLexicalMapper.map,8,10,16,16,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DefaultLexicalMapper.setup,18,28,6,6,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DefaultLexicalMapper.canChangeEncoding,10,14,17,17,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DecimatedArabicDataset$ArabicTreeDecimatedNormalizer.<init>,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DecimatedArabicDataset$ArabicTreeDecimatedNormalizer.setupOutputFiles,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DecimatedArabicDataset$ArabicTreeDecimatedNormalizer.closeOutputFiles,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DecimatedArabicDataset$ArabicTreeDecimatedNormalizer.visitTree,21,30,56,56,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DecimatedArabicDataset$ArabicTreeDecimatedNormalizer.write,5,5,10,10,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DecimatedArabicDataset$ArabicTreeDecimatedNormalizer.getFilenames,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.DecimatedArabicDataset.build,9,11,25,23,92.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.LabeledATBDataset$LabelingTreeNormalizer.processPreterminal,16,23,25,25,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.LDCPosMapper.map,6,7,19,19,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.LDCPosMapper.processShortTag,18,27,64,42,65.625,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.LDCPosMapper.setup,21,30,45,41,91.11111111111111,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.LDCPosMapper.toString,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.TaggedArabicDataset$ArabicTreeTaggedNormalizer.visitTree,12,16,22,22,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.GaleP4LexMapper.mapUtf8,6,7,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.GaleP4LexMapper.mapBuckwalter,6,7,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.GaleP4LexMapper.map,7,8,13,13,100.0,0,1
@@ edu.stanford.nlp.international.arabic.pipeline.GaleP4LexMapper.canChangeEncoding,9,13,16,16,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.UniversalPOSMapper.map,9,11,31,30,96.7741935483871,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.UniversalPOSMapper.setup,9,11,9,9,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.UniversalPOSMapper.loadUniversalMap,9,11,13,13,100.0,0,1
@@ edu.stanford.nlp.international.arabic.pipeline.TaggedArabicDataset.build,19,25,53,53,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.IBMMTArabicDataset.build,15,19,21,19,90.47619047619048,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.IBMMTArabicDataset.setOptions,13,17,31,29,93.54838709677419,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.MWETreeVisitor.loadOps,10,12,16,16,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.MWETreeVisitor.continuing,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.pipeline.LabeledATBDataset.build,17,22,46,46,100.0,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParser.main,28,38,56,46,82.14285714285714,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel.removeDeleteSplittersFromSplitters,18,25,46,46,100.0,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel.getAnnotatedBinaryTreebankFromTreebank,20,27,74,74,100.0,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel.getParserDataFromTreebank,4,4,21,20,95.23809523809523,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel.makeParsers,4,4,15,15,100.0,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel.parse,20,28,105,72,68.57142857142857,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel.run,13,16,28,28,100.0,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel$GenericLatticeScorer.convertItemSpan,5,6,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel$GenericLatticeScorer.oPossible,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.parsesegment.JointParsingModel$GenericLatticeScorer.iPossible,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.<init>,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.setupNormalizationMap,18,25,48,48,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.normalizeToken,19,28,62,40,64.51612903225806,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.isLengthening,12,17,28,28,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.getNext,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.getEllipsis,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.zzRefill,16,22,68,43,63.23529411764706,0,1
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicLexer.next,56,90,220,118,53.63636363636364,0,1
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.<init>,8,10,10,10,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.getTokenizerFactory,9,11,20,18,90.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.segmentStringToIOB,5,5,13,11,84.61538461538461,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.segmentStringToTokenList,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.segment,5,5,10,7,70.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.evaluate,33,45,105,51,48.57142857142857,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.main,18,24,61,52,85.24590163934425,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.decode,16,21,31,27,87.09677419354838,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenter.getSegmenter,10,13,37,37,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicDocumentReaderAndWriter$1.apply,42,61,136,97,71.32352941176471,0,1
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.StringToIOB,17,23,50,32,64.0,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.fillInWordStatistics,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.tokenToDatums,73,113,271,107,39.48339483394834,0,1
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.shouldNotSegment,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.stripSegmentationMarkers,13,17,24,24,100.0,0,1
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.createDatum,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.getTokenType,12,17,25,22,88.0,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.IOBToString,89,141,154,91,59.09090909090909,0,1
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.annotateMarkers,16,23,37,19,51.35135135135135,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.annotateMarkersOnWord,12,16,44,22,50.0,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.getHeadBounds,26,37,100,20,20.0,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.labelDomain,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.IOBUtils.TokenSpansForIOB,46,77,219,19,8.67579908675799,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicDocumentReaderAndWriter.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicDocumentReaderAndWriter.printAnswers,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicDocumentReaderAndWriter.main,25,35,46,38,82.6086956521739,0,0
@@ edu.stanford.nlp.international.arabic.process.StartAndEndArabicSegmenterFeatureFactory.featuresCpC,7,9,14,14,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicTokenizer.getNext,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicTokenizer.atbFactory,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicTokenizer.main,19,25,37,25,67.56756756756756,0,1
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenterFeatureFactory.getCliqueFeatures,15,20,42,42,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicSegmenterFeatureFactory.featuresC,19,26,42,21,50.0,0,1
@@ edu.stanford.nlp.international.arabic.process.ArabicTokenizer$ArabicTokenizerFactory.setOptions,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.international.arabic.process.ArabicTokenizerTester.main,19,25,54,42,77.77777777777779,0,1
@@ edu.stanford.nlp.coref.CorefSystem$1.process,9,11,23,23,100.0,0,0
@@ edu.stanford.nlp.coref.CorefSystem.annotate,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.CorefSystem.runOnConll,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.algorithm,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.coref.CorefProperties.useConstituencyParse,7,9,11,11,100.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.maxMentionDistance,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.mdType,7,8,8,7,87.5,0,0
@@ edu.stanford.nlp.coref.CorefProperties.getMentionDetectionModel,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.conllOutputPath,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.setInput,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.getDataPath,4,4,5,4,80.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.getLanguage,8,11,10,10,100.0,0,1
@@ edu.stanford.nlp.coref.CorefProperties.getHeadFinder,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.CorefProperties.getCorefMentionFilter,6,7,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.CorefPrinter.printConllOutput,7,8,13,12,92.3076923076923,0,0
@@ edu.stanford.nlp.coref.CorefPrinter.printConllOutput,50,67,110,86,78.18181818181819,0,1
@@ edu.stanford.nlp.coref.CorefPrinter.lambda$null$0,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.CorefScorer.getEvalSummary,7,8,16,9,56.25,0,1
@@ edu.stanford.nlp.coref.CorefScorer.printScoreSummary,18,24,20,20,100.0,0,0
@@ edu.stanford.nlp.coref.CorefScorer.getFinalConllScore,5,5,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.coref.CorefScorer.getFinalConllScoreFromOutputDir,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.getMentionPairs,8,9,23,10,43.47826086956522,0,0
@@ edu.stanford.nlp.coref.CorefUtils.getLabeledMentionPairs,13,16,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.mergeCoreferenceClusters,4,4,14,14,100.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.removeSingletonClusters,7,8,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.mergePronounsBasedOnSpeaker,26,36,37,31,83.78378378378379,0,0
@@ edu.stanford.nlp.coref.CorefUtils.heuristicFilter,27,37,76,59,77.63157894736842,0,0
@@ edu.stanford.nlp.coref.CorefUtils.getContentWords,10,14,25,20,80.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.printHumanReadableCoref,8,9,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.getMatchingSpans,11,14,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.coref.CorefUtils.getMatchingMentionsSpans,17,23,23,19,82.6086956521739,0,0
@@ edu.stanford.nlp.coref.CorefUtils.lambda$null$6,11,15,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.lambda$static$3,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.CorefUtils.lambda$getSortedMentions$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityBothHaveProper,16,21,22,14,63.63636363636363,0,0
@@ edu.stanford.nlp.coref.CorefRules.entitySameProperHeadLastWord,10,12,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityAlias,7,9,22,22,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityIWithinI,10,12,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityPersonDisagree,12,15,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityPersonCompatible,12,15,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityWordsIncluded,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityHaveIncompatibleModifier,10,12,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityIsRoleAppositive,8,10,16,16,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityIsRelativePronoun,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityIsAcronym,14,18,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.coref.CorefRules.isAcronym,54,77,122,75,61.47540983606557,0,1
@@ edu.stanford.nlp.coref.CorefRules.entityIsPredicateNominatives,13,19,44,44,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityIsApposition,13,18,28,28,100.0,0,1
@@ edu.stanford.nlp.coref.CorefRules.entityAttributesAgree,76,120,182,150,82.41758241758241,0,0
@@ edu.stanford.nlp.coref.CorefRules.attributeSetDisagree,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.pruneAttributes,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.pruneAttributes,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityAttributesAgreeChinese,7,10,32,32,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityAttributesAgree,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityRelaxedHeadsAgreeBetweenMentions,7,9,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityHeadsAgree,12,17,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityExactStringMatch,24,34,41,38,92.6829268292683,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityExactStringMatch,17,25,39,36,92.3076923076923,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityRelaxedExactStringMatch,20,32,52,52,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityIWithinI,11,18,36,36,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityHaveIncompatibleModifier,32,46,73,56,76.71232876712328,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityHaveDifferentLocation,38,55,79,71,89.87341772151899,0,1
@@ edu.stanford.nlp.coref.CorefRules.entitySameProperHeadLastWord,32,46,62,54,87.09677419354838,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityNumberInLaterMention,14,19,17,17,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityHaveExtraProperNoun,27,38,36,28,77.77777777777779,0,0
@@ edu.stanford.nlp.coref.CorefRules.antecedentIsMentionSpeaker,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.antecedentMatchesMentionSpeakerAnnotation,20,27,32,32,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.mentionMatchesSpeaker,21,30,47,47,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityPersonDisagree,60,102,226,226,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityPersonCompatible,40,70,167,167,100.0,0,1
@@ edu.stanford.nlp.coref.CorefRules.entitySameSpeaker,14,19,21,21,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityDifferentSpeaker,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.getSpeakerClusterId,12,18,32,19,59.375,0,0
@@ edu.stanford.nlp.coref.CorefRules.entitySubjectObject,17,28,56,56,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityTokenDistance,5,6,16,16,100.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityClusterAllCorefDictionary,15,20,25,23,92.0,0,0
@@ edu.stanford.nlp.coref.CorefRules.entityCorefDictionary,17,24,48,38,79.16666666666666,0,0
@@ edu.stanford.nlp.coref.CorefRules.contextIncompatible,22,34,84,60,71.42857142857143,0,0
@@ edu.stanford.nlp.coref.CorefRules.sentenceContextIncompatible,30,46,92,74,80.43478260869566,0,1
@@ edu.stanford.nlp.coref.misc.SingletonPredictor.setTokenIndices,8,9,2,1,50.0,0,0
@@ edu.stanford.nlp.coref.misc.SingletonPredictor.generateFeatureVectors,28,38,42,42,100.0,0,0
@@ edu.stanford.nlp.coref.misc.SingletonPredictor.main,9,11,15,5,33.33333333333333,0,0
@@ edu.stanford.nlp.coref.misc.FromFileCorefAlgorithm.<init>,6,7,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.misc.FromFileCorefAlgorithm.runCoref,6,7,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.misc.FromFileCorefAlgorithm.lambda$new$0,8,10,10,8,80.0,0,0
@@ edu.stanford.nlp.coref.misc.MentionDetectionEvaluator.process,10,12,23,17,73.91304347826086,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefModel.score,15,20,75,56,74.66666666666667,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefModel.makeFeatureVector,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefModel.addDistanceFeatures,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefModel.loadMapFromTextFile,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefDataExporter.process,41,53,90,82,91.11111111111111,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefDataExporter.main,5,5,8,8,100.0,0,1
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefDataExporter.writeCompressor,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefDataExporter.lambda$getSentenceArray$1,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefDataExporter.lambda$getSentenceArray$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.fastneural.FastNeuralCorefAlgorithm.runCoref,28,37,54,45,83.33333333333334,0,1
@@ edu.stanford.nlp.coref.docreader.CoreNLPDocumentReader.<init>,12,17,32,28,87.5,0,0
@@ edu.stanford.nlp.coref.docreader.CoreNLPDocumentReader.getFiles,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoreNLPDocumentReader.getNextDocument,10,13,44,30,68.18181818181817,0,0
@@ edu.stanford.nlp.coref.docreader.CoreNLPDocumentReader.nextDoc,6,7,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.coref.docreader.CoreNLPDocumentReader.extractGoldMentions,11,13,14,10,71.42857142857143,0,0
@@ edu.stanford.nlp.coref.docreader.CoreNLPDocumentReader.reset,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$CorpusStats.process,31,45,102,81,79.41176470588235,0,1
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$CorpusStats.appendIntCountStats,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.<init>,12,17,31,27,87.09677419354838,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.getFiles,5,5,2,2,100.0,0,1
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.reset,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.getNextDocument,10,13,47,33,70.2127659574468,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.getField,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.concatField,7,8,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.getMention,9,12,18,15,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.include,10,14,23,23,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.writeTabSep,31,43,84,68,80.95238095238095,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.main,27,37,61,50,81.9672131147541,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.nextDoc,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.setDependencyTree,10,12,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader.extractGoldMentions,11,13,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.wordsToParse,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.getLabelledSpans,41,61,132,73,55.3030303030303,0,1
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.wordsToSentence,50,72,138,101,73.18840579710145,0,1
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.sentencesToDocument,11,13,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.getTreeNonTerminal,7,9,16,7,43.75,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.annotateDocument,22,31,60,55,91.66666666666666,0,0
@@ edu.stanford.nlp.coref.docreader.CoNLLDocumentReader$DocumentIterator.readNextDocument,30,45,85,48,56.470588235294116,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.findMentions,10,12,29,25,86.20689655172413,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.assignMentionIDs,8,9,2,1,50.0,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.setBarePlural,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.extractNPorPRPFromDependency,9,11,15,11,73.33333333333333,0,1
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.extractMentionForHeadword,22,31,92,61,66.30434782608695,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.getNPSpan,13,16,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.getNPSpanOld,7,8,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.addMention,5,6,18,18,100.0,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.extractPronounForHeadword,15,22,66,58,87.87878787878788,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.findHeadInDependency,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.findHead,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.findHeadInDependency,17,24,64,39,60.9375,0,0
@@ edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.filterPredictedMentions,10,12,30,25,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.findMentions,17,23,51,47,92.15686274509804,0,0
@@ edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.setBarePlural,8,10,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.extractNPorPRP,11,15,32,30,93.75,0,0
@@ edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.extractNamedEntityMentions,19,28,72,37,51.388888888888886,0,0
@@ edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.removeSpuriousMentionsZhSimple,13,17,27,22,81.48148148148148,0,0
@@ edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.removeSpuriousMentionsEn,49,75,145,140,96.55172413793103,0,0
@@ edu.stanford.nlp.coref.md.MentionDetectionClassifier.extractFeatures,36,52,72,72,100.0,0,0
@@ edu.stanford.nlp.coref.md.MentionDetectionClassifier.classifyMentions,34,45,38,38,100.0,0,1
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.extractPremarkedEntityMentions,14,19,31,20,64.51612903225806,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.extractEnumerations,13,17,26,24,92.3076923076923,0,1
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.insideNE,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.inStopList,12,18,14,14,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.removeSpuriousMentions,6,7,17,17,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.removeSpuriousMentionsEn,17,24,48,43,89.58333333333334,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.removeSpuriousMentionsZh,52,80,156,151,96.7948717948718,0,1
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.mentionContainsRemoveChars,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.mentionIsDemonym,7,9,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.mentionIsRangren,8,12,15,15,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.mentionIsInterrogativePronoun,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.extractNamedEntityModifiers,33,49,113,83,73.45132743362832,0,1
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.addNamedEntityStrings,10,12,17,12,70.58823529411765,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.addGoldMentions,13,16,29,24,82.75862068965517,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.findHead,14,18,41,35,85.36585365853658,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.findHeadChinese,14,21,73,33,45.20547945205479,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.findSyntacticHead,35,53,130,85,65.38461538461539,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.findPartialSpan,10,13,18,18,100.0,0,1
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.funkyFindLeafWithApproximateSpan,16,22,29,29,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.getParser,8,11,22,16,72.72727272727273,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.convertToCoreLabels,7,8,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.safeHead,12,17,30,25,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.findTreeWithSpan,19,28,33,33,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.partitiveRule,7,9,22,22,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.isPleonastic,9,11,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.isPleonasticDebug,12,15,29,20,68.96551724137932,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.getPleonasticPatterns,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.coref.md.CorefMentionFinder.checkPleonastic,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.md.HybridCorefMentionFinder.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.md.HybridCorefMentionFinder.findMentions,10,12,32,28,87.5,0,0
@@ edu.stanford.nlp.coref.md.HybridCorefMentionFinder.extractNamedEntityMentions,19,28,72,37,51.388888888888886,0,0
@@ edu.stanford.nlp.coref.md.HybridCorefMentionFinder.extractNPorPRP,20,29,51,42,82.35294117647058,0,0
@@ edu.stanford.nlp.coref.statistical.EvalUtils$AbstractEvaluator.getRecall,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.EvalUtils$AbstractEvaluator.getPrecision,5,5,7,7,100.0,0,1
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.<init>,17,23,57,33,57.89473684210527,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.<init>,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.doAction,15,20,51,33,64.70588235294117,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.doBestAction,8,9,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.isComplete,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.getActions,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.lambda$new$1,10,12,26,26,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$State.lambda$new$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.DatasetBuilder.process,17,22,50,45,90.0,0,1
@@ edu.stanford.nlp.coref.statistical.DatasetBuilder.lambda$process$1,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.SimpleLinearClassifier.<init>,8,9,14,14,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.SimpleLinearClassifier.learn,10,12,25,25,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.SimpleLinearClassifier.weightFeatureProduct,5,5,6,3,50.0,0,0
@@ edu.stanford.nlp.coref.statistical.SimpleLinearClassifier.printWeightVector,8,9,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.SimpleLinearClassifier.lambda$getWeightVector$0,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.getClusterMerges,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.doTraining,16,21,61,36,59.01639344262295,0,1
@@ edu.stanford.nlp.coref.statistical.Clusterer.trainPolicy,5,5,12,8,66.66666666666666,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.evaluatePolicy,11,13,11,11,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.runPolicy,19,24,33,33,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.getFeatures,4,4,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.getFeatures,16,20,41,32,78.04878048780488,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.earliestMention,8,10,19,9,47.368421052631575,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.getFeatures,21,28,71,68,95.77464788732394,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer.addSuffix,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.SimpleLinearClassifier$3.derivative,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.ClustererDataLoader$ClustererDoc.<init>,15,19,24,20,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.statistical.ClustererDataLoader$ClustererDoc.lambda$new$1,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Example.<init>,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Example.isNewLink,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModel.<init>,8,10,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModel.writeModel,12,16,20,20,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModel.learn,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModel.learn,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModel.learn,14,20,45,37,82.22222222222221,0,1
@@ edu.stanford.nlp.coref.statistical.StatisticalCorefProperties.getDefaultModelPath,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.StatisticalCorefProperties.pairwiseScoreThresholds,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.SimpleLinearClassifier$2.derivative,7,8,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Compressor.compress,7,8,15,14,93.33333333333333,0,0
@@ edu.stanford.nlp.coref.statistical.Compressor.uncompress,5,5,17,13,76.47058823529412,0,1
@@ edu.stanford.nlp.coref.statistical.ClustererDataLoader.loadDocuments,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.loadVocabulary,7,8,5,5,100.0,0,1
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.extract,16,20,34,33,97.05882352941177,0,1
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.getFeatures,44,64,125,110,88.0,0,1
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.getFeatures,134,209,545,542,99.44954128440368,0,1
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.relaxedStringMatch,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.getPropers,7,8,21,16,76.19047619047619,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.addFeature,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.bin,8,10,17,16,94.11764705882352,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.getRole,10,13,16,16,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.getDependencyParent,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.addDependencyFeatures,6,7,16,16,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.maximalNp,9,12,10,8,80.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.numEmbeddedNps,9,12,11,8,72.72727272727273,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.headEmbeddingLevel,7,8,13,6,46.15384615384615,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.headContainedIn,7,8,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.wordIndicator,8,9,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.wordIndicator,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.wordIndicator,7,8,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.getPOS,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.nextnextWord,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.nextWord,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.prevWord,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.prevprevWord,5,5,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.lambda$getFeatures$1,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractor.lambda$getFeatures$0,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModelTrainer.trainRanking,68,100,184,118,64.13043478260869,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModelTrainer.getAnaphoricityExamples,22,29,40,34,85.0,0,1
@@ edu.stanford.nlp.coref.statistical.PairwiseModelTrainer.getExamples,8,9,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModelTrainer.trainClassification,15,19,25,21,84.0,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModelTrainer.test,7,8,19,18,94.73684210526315,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModelTrainer.writeScores,9,11,24,22,91.66666666666666,0,0
@@ edu.stanford.nlp.coref.statistical.PairwiseModelTrainer.lambda$trainRanking$0,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$MergeKey.equals,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.FeatureExtractorRunner.process,4,4,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$Cluster.getMentionHash,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.coref.statistical.MetaFeatureExtractor.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.MetaFeatureExtractor.filterOut,13,16,14,9,64.28571428571429,0,0
@@ edu.stanford.nlp.coref.statistical.MetaFeatureExtractor.getFeatures,40,56,152,103,67.76315789473685,0,0
@@ edu.stanford.nlp.coref.statistical.MetaFeatureExtractor.identifiers,16,22,25,25,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.MetaFeatureExtractor.getConjunction,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.ClusteringCorefAlgorithm.runCoref,12,15,37,37,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.StatisticalCorefAlgorithm.runCoref,30,40,51,51,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.StatisticalCorefAlgorithm.lambda$runCoref$0,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.StatisticalCorefTrainer.makeDir,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.StatisticalCorefTrainer.fieldValues,5,5,5,2,40.0,0,0
@@ edu.stanford.nlp.coref.statistical.StatisticalCorefTrainer.preprocess,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$ClustererClassifier.bestAction,5,5,11,11,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.Clusterer$ClustererClassifier.learn,7,8,21,13,61.904761904761905,0,0
@@ edu.stanford.nlp.coref.statistical.MaxMarginMentionRanker.<init>,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.MaxMarginMentionRanker.learn,8,9,18,18,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.EvalUtils$CombinedEvaluator.update,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.EvalUtils$CombinedEvaluator.getF1,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.EvalUtils$MUCEvaluator.getScore,11,13,18,9,50.0,0,0
@@ edu.stanford.nlp.coref.statistical.EvalUtils.f1,11,13,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.MetadataWriter.process,30,41,68,57,83.82352941176471,0,1
@@ edu.stanford.nlp.coref.statistical.MetadataWriter.finish,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.statistical.EvalUtils$B3Evaluator.getScore,17,22,25,16,64.0,0,1
@@ edu.stanford.nlp.coref.data.SpeakerInfo.<init>,7,9,25,24,96.0,0,0
@@ edu.stanford.nlp.coref.data.SpeakerInfo.hasRealSpeakerName,7,9,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.data.SpeakerInfo.addMention,10,14,29,29,100.0,0,0
@@ edu.stanford.nlp.coref.data.SpeakerInfo.getCorefClusterId,7,8,8,7,87.5,0,0
@@ edu.stanford.nlp.coref.data.CorefChain.equals,17,25,47,47,100.0,0,0
@@ edu.stanford.nlp.coref.data.CorefChain.<init>,12,15,28,23,82.14285714285714,0,0
@@ edu.stanford.nlp.coref.data.CorefChain.<init>,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentMaker.<init>,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentMaker.getDocumentReader,8,10,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentMaker.makeDocument,15,19,40,35,87.5,0,0
@@ edu.stanford.nlp.coref.data.DocumentMaker.findGoldMentionHeads,5,5,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.coref.data.DocumentMaker.getStanfordCoreNLP,24,32,37,35,94.5945945945946,0,0
@@ edu.stanford.nlp.coref.data.DocumentMaker.nextDoc,18,24,26,26,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.isPronominal,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.spanToString,9,11,27,18,66.66666666666666,0,0
@@ edu.stanford.nlp.coref.data.Mention.lowercaseNormalizedSpanString,4,4,8,7,87.5,0,0
@@ edu.stanford.nlp.coref.data.Mention.nerTokens,12,17,53,39,73.58490566037736,0,0
@@ edu.stanford.nlp.coref.data.Mention.nerName,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.process,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.process,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.setSingleton,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getSingletonFeatures,9,12,32,28,87.5,0,0
@@ edu.stanford.nlp.coref.data.Mention.getMentionString,7,8,8,8,100.0,0,1
@@ edu.stanford.nlp.coref.data.Mention.getGender,22,34,88,67,76.13636363636364,0,1
@@ edu.stanford.nlp.coref.data.Mention.setDiscourse,26,46,17,17,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.setPerson,27,40,103,103,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.setSemantics,6,7,16,15,93.75,0,0
@@ edu.stanford.nlp.coref.data.Mention.isListMemberOf,9,12,24,24,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.addListMember,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.coref.data.Mention.addBelongsToList,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.coref.data.Mention.isMemberOfSameList,6,8,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.isListLike,33,52,59,30,50.847457627118644,0,0
@@ edu.stanford.nlp.coref.data.Mention.isListLikeByDependency,13,17,24,24,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.setType,26,41,84,84,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.setGender,27,40,99,95,95.95959595959596,0,1
@@ edu.stanford.nlp.coref.data.Mention.setNumber,28,42,120,102,85.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.setAnimacy,69,127,110,82,74.54545454545455,0,0
@@ edu.stanford.nlp.coref.data.Mention.knownSuffix,9,11,10,6,60.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.setHeadString,14,20,49,41,83.6734693877551,0,0
@@ edu.stanford.nlp.coref.data.Mention.setNERString,10,13,22,22,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.sameSentence,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.included,10,14,13,13,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.headsAgree,8,12,36,36,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.numbersAgree,12,16,30,30,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.gendersAgree,12,16,30,30,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.animaciesAgree,12,16,30,30,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.entityTypesAgree,57,98,106,106,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.includedIn,7,9,20,20,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.attributesAgree,8,11,18,18,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.addApposition,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.coref.data.Mention.isApposition,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.addPredicateNominatives,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.coref.data.Mention.isPredicateNominatives,5,6,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.addRelativePronoun,4,4,9,8,88.88888888888889,0,0
@@ edu.stanford.nlp.coref.data.Mention.appearEarlierThan,27,37,88,88,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.longestNNPEndsWithHead,9,11,29,13,44.827586206896555,0,0
@@ edu.stanford.nlp.coref.data.Mention.lowestNPIncludesHead,18,24,42,19,45.23809523809524,0,0
@@ edu.stanford.nlp.coref.data.Mention.stringWithoutArticle,14,20,20,20,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.preprocessSearchTerm,38,55,359,11,3.064066852367688,0,1
@@ edu.stanford.nlp.coref.data.Mention.buildQueryText,5,5,4,1,25.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.removePhraseAfterHead,31,46,121,50,41.32231404958678,0,0
@@ edu.stanford.nlp.coref.data.Mention.removeParenthesis,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.isTheCommonNoun,6,8,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.findDependentVerb,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.insideIn,7,9,24,24,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.moreRepresentativeThan,54,85,196,196,100.0,0,1
@@ edu.stanford.nlp.coref.data.Mention.getPremodifiers,16,25,37,37,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getPostmodifiers,17,27,41,41,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getSplitPattern,10,12,22,22,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getPattern,8,9,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getPattern,20,30,57,47,82.45614035087719,0,0
@@ edu.stanford.nlp.coref.data.Mention.isCoordinated,9,11,9,9,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getContextHelper,14,19,39,18,46.15384615384615,0,0
@@ edu.stanford.nlp.coref.data.Mention.getPremodifierContext,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.isRelativePronoun,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.isRoleAppositive,26,42,74,74,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.isDemonym,12,17,32,21,65.625,0,0
@@ edu.stanford.nlp.coref.data.Mention.getPosition,15,22,44,44,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getHeadParent,5,5,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.data.Mention.getHeadChildren,5,5,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.data.Mention.getHeadSiblings,5,5,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.data.Mention.getHeadPathToRoot,5,5,12,10,83.33333333333334,0,0
@@ edu.stanford.nlp.coref.data.Mention.getRelation,35,58,97,97,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getModifiers,14,20,36,27,75.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getQuantification,19,26,36,36,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getNegation,18,25,40,40,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getModal,23,33,52,52,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.getReportEmbedding,23,34,61,55,90.1639344262295,0,0
@@ edu.stanford.nlp.coref.data.Mention.getCoordination,14,18,14,14,100.0,0,0
@@ edu.stanford.nlp.coref.data.Mention.equals,78,115,291,291,100.0,0,1
@@ edu.stanford.nlp.coref.data.Dictionaries.readWordLists,10,14,80,80,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.loadStateAbbreviation,8,9,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.loadDemonymLists,14,18,23,23,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.getDemonyms,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.getWordsFromFile,13,17,15,15,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.loadCountriesLists,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.loadGenderNumber,20,29,55,43,78.18181818181819,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.loadChineseGenderNumberAnimacy,28,43,73,73,100.0,0,1
@@ edu.stanford.nlp.coref.data.Dictionaries.loadCorefDict,8,9,17,10,58.82352941176471,0,1
@@ edu.stanford.nlp.coref.data.Dictionaries.loadCorefDictPMI,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.loadSignatures,8,9,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.loadSemantics,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.signature,12,16,22,22,100.0,0,0
@@ edu.stanford.nlp.coref.data.Dictionaries.<init>,4,4,9,9,100.0,0,1
@@ edu.stanford.nlp.coref.data.CorefChain$MentionComparator.compare,14,19,48,48,100.0,0,1
@@ edu.stanford.nlp.coref.data.CorefChain$CorefMention.equals,28,40,95,95,100.0,0,0
@@ edu.stanford.nlp.coref.data.CorefChain$CorefMention.moreRepresentativeThan,31,45,124,124,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.preprocess,9,11,17,14,82.35294117647058,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.extractGoldClusters,12,15,15,13,86.66666666666667,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.assignMentionNumbers,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.mentionReordering,5,5,9,5,55.55555555555556,0,1
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.getHeadIndex,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.fillSyntacticInfo,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.initializeMentions,7,8,13,13,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.assignMentionIDs,18,23,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findTwinMentions,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findTwinMentionsStrict,28,37,64,50,78.125,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findTwinMentionsRelaxed,24,32,67,62,92.53731343283582,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.fillMentionInfo,32,45,104,78,75.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findSyntacticRelationsFromDependency,18,25,44,33,75.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.initializeClusters,18,23,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findDocType,17,23,25,14,56.00000000000001,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.setParagraphAnnotation,19,24,19,10,52.63157894736842,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.processDiscourse,77,108,135,131,97.03703703703704,0,1
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.setUtteranceAndSpeakerAnnotation,49,73,119,53,44.537815126050425,0,1
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findSpeakers,18,24,33,33,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findSpeakersInArticle,16,22,67,23,34.32835820895522,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findQuotationSpeaker,14,21,52,52,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findSpeaker,24,34,65,49,75.38461538461539,0,1
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findSubject,10,12,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findSpeakersInConversation,20,26,44,28,63.63636363636363,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findParagraphSpeaker,18,26,60,43,71.66666666666667,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.findNextParagraphSpeaker,18,26,37,34,91.8918918918919,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.isSpeaker,22,32,69,59,85.5072463768116,0,1
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.markListMemberRelation,12,15,13,13,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor.markMentionRelation,28,41,48,48,100.0,0,0
@@ edu.stanford.nlp.coref.data.CorefCluster.<init>,17,24,51,33,64.70588235294117,0,0
@@ edu.stanford.nlp.coref.data.CorefCluster.mergeClusters,28,43,120,120,100.0,0,0
@@ edu.stanford.nlp.coref.data.CorefCluster.printCorefCluster,14,17,29,29,100.0,0,0
@@ edu.stanford.nlp.coref.data.CorefCluster.isSinglePronounCluster,10,13,14,14,100.0,0,0
@@ edu.stanford.nlp.coref.data.Document.getSentenceWordLists,10,12,14,14,100.0,0,1
@@ edu.stanford.nlp.coref.data.Document.mergeIncompatibles,15,20,46,31,67.3913043478261,0,0
@@ edu.stanford.nlp.coref.data.Document.mergeAcronymCache,16,22,52,37,71.15384615384616,0,0
@@ edu.stanford.nlp.coref.data.Document.getGoldLinks,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.data.Document.extractGoldLinks,51,75,178,98,55.0561797752809,0,5
@@ edu.stanford.nlp.coref.data.Document.isCoref,7,9,28,28,100.0,0,0
@@ edu.stanford.nlp.coref.data.CorefChain$CorefMentionComparator.compare,14,19,48,48,100.0,0,0
@@ edu.stanford.nlp.coref.data.DocumentPreprocessor$1.compare,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefAlgorithm.runCoref,18,23,46,37,80.43478260869566,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefProperties.modelPath,8,9,7,7,100.0,0,1
@@ edu.stanford.nlp.coref.neural.NeuralCorefProperties.pretrainedEmbeddingsPath,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.coref.neural.ModelSerializer.main,10,13,38,18,47.368421052631575,0,0
@@ edu.stanford.nlp.coref.neural.CategoricalFeatureExtractor.<init>,16,20,22,22,100.0,0,0
@@ edu.stanford.nlp.coref.neural.CategoricalFeatureExtractor.getPairFeatures,9,11,38,34,89.47368421052632,0,0
@@ edu.stanford.nlp.coref.neural.CategoricalFeatureExtractor.pairwiseFeatures,30,40,48,48,100.0,0,1
@@ edu.stanford.nlp.coref.neural.CategoricalFeatureExtractor.getMentionFeatures,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.neural.CategoricalFeatureExtractor.encodeDistance,13,17,19,19,100.0,0,0
@@ edu.stanford.nlp.coref.neural.CategoricalFeatureExtractor.encodeGenre,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.neural.CategoricalFeatureExtractor.lambda$getMentionFeatures$0,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.neural.EmbeddingExtractor.getDocumentEmbedding,9,11,21,21,100.0,0,0
@@ edu.stanford.nlp.coref.neural.EmbeddingExtractor.getMentionEmbeddingsForFast,8,9,12,12,100.0,0,0
@@ edu.stanford.nlp.coref.neural.EmbeddingExtractor.getMentionEmbeddings,8,9,14,14,100.0,0,0
@@ edu.stanford.nlp.coref.neural.EmbeddingExtractor.getAverageEmbedding,8,9,14,11,78.57142857142857,0,0
@@ edu.stanford.nlp.coref.neural.EmbeddingExtractor.getWordEmbedding,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.neural.EmbeddingExtractor.getWordEmbedding,7,8,17,17,100.0,0,0
@@ edu.stanford.nlp.coref.neural.EmbeddingExtractor.normalizeWord,25,36,28,26,92.85714285714286,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefModel.score,7,8,24,10,41.66666666666667,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefDataExporter.process,41,53,72,72,100.0,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefDataExporter.main,6,7,13,9,69.23076923076923,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefDataExporter.lambda$getSentenceArray$3,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefDataExporter.lambda$getSentenceArray$2,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.coref.neural.NeuralCorefDataExporter.lambda$process$1,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefSystem.<init>,9,11,13,13,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefSystem.<init>,9,11,15,15,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefSystem.runCoref,19,26,57,34,59.64912280701754,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefSystem.coref,13,17,31,31,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefSystem.makeCorefOutput,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefSystem.postProcessing,23,33,42,42,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefPrinter.printRawDoc,8,9,21,17,80.95238095238095,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefPrinter.printErrorLog,67,96,318,283,88.9937106918239,0,1
@@ edu.stanford.nlp.coref.hybrid.HybridCorefPrinter.isFirstMention,11,14,17,17,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefPrinter.sentenceStringWithMention,47,65,107,87,81.30841121495327,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefPrinter.printMentionDetectionLog,22,30,83,71,85.54216867469879,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefPrinter.printErrorLogDcoref,49,68,262,235,89.69465648854961,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefPrinter.linkDistanceAnalysis,32,48,127,92,72.44094488188976,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefProperties.getLanguage,8,11,10,10,100.0,0,1
@@ edu.stanford.nlp.coref.hybrid.HybridCorefProperties.getClassifierType,8,10,13,13,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefProperties.getMentionTypes,10,13,16,15,93.75,0,0
@@ edu.stanford.nlp.coref.hybrid.HybridCorefProperties.getMentionTypeStr,6,7,17,11,64.70588235294117,0,0
@@ edu.stanford.nlp.coref.hybrid.demo.ChineseHcorefDemo.main,11,13,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.rf.DecisionTreeNode.isLeaf,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.rf.DecisionTree.probabilityOfTrue,8,9,28,9,32.142857142857146,0,0
@@ edu.stanford.nlp.coref.hybrid.rf.RandomForest.probabilityOfTrue,5,5,7,4,57.14285714285714,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.resolveMention,13,16,32,25,78.125,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.loadSieve,6,8,19,19,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.loadSieves,8,9,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.hasThat,8,10,4,4,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.hasToVerb,8,10,20,8,40.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.skipMentionType,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.merge,4,4,8,8,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.isReallyCoref,8,10,20,20,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.skipForAnalysis,8,10,11,11,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.matchedMentionType,9,11,7,7,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.matchedMentionType,38,63,88,88,100.0,0,1
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.getOrderedAntecedents,7,8,25,23,92.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.Sieve.sortMentionsByClause,16,24,32,31,96.875,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.DcorefSieveOptions.toString,64,94,156,156,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.DeterministicCorefSieve.findCoreferentAntecedent,61,96,269,208,77.32342007434944,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.DeterministicCorefSieve.skipThisMention,22,35,68,64,94.11764705882352,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.DeterministicCorefSieve.getOrderedAntecedents,9,12,30,26,86.66666666666667,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.DeterministicCorefSieve.sortMentionsForPronoun,19,28,48,43,89.58333333333334,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.RFSieve.findCoreferentAntecedent,29,42,108,97,89.81481481481481,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.RFSieve.extractDatum,498,757,1522,1488,97.76609724047306,0,5
@@ edu.stanford.nlp.coref.hybrid.sieve.RFSieve.numEntitiesInList,11,15,37,19,51.35135135135135,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.OracleSieve.findCoreferentAntecedent,20,28,64,55,85.9375,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.NameMatch.isNamedMention,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.coref.hybrid.sieve.NameMatch.checkEntityMatch,13,21,66,65,98.48484848484848,0,0
@@ edu.stanford.nlp.process.TSVSentenceIterator.toCoreMap,72,107,332,117,35.24096385542169,0,0
@@ edu.stanford.nlp.process.WhitespaceLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.process.WhitespaceLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.process.WhitespaceLexer.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.process.WhitespaceLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.WhitespaceLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.process.WhitespaceLexer.yypushback,4,4,7,7,100.0,0,1
@@ edu.stanford.nlp.process.WhitespaceLexer.next,31,45,126,57,45.23809523809524,0,1
@@ edu.stanford.nlp.process.CoreLabelTokenFactory.makeToken,7,8,14,14,100.0,0,0
@@ edu.stanford.nlp.process.WordToTaggedWordProcessor.process,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.process.WordToTaggedWordProcessor.splitTag,6,7,13,13,100.0,0,1
@@ edu.stanford.nlp.process.WordToTaggedWordProcessor.main,10,12,13,10,76.92307692307693,0,0
@@ edu.stanford.nlp.process.TransformXML$SAXInterface.outputTextAndTag,8,10,22,18,81.81818181818183,0,0
@@ edu.stanford.nlp.process.TransformXML$SAXInterface.startElement,8,10,21,21,100.0,0,0
@@ edu.stanford.nlp.process.TransformXML$SAXInterface.endElement,7,9,22,22,100.0,0,0
@@ edu.stanford.nlp.process.TransformXML$SAXInterface.processText,4,4,6,6,100.0,0,1
@@ edu.stanford.nlp.process.AbstractListProcessor.processLists,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.process.DistSimClassifier.<init>,15,20,31,19,61.29032258064516,0,0
@@ edu.stanford.nlp.process.DistSimClassifier.distSimClass,8,10,22,16,72.72727272727273,0,0
@@ edu.stanford.nlp.process.WordSegmentingTokenizer$WordSegmentingTokenizerFactory.getTokenizer,4,4,10,9,90.0,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.removeWhite,7,8,16,11,68.75,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.process.PTB2TextLexer.next,86,155,391,143,36.57289002557545,0,0
@@ edu.stanford.nlp.process.LowercaseFunction.apply,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.process.TSVSentenceIterator$SentenceField.isToken,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.stringToNewlineIsSentenceBreak,9,12,12,12,100.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.isForcedEndToken,10,14,11,11,100.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.getString,8,10,9,9,100.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.matches,7,8,3,3,100.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.process,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.plausibleToAdd,18,26,25,15,60.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.wordsToSentences,97,155,329,137,41.641337386018236,0,17
@@ edu.stanford.nlp.process.WordToSentenceProcessor.<init>,15,19,19,19,100.0,0,0
@@ edu.stanford.nlp.process.WordToSentenceProcessor.<init>,17,22,27,27,100.0,0,1
@@ edu.stanford.nlp.process.Morphology.next,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.process.Morphology.lemmatize,11,15,20,18,90.0,0,0
@@ edu.stanford.nlp.process.Morphology.initStaticLexer,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.process.Morphology.apply,6,7,10,10,100.0,0,1
@@ edu.stanford.nlp.process.Morphology.main,26,36,58,39,67.24137931034483,0,0
@@ edu.stanford.nlp.process.Stemmer.add,7,8,28,23,82.14285714285714,0,1
@@ edu.stanford.nlp.process.Stemmer.cons,10,13,15,15,100.0,0,1
@@ edu.stanford.nlp.process.Stemmer.m,17,22,66,28,42.42424242424242,0,0
@@ edu.stanford.nlp.process.Stemmer.vowelinstem,7,8,16,9,56.25,0,0
@@ edu.stanford.nlp.process.Stemmer.doublec,6,7,10,10,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.cvc,11,17,23,23,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.ends,9,11,25,18,72.0,0,0
@@ edu.stanford.nlp.process.Stemmer.setto,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.process.Stemmer.r,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.step1,30,47,68,65,95.58823529411765,0,1
@@ edu.stanford.nlp.process.Stemmer.step2,5,6,7,7,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.step3,47,76,94,94,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.step4,17,27,36,36,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.step5,61,96,101,101,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.step6,11,17,36,26,72.22222222222221,0,1
@@ edu.stanford.nlp.process.Stemmer.stem,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.main,10,12,12,12,100.0,0,0
@@ edu.stanford.nlp.process.Stemmer.stem,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.process.TSVUtils.unescapeSQL,5,6,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.process.TSVUtils.parseArray,34,49,109,45,41.284403669724774,0,1
@@ edu.stanford.nlp.process.TSVUtils.parseTree,23,33,59,59,100.0,0,1
@@ edu.stanford.nlp.process.TSVUtils.parseJsonTree,23,33,67,62,92.53731343283582,0,0
@@ edu.stanford.nlp.process.TSVUtils.parseSentence,11,14,45,40,88.88888888888889,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor$PlainTextIterator.<init>,16,21,19,15,78.94736842105263,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor$PlainTextIterator.primeNext,35,55,107,95,88.78504672897196,0,1
@@ edu.stanford.nlp.process.DocumentPreprocessor$PlainTextIterator.hasNext,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor$PlainTextIterator.next,6,7,11,11,100.0,0,0
@@ edu.stanford.nlp.process.TransformXML$NoEscapingSAXInterface.processText,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor.<init>,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor.iterator,6,7,14,14,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor.main,66,93,149,83,55.70469798657718,0,1
@@ edu.stanford.nlp.process.PTBTokenizer.<init>,9,11,14,14,100.0,0,1
@@ edu.stanford.nlp.process.PTBTokenizer.ptb2Text,5,5,6,6,100.0,0,0
@@ edu.stanford.nlp.process.PTBTokenizer.ptb2Text,5,5,9,6,66.66666666666666,0,0
@@ edu.stanford.nlp.process.PTBTokenizer.untok,14,18,39,26,66.66666666666666,0,0
@@ edu.stanford.nlp.process.PTBTokenizer.labelList2Text,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.process.PTBTokenizer.tok,21,29,71,48,67.6056338028169,0,0
@@ edu.stanford.nlp.process.PTBTokenizer.tokReader,37,53,91,45,49.45054945054945,0,0
@@ edu.stanford.nlp.process.PTBTokenizer.main,33,46,70,60,85.71428571428571,0,1
@@ edu.stanford.nlp.process.PTBEscapingProcessor.unprocess,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.process.PTBEscapingProcessor.process,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.process.PTBEscapingProcessor.fixQuotes,20,27,43,26,60.46511627906976,0,0
@@ edu.stanford.nlp.process.PTBEscapingProcessor.escapeString,26,35,99,50,50.505050505050505,0,0
@@ edu.stanford.nlp.process.PTBEscapingProcessor.maybeAppendOneMore,11,14,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.process.PTBEscapingProcessor.main,10,12,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor$MyHTMLParser.handleText,10,13,22,20,90.9090909090909,0,0
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor$MyHTMLParser.handleStartTag,8,10,17,17,100.0,0,1
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor$MyHTMLParser.handleEndTag,8,10,15,15,100.0,0,0
@@ edu.stanford.nlp.process.CodepointCoreLabelProcessor.process,5,5,3,2,66.66666666666666,0,0
@@ edu.stanford.nlp.process.CodepointCoreLabelProcessor.restore,5,5,1,1,100.0,0,0
@@ edu.stanford.nlp.process.JFlexDummyLexer.zzUnpackRowMap,5,5,14,7,50.0,0,1
@@ edu.stanford.nlp.process.JFlexDummyLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.process.JFlexDummyLexer.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.process.JFlexDummyLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.JFlexDummyLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.process.JFlexDummyLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.process.JFlexDummyLexer.yylex,29,41,108,47,43.51851851851852,0,1
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor.<init>,11,13,13,13,100.0,0,0
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor.normalize,9,11,18,14,77.77777777777779,0,0
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor.main,45,65,111,63,56.75675675675676,0,0
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor.fromHTML,5,5,2,2,100.0,0,0
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor.fromPlainText,31,45,143,45,31.46853146853147,0,0
@@ edu.stanford.nlp.process.ChineseDocumentToSentenceProcessor.removeWhitespace,5,6,12,11,91.66666666666666,0,0
@@ edu.stanford.nlp.process.AmericanizeFunction.apply,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor$XMLIterator.hasNext,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor$XMLIterator.next,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.LexerUtils.normalizeFractions,6,7,19,17,89.47368421052632,0,0
@@ edu.stanford.nlp.process.LexerUtils.removeSoftHyphens,4,4,4,3,75.0,0,0
@@ edu.stanford.nlp.process.LexerUtils.escapeChar,8,10,36,4,11.11111111111111,0,0
@@ edu.stanford.nlp.process.LexerUtils.latexQuotes,5,5,14,12,85.71428571428571,0,0
@@ edu.stanford.nlp.process.LexerUtils.unicodeQuotes,5,5,16,14,87.5,0,0
@@ edu.stanford.nlp.process.LexerUtils.handleQuotes,7,10,17,17,100.0,0,0
@@ edu.stanford.nlp.process.LexerUtils.handleEllipsis,8,11,14,14,100.0,0,0
@@ edu.stanford.nlp.process.LexerUtils.handleDashes,16,24,22,22,100.0,0,0
@@ edu.stanford.nlp.process.LexerUtils.pennNormalizeParens,4,4,7,6,85.71428571428571,0,0
@@ edu.stanford.nlp.process.WhitespaceTokenizer.getNext,10,13,24,14,58.333333333333336,0,0
@@ edu.stanford.nlp.process.WhitespaceTokenizer.<init>,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.process.WhitespaceTokenizer.main,16,21,20,20,100.0,0,0
@@ edu.stanford.nlp.process.Americanize.<init>,5,5,3,3,100.0,0,0
@@ edu.stanford.nlp.process.Americanize.apply,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.process.Americanize.americanize,21,30,51,42,82.35294117647058,0,0
@@ edu.stanford.nlp.process.Americanize.main,16,21,15,15,100.0,0,0
@@ edu.stanford.nlp.process.LowercaseAndAmericanizeFunction.apply,4,4,3,3,100.0,0,0
@@ edu.stanford.nlp.process.TokenizerAdapter.getNext,7,10,14,14,100.0,0,1
@@ edu.stanford.nlp.process.TokenizerAdapter.setEolString,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.process.LexerTokenizer.getNext,7,8,18,10,55.55555555555556,0,0
@@ edu.stanford.nlp.process.LexerTokenizer.<init>,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.process.LexerTokenizer.main,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.process.DocumentPreprocessor$PlainTextIterator$1.apply,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.process.AbstractTokenizer.next,6,7,11,10,90.9090909090909,0,0
@@ edu.stanford.nlp.process.AbstractTokenizer.hasNext,7,8,11,7,63.63636363636363,0,0
@@ edu.stanford.nlp.process.AbstractTokenizer.peek,6,7,14,8,57.14285714285714,0,0
@@ edu.stanford.nlp.process.AbstractTokenizer.tokenize,7,8,8,8,100.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.<init>,114,170,176,167,94.88636363636364,0,1
@@ edu.stanford.nlp.process.PTBLexer.breakByHyphensSlashes,11,15,33,21,63.63636363636363,0,0
@@ edu.stanford.nlp.process.PTBLexer.handleHyphenatedNumber,39,71,44,44,100.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.removeFromNumber,17,25,45,23,51.11111111111111,0,0
@@ edu.stanford.nlp.process.PTBLexer.indexOfSpace,8,10,17,10,58.82352941176471,0,0
@@ edu.stanford.nlp.process.PTBLexer.getNext,6,7,20,20,100.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.processAcronym,8,10,15,12,80.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.processAbbrev1,6,7,11,9,81.81818181818183,0,0
@@ edu.stanford.nlp.process.PTBLexer.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.zzRefill,16,22,68,43,63.23529411764706,0,1
@@ edu.stanford.nlp.process.PTBLexer.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.process.PTBLexer.next,610,988,2984,1398,46.84986595174262,0,9
@@ edu.stanford.nlp.process.StripTagsProcessor.process,23,33,64,32,50.0,0,0
@@ edu.stanford.nlp.process.Morpha.zzUnpackRowMap,5,5,14,7,50.0,0,0
@@ edu.stanford.nlp.process.Morpha.setOptions,8,9,13,5,38.46153846153847,0,0
@@ edu.stanford.nlp.process.Morpha.common_noun_stem,4,4,5,4,80.0,0,1
@@ edu.stanford.nlp.process.Morpha.capitalise,11,14,25,15,60.0,0,0
@@ edu.stanford.nlp.process.Morpha.condub_stem,11,14,29,15,51.724137931034484,0,0
@@ edu.stanford.nlp.process.Morpha.stem,8,10,18,9,50.0,0,0
@@ edu.stanford.nlp.process.Morpha.semi_reg_stem,15,22,50,40,80.0,0,1
@@ edu.stanford.nlp.process.Morpha.<init>,5,5,15,11,73.33333333333333,0,0
@@ edu.stanford.nlp.process.Morpha.zzCMap,5,5,8,8,100.0,0,0
@@ edu.stanford.nlp.process.Morpha.zzRefill,16,22,68,43,63.23529411764706,0,0
@@ edu.stanford.nlp.process.Morpha.yyclose,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.Morpha.yyreset,4,4,5,5,100.0,0,0
@@ edu.stanford.nlp.process.Morpha.yypushback,4,4,7,7,100.0,0,0
@@ edu.stanford.nlp.process.Morpha.next,795,1572,3712,1284,34.59051724137931,0,15
@@ edu.stanford.nlp.process.PTBTokenizer$PTBTokenizerFactory.<init>,9,11,12,12,100.0,0,0
@@ edu.stanford.nlp.process.PTBTokenizer$PTBTokenizerFactory.getTokenizer,5,6,17,17,100.0,0,0
@@ edu.stanford.nlp.process.StoplistFilter.processDocument,7,8,9,9,100.0,0,0
@@ edu.stanford.nlp.process.StopList.<init>,5,5,5,5,100.0,0,0
@@ edu.stanford.nlp.process.StopList.addGenericWords,5,5,9,5,55.55555555555556,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.lookupShaper,36,52,34,34,100.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.dontUseLC,9,13,10,10,100.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShape,23,41,61,39,63.934426229508205,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeDan1,24,35,45,16,35.55555555555556,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeDan2,23,34,72,27,37.5,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeJenny1,27,39,91,30,32.967032967032964,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeChris2,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeChris2Short,27,39,73,31,42.465753424657535,0,1
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeChris2Long,51,73,161,64,39.75155279503105,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.chris4equivalenceClass,48,75,56,56,100.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeChris4,4,4,9,9,100.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeChris4Short,20,28,50,23,46.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeChris4Long,28,40,75,38,50.66666666666667,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeDan2Bio,4,4,6,6,100.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeChris1,118,193,336,48,14.285714285714285,0,2
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeDigits,11,14,29,11,37.93103448275862,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.wordShapeCluster1,16,24,35,21,60.0,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier.main,11,15,32,18,56.25,0,0
@@ edu.stanford.nlp.process.WordShapeClassifier$DistributionalClusters.loadWordClusters,10,12,7,7,100.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSentTrainer.fileToTrainSet,89,129,299,110,36.78929765886287,0,1
@@ edu.stanford.nlp.process.stattok.StatTokSentTrainer.addFeatures,17,21,51,25,49.01960784313725,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSentTrainer.readMultiWordRules,9,11,10,10,100.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSentTrainer.writeMultiWordRules,9,11,6,6,100.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSentTrainer.inferMultiWordRules,20,28,36,32,88.88888888888889,0,1
@@ edu.stanford.nlp.process.stattok.StatTokSentTrainer.main,41,59,83,72,86.74698795180723,0,0
@@ edu.stanford.nlp.process.stattok.BuildMultiWordRules.main,6,7,8,8,100.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSent.<init>,5,5,9,9,100.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSent.readMultiWordRules,5,5,6,6,100.0,0,1
@@ edu.stanford.nlp.process.stattok.StatTokSent.classify,5,5,4,4,100.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSent.textToFeatures,17,21,50,24,48.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSent.tokenToSplit,4,4,4,4,100.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSent.splitToken,11,13,23,20,86.95652173913044,0,1
@@ edu.stanford.nlp.process.stattok.StatTokSent.makeSentenceTokens,27,36,75,33,44.0,0,0
@@ edu.stanford.nlp.process.stattok.StatTokSent.tokenize,28,41,232,35,15.086206896551724,0,1
@@ edu.stanford.nlp.process.stattok.StatTokSent.main,14,17,18,13,72.22222222222221,0,0
@@ edu.stanford.nlp.truecaser.MixDisambiguation.main,29,39,43,33,76.74418604651163,0,1
