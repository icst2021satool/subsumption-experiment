{
"Class" : "org.apache.sysds.runtime.transform.tokenize.TokenizerPreNgram", 
"Methods" : [{ "Name" : "wordTokenToNgrams" ,
"Duas" : 22,
"0" :  "(60,68, this)",
"1" :  "(60,69, wordTokens)",
"2" :  "(60,70, wordTokens)",
"3" :  "(60,69, wordTokens.textToken)",
"4" :  "(60,68, this.params)",
"5" :  "(60,68, this.maxGram)",
"6" :  "(60,70, wordTokens.startIndex)",
"7" :  "(60,74, ngramTokens)",
"8" :  "(60,71, ngramTokens)",
"9" :  "(62,68, tokenLen)",
"10" :  "(64,(66,67), endPos)",
"11" :  "(64,(66,74), endPos)",
"12" :  "(66,(66,67), i)",
"13" :  "(66,(66,74), i)",
"14" :  "(66,67, i)",
"15" :  "(66,68, i)",
"16" :  "(66,66, i)",
"17" :  "(66,(66,67), i)",
"18" :  "(66,(66,74), i)",
"19" :  "(66,67, i)",
"20" :  "(66,68, i)",
"21" :  "(66,66, i)"},{ "Name" : "wordTokenListToNgrams" ,
"Duas" : 3,
"0" :  "(78,81, this)",
"1" :  "(78,84, ngramTokens)",
"2" :  "(78,82, ngramTokens)"},{ "Name" : "tokenizePre" ,
"Duas" : 3,
"0" :  "(89,95, this)",
"1" :  "(91,98, docToNgramTokens)",
"2" :  "(91,96, docToNgramTokens)"}]
}